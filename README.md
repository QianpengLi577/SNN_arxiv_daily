# 172、活性树突树可以减轻超导神经元扇入的限制
- [ ] An active dendritic tree can mitigate fan-in limitations in superconducting neurons 
时间：2021年07月12日                         第一作者：Bryce A. Primavera                        [链接](https://arxiv.org/abs/2107.05777).                     
## 摘要：超导电子电路在神经形态硬件方面有很多可提供的。超导量子干涉器件（SQUIDs）可以作为神经元胞体阈值操作的有源元件。然而，SQUID在应用信号中具有周期性的响应函数。我们从理论上证明，如果一个人限制对鱿鱼的总输入以维持一个单调递增的反应，那么一大部分突触必须是活跃的，以驱动神经元达到阈值。然后我们证明了一个活跃的树突树（也基于SQUIDs）可以显著减少突触的比例，这些突触必须活跃才能驱动神经元达到阈值。在这种情况下，树突树的加入提供了增强每个神经元的计算能力和允许神经元以稀疏的输入活动脉冲的双重好处。
<details>	<summary>英文摘要</summary>	Superconducting electronic circuits have much to offer with regard to neuromorphic hardware. Superconducting quantum interference devices (SQUIDs) can serve as an active element to perform the thresholding operation of a neuron's soma. However, a SQUID has a response function that is periodic in the applied signal. We show theoretically that if one restricts the total input to a SQUID to maintain a monotonically increasing response, a large fraction of synapses must be active to drive a neuron to threshold. We then demonstrate that an active dendritic tree (also based on SQUIDs) can significantly reduce the fraction of synapses that must be active to drive the neuron to threshold. In this context, the inclusion of a dendritic tree provides the dual benefits of enhancing the computational abilities of each neuron and allowing the neuron to spike with sparse input activity. </details>
<details>	<summary>注释</summary>	8 pages, 5 figures </details>
<details>	<summary>邮件日期</summary>	2021年07月14日</details>

# 171、更快速的SNN模拟，具有惰性+事件驱动的可塑性和共享原子
- [ ] Even Faster SNN Simulation with Lazy+Event-driven Plasticity and Shared Atomics 
时间：2021年07月08日                         第一作者：Dennis Bautembach                       [链接](https://arxiv.org/abs/2107.04092).                     
## 摘要：我们提出了两种新的优化方法来加速基于时钟的脉冲神经网络（SNN）模拟器。第一个目标是脉冲时间依赖性可塑性（STDP）。它结合了懒惰和事件驱动的可塑性，并有效地促进了使用位场和整数内部函数计算突触前和突触后峰值。它提供了更高的带宽比事件驱动塑性单独实现了1.5倍-2倍的加速比我们最接近的竞争对手。第二个优化目标是脉冲交货。我们以一种限制在任何给定时间需要更新的神经元数量的方式来划分我们的图表示，这允许我们在共享内存而不是全局内存中执行所述更新。这比我们最接近的竞争对手快2-2.5倍。这两种优化都代表了STDP和Spice（我们最先进的SNN模拟器）内部峰值交付多年迭代的最终进化阶段。所提出的优化不仅限于我们的图形表示或管道，而且适用于多种模拟器设计。我们在三个成熟的模型上评估我们的性能，并将我们自己与其他三个最先进的模拟器进行比较。
<details>	<summary>英文摘要</summary>	We present two novel optimizations that accelerate clock-based spiking neural network (SNN) simulators. The first one targets spike timing dependent plasticity (STDP). It combines lazy- with event-driven plasticity and efficiently facilitates the computation of pre- and post-synaptic spikes using bitfields and integer intrinsics. It offers higher bandwidth than event-driven plasticity alone and achieves a 1.5x-2x speedup over our closest competitor. The second optimization targets spike delivery. We partition our graph representation in a way that bounds the number of neurons that need be updated at any given time which allows us to perform said update in shared memory instead of global memory. This is 2x-2.5x faster than our closest competitor. Both optimizations represent the final evolutionary stages of years of iteration on STDP and spike delivery inside "Spice" (/spaIk/), our state of the art SNN simulator. The proposed optimizations are not exclusive to our graph representation or pipeline but are applicable to a multitude of simulator designs. We evaluate our performance on three well-established models and compare ourselves against three other state of the art simulators. </details>
<details>	<summary>注释</summary>	Submitted to IEEE-HPEC 2021 </details>
<details>	<summary>邮件日期</summary>	2021年07月12日</details>

# 170、一种用于人工智能的长-短期记忆算法在脉冲神经元硬件中的应用
- [ ] A Long Short-Term Memory for AI Applications in Spike-based Neuromorphic Hardware 
时间：2021年07月08日                         第一作者：Philipp Plank                       [链接](https://arxiv.org/abs/2107.03992).                     
## 摘要：尽管付出了大量的努力，但目前采用深度神经网络（DNNs）的人工智能（AI）方法在多大程度上可以在基于spike的神经形态硬件上更有效地实现仍然是一个悬而未决的问题。这尤其适用于解决序列处理任务的人工智能方法，序列处理任务是基于峰值的神经形态硬件的主要应用目标。一个困难是，用于此类任务的dnn通常采用长-短期记忆（LSTM）单元。然而，在基于峰值的硬件中对这些单元的有效仿真却一直缺失。我们提出了一个生物启发的解决方案，解决了这个问题。该解决方案使我们能够实现一类主要的dnn，用于序列处理任务，如时间序列分类和问答，并在神经形态硬件上节省大量的能量。事实上，我们用来回答问题的用于推理对象之间关系的关系网络是大型DNN的第一个例子，该DNN在神经形态硬件上执行序列处理任务，具有显著的节能效果。
<details>	<summary>英文摘要</summary>	In spite of intensive efforts it has remained an open problem to what extent current Artificial Intelligence (AI) methods that employ Deep Neural Networks (DNNs) can be implemented more energy-efficiently on spike-based neuromorphic hardware. This holds in particular for AI methods that solve sequence processing tasks, a primary application target for spike-based neuromorphic hardware. One difficulty is that DNNs for such tasks typically employ Long Short-Term Memory (LSTM) units. Yet an efficient emulation of these units in spike-based hardware has been missing. We present a biologically inspired solution that solves this problem. This solution enables us to implement a major class of DNNs for sequence processing tasks such as time series classification and question answering with substantial energy savings on neuromorphic hardware. In fact, the Relational Network for reasoning about relations between objects that we use for question answering is the first example of a large DNN that carries out a sequence processing task with substantial energy-saving on neuromorphic hardware. </details>
<details>	<summary>注释</summary>	Philipp Plank and Arjun Rao have contributed equally to this work as first authors </details>
<details>	<summary>邮件日期</summary>	2021年07月09日</details>

# 169、Q-SpiNN：一种量化脉冲神经网络的框架
- [ ] Q-SpiNN: A Framework for Quantizing Spiking Neural Networks 
时间：2021年07月05日                         第一作者：Rachmad Vidya Wicaksana Putra                       [链接](https://arxiv.org/abs/2107.01807).                     
## 摘要：量化是在不显著降低准确度的情况下减少脉冲神经网络（SNNs）内存占用的一项重要技术。然而，最新的技术仅集中于从特定量化方案直接采用权重量化，即训练后量化（PTQ）或训练量化（ITQ），并且不考虑（1）量化其他SNN参数（例如，神经元膜电位），（2）探索量化方法的不同组合（即量化方案、精度水平和舍入方案），以及（3）在最后选择具有良好记忆精度权衡的SNN模型。因此，由这些最新技术提供的用于满足目标精度的存储器节省是有限的，从而妨碍在资源受限的系统（例如，物联网边缘设备）上处理snn。针对这一点，我们提出了Q-SpiNN，一个新的量化框架的内存效率SNNs。Q-SpiNN的关键机制是：（1）根据不同SNN参数对精度的重要性对其进行量化；（2）探索量化方案、精度水平和舍入方案的不同组合，以找到有效的SNN模型候选，（3）开发一种算法，该算法量化了候选人获得的记忆精度折衷的好处，并选择帕累托最优的。实验结果表明，对于无监督网络，Q-SpiNN减少了约4倍的内存占用，同时在MNIST数据集上保持了1%的准确率。对于有监督的网络，Q-SpiNN减少了大约2倍的内存，同时将精度保持在DVS手势数据集基线的2%以内。
<details>	<summary>英文摘要</summary>	A prominent technique for reducing the memory footprint of Spiking Neural Networks (SNNs) without decreasing the accuracy significantly is quantization. However, the state-of-the-art only focus on employing the weight quantization directly from a specific quantization scheme, i.e., either the post-training quantization (PTQ) or the in-training quantization (ITQ), and do not consider (1) quantizing other SNN parameters (e.g., neuron membrane potential), (2) exploring different combinations of quantization approaches (i.e., quantization schemes, precision levels, and rounding schemes), and (3) selecting the SNN model with a good memory-accuracy trade-off at the end. Therefore, the memory saving offered by these state-of-the-art to meet the targeted accuracy is limited, thereby hindering processing SNNs on the resource-constrained systems (e.g., the IoT-Edge devices). Towards this, we propose Q-SpiNN, a novel quantization framework for memory-efficient SNNs. The key mechanisms of the Q-SpiNN are: (1) employing quantization for different SNN parameters based on their significance to the accuracy, (2) exploring different combinations of quantization schemes, precision levels, and rounding schemes to find efficient SNN model candidates, and (3) developing an algorithm that quantifies the benefit of the memory-accuracy trade-off obtained by the candidates, and selects the Pareto-optimal one. The experimental results show that, for the unsupervised network, the Q-SpiNN reduces the memory footprint by ca. 4x, while maintaining the accuracy within 1% from the baseline on the MNIST dataset. For the supervised network, the Q-SpiNN reduces the memory by ca. 2x, while keeping the accuracy within 2% from the baseline on the DVS-Gesture dataset. </details>
<details>	<summary>注释</summary>	Accepted for publication at the 2021 International Joint Conference on Neural Networks (IJCNN), July 2021, Virtual Event </details>
<details>	<summary>邮件日期</summary>	2021年07月06日</details>

# 168、DVS攻击：对动态视觉传感器的攻击
- [ ] DVS-Attacks: Adversarial Attacks on Dynamic Vision Sensors for Spiking Neural Networks 
时间：2021年07月01日                         第一作者：Alberto Marchisio                        [链接](https://arxiv.org/abs/2107.00415).                     
## 摘要：脉冲神经网络（SNN）尽管在神经形态硬件上实现时具有能量效率，并且与基于事件的动态视觉传感器（DV）相结合，但是容易受到安全威胁，例如对抗性攻击，即，为诱导误分类而添加到输入中的小扰动。为此，我们提出了DVS攻击，这是一套隐蔽而有效的对抗性攻击方法，旨在干扰构成snn输入的事件序列。首先，我们证明了DVS的噪声滤波器可以作为对抗攻击的防御机制。然后，我们实现了几种攻击，并在DVS摄像机的两种噪声滤波器的情况下进行了测试。实验结果表明，所设计的滤波器只能部分地抵抗我们提出的DVS攻击。使用最佳的噪声滤波器设置，我们提出的基于掩码滤波器的破折号攻击在DVS手势数据集和MNIST数据集上的准确率分别比原始干净帧降低了20%和65%以上。所有建议的DVS攻击和噪声滤波器的源代码发布于https://github.com/albertomarchisio/DVS-Attacks.
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNNs), despite being energy-efficient when implemented on neuromorphic hardware and coupled with event-based Dynamic Vision Sensors (DVS), are vulnerable to security threats, such as adversarial attacks, i.e., small perturbations added to the input for inducing a misclassification. Toward this, we propose DVS-Attacks, a set of stealthy yet efficient adversarial attack methodologies targeted to perturb the event sequences that compose the input of the SNNs. First, we show that noise filters for DVS can be used as defense mechanisms against adversarial attacks. Afterwards, we implement several attacks and test them in the presence of two types of noise filters for DVS cameras. The experimental results show that the filters can only partially defend the SNNs against our proposed DVS-Attacks. Using the best settings for the noise filters, our proposed Mask Filter-Aware Dash Attack reduces the accuracy by more than 20% on the DVS-Gesture dataset and by more than 65% on the MNIST dataset, compared to the original clean frames. The source code of all the proposed DVS-Attacks and noise filters is released at https://github.com/albertomarchisio/DVS-Attacks. </details>
<details>	<summary>注释</summary>	Accepted for publication at IJCNN 2021 </details>
<details>	<summary>邮件日期</summary>	2021年07月02日</details>

# 167、CarSNN：一种基于Loihi神经形态研究处理器的基于事件的自主汽车的高效脉冲神经网络
- [ ] CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor 
时间：2021年07月01日                         第一作者：Alberto Viale                        [链接](https://arxiv.org/abs/2107.00401).                     
## 摘要：与自动驾驶（AD）相关的功能提供了新的移动性形式，这也有利于其他类型的智能和自动系统，如机器人、智能交通和智能工业。对于这些应用程序，需要快速、实时地做出决策。此外，在寻求电动移动性的过程中，这项任务必须遵循低功耗策略，而不影响交通工具或机器人的自主性。这两个挑战可以利用新兴的脉冲神经网络（SNNs）来解决。当部署在专门的神经形态硬件上时，SNNs可以以低延迟和低功耗实现高性能。在本文中，我们使用一个连接到基于事件的摄像机的SNN来解决AD的一个关键问题，即汽车和其他物体之间的分类。为了比传统的基于帧的相机消耗更少的能量，我们使用了动态视觉传感器（DVS）。实验遵循离线监督学习规则进行，然后将学习到的SNN模型映射到Intel-Loihi神经形态研究芯片上。我们的最佳实验实现了86%的离线实现准确率，当它被移植到Loihi芯片上时，准确率下降到83%。神经形态硬件实现每个样本的最大延迟为0.72ms，仅消耗310mw。据我们所知，这项工作是第一个在神经形态芯片上实现基于事件的汽车分类器。
<details>	<summary>英文摘要</summary>	Autonomous Driving (AD) related features provide new forms of mobility that are also beneficial for other kind of intelligent and autonomous systems like robots, smart transportation, and smart industries. For these applications, the decisions need to be made fast and in real-time. Moreover, in the quest for electric mobility, this task must follow low power policy, without affecting much the autonomy of the mean of transport or the robot. These two challenges can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed on a specialized neuromorphic hardware, SNNs can achieve high performance with low latency and low power consumption. In this paper, we use an SNN connected to an event-based camera for facing one of the key problems for AD, i.e., the classification between cars and other objects. To consume less power than traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS). The experiments are made following an offline supervised learning rule, followed by mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip. Our best experiment achieves an accuracy on offline implementation of 86%, that drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware implementation has maximum 0.72 ms of latency for every sample, and consumes only 310 mW. To the best of our knowledge, this work is the first implementation of an event-based car classifier on a Neuromorphic Chip. </details>
<details>	<summary>注释</summary>	Accepted for publication at IJCNN 2021 </details>
<details>	<summary>邮件日期</summary>	2021年07月02日</details>

# 166、基于脉冲神经网络的三维趋化算法
- [ ] Algorithm For 3D-Chemotaxis Using Spiking Neural Network 
时间：2021年06月30日                         第一作者：Jayesh Choudhary                       [链接](https://arxiv.org/abs/2106.16215).                     
## 摘要：在这项工作中，我们的目标是设计一个端到端的脉冲实现在三维媒体的轮廓跟踪启发趋化，其中蠕虫到达的地区，有给定的集合浓度。对于刨床介质，有效的轮廓跟踪算法已经被设计出来，但是新的自由度有相当多的挑战。在这里，我们设计了一个基于klinokinesis的算法——蠕虫的运动是对刺激的响应，但与刺激不成正比。因此，所遵循的路径不是最短的，但我们可以成功地跟踪设定浓度。考虑到在神经形态计算硬件上实现的可行性，我们使用简单的LIF神经元来实现神经网络。
<details>	<summary>英文摘要</summary>	In this work, we aim to devise an end-to-end spiking implementation for contour tracking in 3D media inspired by chemotaxis, where the worm reaches the region which has the given set concentration. For a planer medium, efficient contour tracking algorithms have already been devised, but a new degree of freedom has quite a few challenges. Here we devise an algorithm based on klinokinesis - where the motion of the worm is in response to the stimuli but not proportional to it. Thus the path followed is not the shortest, but we can track the set concentration successfully. We are using simple LIF neurons for the neural network implementation, considering the feasibility of its implementation in the neuromorphic computing hardware. </details>
<details>	<summary>注释</summary>	12 pages, 8 figures, accepted for the '30th International Conference on Artificial Neural Networks, ICANN2021' </details>
<details>	<summary>邮件日期</summary>	2021年07月01日</details>

# 165、Spiking-GAN：一种使用时间到第一个Spike编码的生成性攻击网络
- [ ] Spiking-GAN: A Spiking Generative Adversarial Network Using Time-To-First-Spike Coding 
时间：2021年06月29日                         第一作者：Vineet Kotariya                       [链接](https://arxiv.org/abs/2106.15420).                     
## 摘要：脉冲神经网络（SNNs）在解决深度学习问题中显示出巨大的潜力。然而，它们仍然局限于简单的分类任务。在本文中，我们提出了第一个基于脉冲的生成性对抗网络（GAN）。它采用了一种称为时间到第一峰值编码的时态编码方案。我们使用时域近似反向传播来训练它。我们使用简单的集成和火灾（如果）神经元非常高的不应期为我们的网络，这确保了一个神经元的最大峰值。这使得该模型比基于峰值速率的系统要稀疏得多。我们改进的时间损失函数称为“攻击性TTFS”，与以前的工作相比，网络的推理时间提高了33%以上，网络中的脉冲数减少了11%以上。实验表明，利用该方法在MNIST数据集上训练网络，可以生成高质量的样本。从而证明了该框架在解决脉冲域中的此类问题方面的潜力。
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNNs) have shown great potential in solving deep learning problems in an energy-efficient manner. However, they are still limited to simple classification tasks. In this paper, we propose Spiking-GAN, the first spike-based Generative Adversarial Network (GAN). It employs a kind of temporal coding scheme called time-to-first-spike coding. We train it using approximate backpropagation in the temporal domain. We use simple integrate-and-fire (IF) neurons with very high refractory period for our network which ensures a maximum of one spike per neuron. This makes the model much sparser than a spike rate-based system. Our modified temporal loss function called 'Aggressive TTFS' improves the inference time of the network by over 33% and reduces the number of spikes in the network by more than 11% compared to previous works. Our experiments show that on training the network on the MNIST dataset using this approach, we can generate high quality samples. Thereby demonstrating the potential of this framework for solving such problems in the spiking domain. </details>
<details>	<summary>邮件日期</summary>	2021年06月30日</details>

# 164、分叉脉冲神经网络
- [ ] Bifurcation Spiking Neural Network 
时间：2021年06月25日                         第一作者：Shao-Qun Zhang                        [链接](https://arxiv.org/abs/1909.08341).                     
<details>	<summary>注释</summary>	18 pages </details>
<details>	<summary>邮件日期</summary>	2021年06月28日</details>

# 163、群体编码和动态神经元改进的脉冲参与者网络用于强化学习
- [ ] Population-coding and Dynamic-neurons improved Spiking Actor Network for Reinforcement Learning 
时间：2021年06月23日                         第一作者：Duzhen Zhang                       [链接](https://arxiv.org/abs/2106.07854).                     
<details>	<summary>注释</summary>	27 pages, 11 figures </details>
<details>	<summary>邮件日期</summary>	2021年06月24日</details>

# 162、深度脉冲神经网络的梯度重排剪枝
- [ ] Pruning of Deep Spiking Neural Networks through Gradient Rewiring 
时间：2021年06月22日                         第一作者：Yanqi Chen                       [链接](https://arxiv.org/abs/2105.04916).                     
<details>	<summary>注释</summary>	9 pages, 7 figures, 4 tables. To appear in the 30th International Joint Conference on Artificial Intelligence (IJCAI 2021) </details>
<details>	<summary>邮件日期</summary>	2021年06月23日</details>

# 161、约束塑性储备作为神经网络频率和权值控制的一种自然方法
- [ ] Constrained plasticity reserve as a natural way to control frequency and weights in spiking neural networks 
时间：2021年06月20日                         第一作者：Oleg Nikitin                        [链接](https://arxiv.org/abs/2103.08143).                     
<details>	<summary>注释</summary>	24 pages, 10 figures MSC-class: 68T05 ACM-class: I.2.6 </details>
<details>	<summary>邮件日期</summary>	2021年06月22日</details>

# 160、SiamSNN：用于节能目标跟踪的siames脉冲神经网络
- [ ] SiamSNN: Siamese Spiking Neural Networks for Energy-Efficient Object Tracking 
时间：2021年06月19日                         第一作者：Yihao Luo                       [链接](https://arxiv.org/abs/2003.07584).                     
<details>	<summary>注释</summary>	Accepted by ICANN2021, 12 pages, 5figures </details>
<details>	<summary>邮件日期</summary>	2021年06月22日</details>

# 159、VLSI电路约束对时序编码多层脉冲神经网络的影响
- [ ] Effects of VLSI Circuit Constraints on Temporal-Coding Multilayer Spiking Neural Networks 
时间：2021年06月18日                         第一作者：Yusuke Sakemi                       [链接](https://arxiv.org/abs/2106.10382).                     
## 摘要：脉冲神经网络（spiking neural network，SNN）不仅作为大脑的一种数学模型，而且作为一种能量有效的信息处理模型，在现实世界中得到了广泛的应用。特别地，基于时态编码的snn被期望比基于速率编码的snn更有效，因为前者需要更少的峰值来执行任务。由于snn是连续状态和连续时间模型，用模拟VLSI电路实现snn是非常有利的。然而，当系统规模很大时，用连续时间模拟电路构建整个系统是不可行的。因此，必须采用混合信号电路，对突触权值进行时间离散化和量化。此外，SNNs的模拟VLSI实现具有非理想性，例如噪声和器件失配的影响，以及模拟电路操作引起的其他限制。在这项研究中，我们研究了时间离散化和/或权重量化对SNNs性能的影响。此外，我们还阐明了膜电位下限和放电阈值的时间波动的影响。最后，我们提出了一种将数学SNN模型映射到离散时间模拟电路的优化方法。
<details>	<summary>英文摘要</summary>	The spiking neural network (SNN) has been attracting considerable attention not only as a mathematical model for the brain, but also as an energy-efficient information processing model for real-world applications. In particular, SNNs based on temporal coding are expected to be much more efficient than those based on rate coding, because the former requires substantially fewer spikes to carry out tasks. As SNNs are continuous-state and continuous-time models, it is favorable to implement them with analog VLSI circuits. However, the construction of the entire system with continuous-time analog circuits would be infeasible when the system size is very large. Therefore, mixed-signal circuits must be employed, and the time discretization and quantization of the synaptic weights are necessary. Moreover, the analog VLSI implementation of SNNs exhibits non-idealities, such as the effects of noise and device mismatches, as well as other constraints arising from the analog circuit operation. In this study, we investigated the effects of the time discretization and/or weight quantization on the performance of SNNs. Furthermore, we elucidated the effects the lower bound of the membrane potentials and the temporal fluctuation of the firing threshold. Finally, we propose an optimal approach for the mapping of mathematical SNN models to analog circuits with discretized time. </details>
<details>	<summary>注释</summary>	corrected typos </details>
<details>	<summary>邮件日期</summary>	2021年06月28日</details>

# 158、基于模糊神经遗传算法的水电站恢复力优化规划
- [ ] HydroPower Plant Planning for Resilience Improvement of Power Systems using Fuzzy-Neural based Genetic Algorithm 
时间：2021年06月16日                         第一作者：Akbal Rain                       [链接](https://arxiv.org/abs/2106.12042).                     
## 摘要：本文提出了一种基于负荷频率控制（LFC）的小水电站优化设计新方法，该方法采用自校正模糊比例微分（PD）方法对规划进行估计和预测。由于频率不受任何甩负荷或其它因素的控制，因此该电站处于动态频率变化下，采用PD控制器进行模糊规则优化，再结合神经深度学习技术和遗传算法进行优化。这项工作的主要目的是使小水电站的频率保持在额定值。因此，本文提出的模糊PD遗传优化控制器将应用于小规模水电系统的线性调频控制。该方案可用于小水电和柴油发电机组的不同设计。也可以在水电系统中使用柴油发电机，当用户需求高于发电量时，柴油发电机可以关闭。仿真将在MATLAB/Simulink中进行，以表示和评估这种控制方案在动态频率变化下的性能。以脉冲神经网络（SNN）为主要的深度学习技术，对这种负载频率控制进行优化，形成深度脉冲神经网络（DSNN）。结果表明，与其他方法相比，该方案具有鲁棒性强、性能高的频率控制性能。
<details>	<summary>英文摘要</summary>	This paper will propose a novel technique for optimize hydropower plant in small scale based on load frequency control (LFC) which use self-tuning fuzzy Proportional- Derivative (PD) method for estimation and prediction of planning. Due to frequency is not controlled by any dump load or something else, so this power plant is under dynamic frequency variations that will use PD controller which optimize by fuzzy rules and then with neural deep learning techniques and Genetic Algorithm optimization. The main purpose of this work is because to maintain frequency in small-hydropower plant at nominal value. So, proposed controller means Fuzzy PD optimization with Genetic Algorithm will be used for LFC in small scale of hydropower system. The proposed schema can be used in different designation of both diesel generator and mini-hydropower system at low stream flow. It is also possible to use diesel generator at the hydropower system which can be turn off when Consumer demand is higher than electricity generation. The simulation will be done in MATLAB/Simulink to represent and evaluate the performance of this control schema under dynamic frequency variations. Spiking Neural Network (SNN) used as the main deep learning techniques to optimizing this load frequency control which turns into Deep Spiking Neural Network (DSNN). Obtained results represented that the proposed schema has robust and high-performance frequency control in comparison to other methods. </details>
<details>	<summary>注释</summary>	9 pages, 7 figures </details>
<details>	<summary>邮件日期</summary>	2021年06月24日</details>

# 157、深相量网络：连接传统和脉冲神经网络
- [ ] Deep Phasor Networks: Connecting Conventional and Spiking Neural Networks 
时间：2021年06月15日                         第一作者：Wilkie Olin-Ammentorp                       [链接](https://arxiv.org/abs/2106.11908).                     
## 摘要：在这项工作中，我们扩展了标准的神经网络，假设神经元的激活与单位圆上的复数的角度相对应，即“相量”。这样的网络中的每一层通过对前一层的相位进行加权叠加并计算新的相位值来产生新的激活。这种广义体系结构允许模型达到高精度，并具有独特的优点，即可以在考虑或不考虑时间变量的情况下执行网络的数学等效版本。重要的是，时域中相位角的值可以稀疏地由一系列周期性重复的δ函数或“脉冲”表示。我们展示了在标准深度学习任务上相量网络的非时域训练，并且证明了这些网络可以在传统的非时域或脉冲时域中执行，而不需要转换步骤。这为构建深度网络提供了一个新的基础，该网络通过适合于神经形态计算硬件的基于时间脉冲的计算进行操作。
<details>	<summary>英文摘要</summary>	In this work, we extend standard neural networks by building upon an assumption that neuronal activations correspond to the angle of a complex number lying on the unit circle, or 'phasor.' Each layer in such a network produces new activations by taking a weighted superposition of the previous layer's phases and calculating the new phase value. This generalized architecture allows models to reach high accuracy and carries the singular advantage that mathematically equivalent versions of the network can be executed with or without regard to a temporal variable. Importantly, the value of a phase angle in the temporal domain can be sparsely represented by a periodically repeating series of delta functions or 'spikes'. We demonstrate the atemporal training of a phasor network on standard deep learning tasks and show that these networks can then be executed in either the traditional atemporal domain or spiking temporal domain with no conversion step needed. This provides a novel basis for constructing deep networkswhich operate via temporal, spike-based calculations suitable for neuromorphic computing hardware. </details>
<details>	<summary>注释</summary>	18 pages, 6 figures </details>
<details>	<summary>邮件日期</summary>	2021年06月23日</details>

# 156、群体编码和动态神经元改进的脉冲参与者网络用于强化学习
- [ ] Population-coding and Dynamic-neurons improved Spiking Actor Network for Reinforcement Learning 
时间：2021年06月15日                         第一作者：Duzhen Zhang                       [链接](https://arxiv.org/abs/2106.07854).                     
## 摘要：由于深度神经网络（DNNs）是一种功能强大的函数逼近器，深度强化学习（DRL）在机器人控制任务中得到了很好的应用。与普通人工神经元的dnn相比，具有生物合理性的脉冲神经元网络（SNN）包含了不同数量的脉冲神经元，使得它在时空信息的状态表示上具有很强的自然能力。基于一个混合学习框架，即脉冲-参与者网络从状态中推断行为，而深度批评网络评估参与者，我们提出了一个群体编码和动态神经元改进的脉冲-参与者网络（PDSAN），用于从两个不同的标度（输入编码和神经元编码）进行有效的状态表示。对于输入编码，我们采用具有动态感受野的总体编码来直接编码每个输入状态分量。对于神经元编码，我们提出了不同类型的动态神经元（包括一阶和二阶神经元动力学）来描述更复杂的神经元动力学。最后，使用双延迟深度确定性策略梯度算法（TD3-PDSAN）结合深度批评网络对PDSAN进行训练。大量的实验结果表明，我们的TD3-PDSAN模型在四个OpenAI健身房基准任务上取得了比现有模型更好的性能。利用SNN改进RL，使其向满足生物合理性的有效计算方向发展，是一个重要的尝试。
<details>	<summary>英文摘要</summary>	With the Deep Neural Networks (DNNs) as a powerful function approximator, Deep Reinforcement Learning (DRL) has been excellently demonstrated on robotic control tasks. Compared to DNNs with vanilla artificial neurons, the biologically plausible Spiking Neural Network (SNN) contains a diverse population of spiking neurons, making it naturally powerful on state representation with spatial and temporal information. Based on a hybrid learning framework, where a spike actor-network infers actions from states and a deep critic network evaluates the actor, we propose a Population-coding and Dynamic-neurons improved Spiking Actor Network (PDSAN) for efficient state representation from two different scales: input coding and neuronal coding. For input coding, we apply population coding with dynamically receptive fields to directly encode each input state component. For neuronal coding, we propose different types of dynamic-neurons (containing 1st-order and 2nd-order neuronal dynamics) to describe much more complex neuronal dynamics. Finally, the PDSAN is trained in conjunction with deep critic networks using the Twin Delayed Deep Deterministic policy gradient algorithm (TD3-PDSAN). Extensive experimental results show that our TD3-PDSAN model achieves better performance than state-of-the-art models on four OpenAI gym benchmark tasks. It is an important attempt to improve RL with SNN towards the effective computation satisfying biological plausibility. </details>
<details>	<summary>注释</summary>	27 pages, 11 figures, accepted by Journal of Neural Networks </details>
<details>	<summary>邮件日期</summary>	2021年06月16日</details>

# 155、基于脉冲时变塑性和梯度下降的脉冲神经网络SAR图像分类
- [ ] SAR Image Classification Based on Spiking Neural Network through Spike-Time Dependent Plasticity and Gradient Descent 
时间：2021年06月15日                         第一作者：Jiankun Chen                       [链接](https://arxiv.org/abs/2106.08005).                     
## 摘要：目前，基于卷积神经网络（CNN）的合成孔径雷达（SAR）图像分类方法存在抗噪性差、泛化能力差等问题。脉冲神经网络是类脑智能的核心组成部分之一，具有良好的应用前景。本文利用具有复杂时空信息的脉冲序列，基于SNN的无监督和有监督学习，构造了一个完整的SAR图像分类器。本文首先阐述了脉冲神经元模型、SNN的感受野以及脉冲序列的构建。提出了一种基于STDP的无监督学习算法和一种基于梯度下降的有监督学习算法。在MSTAR数据集的三类图像中，单层和双层无监督学习SNN的平均分类准确率分别为80.8%和85.1%。此外，无监督学习的收敛输出脉冲序列可以作为教学信号。基于TensorFlow框架，自下而上构建了单层监督学习SNN，分类准确率达到90.05%。通过比较SNN和cnn的抗噪性能和模型参数，验证了SNN的有效性和突出的优点。复制我们实验的代码可从\url获得{https://github.com/Jiankun-chen/Supervised-SNN-with-GD}.
<details>	<summary>英文摘要</summary>	At present, the Synthetic Aperture Radar (SAR) image classification method based on convolution neural network (CNN) has faced some problems such as poor noise resistance and generalization ability. Spiking neural network (SNN) is one of the core components of brain-like intelligence and has good application prospects. This article constructs a complete SAR image classifier based on unsupervised and supervised learning of SNN by using spike sequences with complex spatio-temporal information. We firstly expound the spiking neuron model, the receptive field of SNN, and the construction of spike sequence. Then we put forward an unsupervised learning algorithm based on STDP and a supervised learning algorithm based on gradient descent. The average classification accuracy of single layer and bilayer unsupervised learning SNN in three categories images on MSTAR dataset is 80.8\% and 85.1\%, respectively. Furthermore, the convergent output spike sequences of unsupervised learning can be used as teaching signals. Based on the TensorFlow framework, a single layer supervised learning SNN is built from the bottom, and the classification accuracy reaches 90.05\%. By comparing noise resistance and model parameters between SNNs and CNNs, the effectiveness and outstanding advantages of SNN are verified. Code to reproduce our experiments is available at \url{https://github.com/Jiankun-chen/Supervised-SNN-with-GD}. </details>
<details>	<summary>邮件日期</summary>	2021年06月16日</details>

# 154、脉冲神经网络的能量有效知识提取
- [ ] Energy-efficient Knowledge Distillation for Spiking Neural Networks 
时间：2021年06月14日                         第一作者：Dongjin Lee                       [链接](https://arxiv.org/abs/2106.07172).                     
## 摘要：脉冲神经网络（SNNs）作为传统人工神经网络（ANNs）的一种高效节能的替代方法，由于其事件驱动的计算能力而受到广泛关注。考虑到SNN模型在约束神经形态设备中的应用前景，许多研究将最初用于ANN模型压缩的技术，如网络量化、剪枝和知识提取等，应用到SNN中。其中，已有的关于知识提炼的研究报道了student-SNN模型的精度改进。然而，对SNN的一个重要特征&能量效率的分析却很少。在本文中，我们从准确性和能源效率两个方面深入分析了提取的SNN模型的性能。在这个过程中，我们观察到，当使用传统的知识蒸馏方法时，脉冲数量大幅增加，导致能源效率低下。在此基础上，提出了一种基于非均匀温度参数的知识提取方法。我们在两个不同的数据集上对我们的方法进行了评估，结果表明SNN学生既满足准确性的提高，也满足脉冲数目的减少。在MNIST数据集上，我们提出的学生SNN与传统知识提取方法训练的学生SNN相比，准确率提高了0.09%，峰值减少了65%。我们还将结果与其他SNN压缩技术和训练方法进行了比较。
<details>	<summary>英文摘要</summary>	Spiking neural networks (SNNs) have been gaining interest as energy-efficient alternatives of conventional artificial neural networks (ANNs) due to their event-driven computation. Considering the future deployment of SNN models to constrained neuromorphic devices, many studies have applied techniques originally used for ANN model compression, such as network quantization, pruning, and knowledge distillation, to SNNs. Among them, existing works on knowledge distillation reported accuracy improvements of student SNN model. However, analysis on energy efficiency, which is also an important feature of SNN, was absent. In this paper, we thoroughly analyze the performance of the distilled SNN model in terms of accuracy and energy efficiency. In the process, we observe a substantial increase in the number of spikes, leading to energy inefficiency, when using the conventional knowledge distillation methods. Based on this analysis, to achieve energy efficiency, we propose a novel knowledge distillation method with heterogeneous temperature parameters. We evaluate our method on two different datasets and show that the resulting SNN student satisfies both accuracy improvement and reduction of the number of spikes. On MNIST dataset, our proposed student SNN achieves up to 0.09% higher accuracy and produces 65% less spikes compared to the student SNN trained with conventional knowledge distillation method. We also compare the results with other SNN compression techniques and training methods. </details>
<details>	<summary>邮件日期</summary>	2021年06月15日</details>

# 153、反向传播算法在脉冲神经元硬件上的实现
- [ ] The Backpropagation Algorithm Implemented on Spiking Neuromorphic Hardware 
时间：2021年06月13日                         第一作者：Alpha Renner                       [链接](https://arxiv.org/abs/2106.07030).                     
## 摘要：自然神经系统的能力激发了新一代机器学习算法以及能够快速、低功耗信息处理的神经形态超大规模集成（VLSI）电路。然而，大多数现代机器学习算法在神经生理学上并不合理，因此不能直接在神经形态硬件中实现。特别是，现代深度学习的主力，反向传播算法，已经证明很难转化为神经形态的硬件。在这项研究中，我们提出了一个基于脉冲门控动态信息协调和处理的神经形态，脉冲反向传播算法，实现在英特尔的Loihi神经形态研究处理器。我们展示了一个原理证明三层电路，学习从MNIST数据集分类数字。这个实现展示了在现代深度学习应用程序中使用大规模并行、低功耗、低延迟的神经形态处理器的途径。
<details>	<summary>英文摘要</summary>	The capabilities of natural neural systems have inspired new generations of machine learning algorithms as well as neuromorphic very large-scale integrated (VLSI) circuits capable of fast, low-power information processing. However, most modern machine learning algorithms are not neurophysiologically plausible and thus are not directly implementable in neuromorphic hardware. In particular, the workhorse of modern deep learning, the backpropagation algorithm, has proven difficult to translate to neuromorphic hardware. In this study, we present a neuromorphic, spiking backpropagation algorithm based on pulse-gated dynamical information coordination and processing, implemented on Intel's Loihi neuromorphic research processor. We demonstrate a proof-of-principle three-layer circuit that learns to classify digits from the MNIST dataset. This implementation shows a path for using massively parallel, low-power, low-latency neuromorphic processors in modern deep learning applications. </details>
<details>	<summary>注释</summary>	20 pages, 5 figures Report-no: LA-UR-21-24457 ACM-class: I.2.6 </details>
<details>	<summary>邮件日期</summary>	2021年06月15日</details>

# 152、基于脉冲神经网络的联合学习
- [ ] Federated Learning with Spiking Neural Networks 
时间：2021年06月11日                         第一作者：Yeshwanth Venkatesha                       [链接](https://arxiv.org/abs/2106.06579).                     
## 摘要：随着神经网络在资源受限的嵌入式设备中的广泛应用，对低功耗神经系统的需求也越来越大。脉冲神经网络（SNNs）是一种新兴的能源效率的替代传统的人工神经网络（ANNs）是众所周知的计算密集型。从应用的角度来看，由于联合学习涉及多个能量受限的设备，因此利用SNNs提供的能量效率有很大的空间。尽管snn非常重要，但是在像联邦学习这样的大规模分布式系统上训练snn的研究却很少。在本文中，我们将SNNs引入到一个更现实的联邦学习场景中。具体来说，我们提出了一个联邦学习框架，分散和隐私保护培训的SNN。为了验证所提出的联邦学习框架，我们使用CIFAR10和CIFAR100基准测试评估了SNNs在联邦学习各个方面的优势。我们观察到，当数据分布在联邦中的大量客户机上时，SNNs在总体准确率方面优于ANNs，超过15%，同时提供高达5.3倍的能效。除了效率之外，我们还分析了所提出的联邦SNN框架对客户端数据分布、散乱和梯度噪声的敏感性，并与人工神经网络进行了综合比较。
<details>	<summary>英文摘要</summary>	As neural networks get widespread adoption in resource-constrained embedded devices, there is a growing need for low-power neural systems. Spiking Neural Networks (SNNs)are emerging to be an energy-efficient alternative to the traditional Artificial Neural Networks (ANNs) which are known to be computationally intensive. From an application perspective, as federated learning involves multiple energy-constrained devices, there is a huge scope to leverage energy efficiency provided by SNNs. Despite its importance, there has been little attention on training SNNs on a large-scale distributed system like federated learning. In this paper, we bring SNNs to a more realistic federated learning scenario. Specifically, we propose a federated learning framework for decentralized and privacy-preserving training of SNNs. To validate the proposed federated learning framework, we experimentally evaluate the advantages of SNNs on various aspects of federated learning with CIFAR10 and CIFAR100 benchmarks. We observe that SNNs outperform ANNs in terms of overall accuracy by over 15% when the data is distributed across a large number of clients in the federation while providing up to5.3x energy efficiency. In addition to efficiency, we also analyze the sensitivity of the proposed federated SNN framework to data distribution among the clients, stragglers, and gradient noise and perform a comprehensive comparison with ANNs. </details>
<details>	<summary>邮件日期</summary>	2021年06月15日</details>

# 151、具有平衡突触的单混合信号神经元的时空棘波模式选择性
- [ ] Spatiotemporal Spike-Pattern Selectivity in Single Mixed-Signal Neurons with Balanced Synapses 
时间：2021年06月10日                         第一作者：Mattias Nilsson                       [链接](https://arxiv.org/abs/2106.05686).                     
## 摘要：实现混合信号神经形态处理器超低功耗推理和学习的潜力，需要有效地利用其非均匀模拟电路以及稀疏的、基于时间的信息编码和处理。在这里，我们研究了时空相关器（STC）网络中输出神经元的基于脉冲时间的时空感受野，我们使用兴奋-抑制平衡的突触前输入代替专门的轴突或神经元延迟。我们提出了一个混合信号DYNAP-SE神经形态处理器的半实物实验，其中硬件神经元的五维感受野通过随机抽样均匀分布的输入脉冲模式来映射。我们发现，当平衡的突触前成分被随机编程时，一些神经元显示出不同的感受野。此外，我们还演示了如何通过激活不同的非均匀模拟突触电路子集，调整神经元以检测特定的时空特征，而神经元最初是非选择性的。与以前基于延迟的神经形态硬件实现相比，平衡的突触元件的能量耗散比每侧连接低一个数量级（0.65nj对9.3nj）。因此，我们展示了如何利用不均匀的突触电路来实现STC网络层的资源有效性，使突触地址重编程成为一种离散的特征调整机制。
<details>	<summary>英文摘要</summary>	Realizing the potential of mixed-signal neuromorphic processors for ultra-low-power inference and learning requires efficient use of their inhomogeneous analog circuitry as well as sparse, time-based information encoding and processing. Here, we investigate spike-timing-based spatiotemporal receptive fields of output-neurons in the Spatiotemporal Correlator (STC) network, for which we used excitatory-inhibitory balanced disynaptic inputs instead of dedicated axonal or neuronal delays. We present hardware-in-the-loop experiments with a mixed-signal DYNAP-SE neuromorphic processor, in which five-dimensional receptive fields of hardware neurons were mapped by randomly sampling input spike-patterns from a uniform distribution. We find that, when the balanced disynaptic elements are randomly programmed, some of the neurons display distinct receptive fields. Furthermore, we demonstrate how a neuron was tuned to detect a particular spatiotemporal feature, to which it initially was non-selective, by activating a different subset of the inhomogeneous analog synaptic circuits. The energy dissipation of the balanced synaptic elements is one order of magnitude lower per lateral connection (0.65 nJ vs 9.3 nJ per spike) than former delay-based neuromorphic hardware implementations. Thus, we show how the inhomogeneous synaptic circuits could be utilized for resource-efficient implementation of STC network layers, in a way that enables synapse-address reprogramming as a discrete mechanism for feature tuning. </details>
<details>	<summary>注释</summary>	This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible </details>
<details>	<summary>邮件日期</summary>	2021年06月11日</details>

# 150、基于反向传播的深脉冲神经网络时间脉冲序列学习
- [ ] Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks 
时间：2021年06月07日                         第一作者：Wenrui Zhang                       [链接](https://arxiv.org/abs/2002.10085).                     
<details>	<summary>注释</summary>	Accepted for spotlight presentation of NeurIPS (Neural Information Processing System) 2020: https://proceedings.neurips.cc/paper/2020/hash/8bdb5058376143fa358981954e7626b8-Abstract.html </details>
<details>	<summary>邮件日期</summary>	2021年06月08日</details>

# 149、脉冲神经网络中的深度剩余学习
- [ ] Deep Residual Learning in Spiking Neural Networks 
时间：2021年06月05日                         第一作者：Wei Fang                       [链接](https://arxiv.org/abs/2102.04159).                     
<details>	<summary>邮件日期</summary>	2021年06月08日</details>

# 148、SpikePropamine：脉冲神经网络的可微可塑性
- [ ] SpikePropamine: Differentiable Plasticity in Spiking Neural Networks 
时间：2021年06月04日                         第一作者：Samuel Schmidgall                       [链接](https://arxiv.org/abs/2106.02681).                     
## 摘要：在生物神经网络的学习过程中，突触效能的适应性变化已经被证明起着关键的作用。尽管有这样的灵感来源，许多使用脉冲神经网络（SNNs）的以学习为中心的应用程序仍然保持静态的突触连接，阻止了初始训练期后的额外学习。在这里，我们介绍了一个框架，同时学习潜在的固定权重和规则的动态突触可塑性和神经调节突触可塑性在SNNs通过梯度下降。我们进一步展示了这个框架在一系列具有挑战性的基准上的能力，学习了几个可塑性规则的参数，包括BCM、Oja以及它们各自的一组神经调节变体。实验结果表明，具有可微可塑性的SNN足以解决一组传统SNN无法解决的具有挑战性的时间学习任务，即使在存在显著噪声的情况下也是如此。这些网络也被证明能够在高维机器人学习任务中产生运动，在初始训练期间没有出现的新情况下，可以观察到几乎最小的性能退化。
<details>	<summary>英文摘要</summary>	The adaptive changes in synaptic efficacy that occur between spiking neurons have been demonstrated to play a critical role in learning for biological neural networks. Despite this source of inspiration, many learning focused applications using Spiking Neural Networks (SNNs) retain static synaptic connections, preventing additional learning after the initial training period. Here, we introduce a framework for simultaneously learning the underlying fixed-weights and the rules governing the dynamics of synaptic plasticity and neuromodulated synaptic plasticity in SNNs through gradient descent. We further demonstrate the capabilities of this framework on a series of challenging benchmarks, learning the parameters of several plasticity rules including BCM, Oja's, and their respective set of neuromodulatory variants. The experimental results display that SNNs augmented with differentiable plasticity are sufficient for solving a set of challenging temporal learning tasks that a traditional SNN fails to solve, even in the presence of significant noise. These networks are also shown to be capable of producing locomotion on a high-dimensional robotic learning task, where near-minimal degradation in performance is observed in the presence of novel conditions not seen during the initial training period. </details>
<details>	<summary>邮件日期</summary>	2021年06月08日</details>

# 147、基于时间到第一脉冲编码的能量有效的深脉冲神经网络训练
- [ ] Training Energy-Efficient Deep Spiking Neural Networks with Time-to-First-Spike Coding 
时间：2021年06月04日                         第一作者：Seongsik Park                       [链接](https://arxiv.org/abs/2106.02568).                     
## 摘要：深度神经网络（DNNs）的巨大能量消耗已经成为深度学习中的一个严重问题。脉冲神经网络（Spiking neural networks，SNNs）是一种模拟人脑操作的高效节能神经网络。由于snn的事件驱动和时空稀疏操作，使得snn具有高效节能处理的可能性。为了释放它们的潜能，深部snn采用了时间编码，如TTFS（time-To-first spike）编码，它代表了神经元之间在第一个峰值时间的信息。通过TTFS编码，每个神经元最多产生一个脉冲，从而显著提高了能量效率。已有一些研究成功地将TTFS编码引入深度snn，但由于缺乏对训练效率的考虑，其效率的提高受到限制。针对上述问题，本文提出了基于TTFS编码的能量有效的深度snn训练方法。我们引入了一个代理DNN模型来在可行的时间内训练深度SNN，并分析了时态核对训练性能和效率的影响。在此基础上，我们提出了随机松弛激活和基于初值的时间核参数正则化方法。此外，为了进一步减少峰值的数量，我们提出了时态核感知的批处理规范化。利用所提出的方法，我们可以在显著减少脉冲的情况下获得可比的训练结果，从而产生节能的深SNN。
<details>	<summary>英文摘要</summary>	The tremendous energy consumption of deep neural networks (DNNs) has become a serious problem in deep learning. Spiking neural networks (SNNs), which mimic the operations in the human brain, have been studied as prominent energy-efficient neural networks. Due to their event-driven and spatiotemporally sparse operations, SNNs show possibilities for energy-efficient processing. To unlock their potential, deep SNNs have adopted temporal coding such as time-to-first-spike (TTFS)coding, which represents the information between neurons by the first spike time. With TTFS coding, each neuron generates one spike at most, which leads to a significant improvement in energy efficiency. Several studies have successfully introduced TTFS coding in deep SNNs, but they showed restricted efficiency improvement owing to the lack of consideration for efficiency during training. To address the aforementioned issue, this paper presents training methods for energy-efficient deep SNNs with TTFS coding. We introduce a surrogate DNN model to train the deep SNN in a feasible time and analyze the effect of the temporal kernel on training performance and efficiency. Based on the investigation, we propose stochastically relaxed activation and initial value-based regularization for the temporal kernel parameters. In addition, to reduce the number of spikes even further, we present temporal kernel-aware batch normalization. With the proposed methods, we could achieve comparable training results with significantly reduced spikes, which could lead to energy-efficient deep SNNs. </details>
<details>	<summary>邮件日期</summary>	2021年06月07日</details>

# 146、基于事件的脉冲神经网络光流自监督学习
- [ ] Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks 
时间：2021年06月03日                         第一作者：Federico Paredes-Vall\'es                       [链接](https://arxiv.org/abs/2106.01862).                     
## 摘要：神经形态传感和计算为高能量效率和高带宽的传感器处理带来了希望。神经形态计算面临的一个主要挑战是，传统人工神经网络（ANNs）的学习算法由于离散脉冲和更复杂的神经元动力学特性而不能直接转换为脉冲神经网络（SNNs）。因此，snn尚未成功地应用于复杂的大规模任务。本文主要研究基于事件的摄像机输入光流估计的自监督学习问题，并研究了最新的人工神经网络训练流水线所需的变化，以便成功地用SNNs解决这一问题。更具体地说，我们首先修改输入事件表示，用最少的显式时间信息编码更小的时间片。因此，我们使网络的神经元动力学和循环连接负责整合信息随着时间的推移。此外，我们重新构造了基于事件的光流的自监督损失函数，以改善其凸性。我们使用所提出的管道对各种类型的递归神经网络和snn进行了实验。关于SNNs，我们研究了参数初始化和优化、替代梯度形状和自适应神经元机制等因素的影响。我们发现初始化和替代梯度宽度在稀疏输入的学习中起着关键作用，而自适应性和可学习神经元参数的加入可以提高学习性能。结果表明，所提出的人工神经网络和神经网络的性能与目前最先进的自监督训练人工神经网络相当。
<details>	<summary>英文摘要</summary>	Neuromorphic sensing and computing hold a promise for highly energy-efficient and high-bandwidth-sensor processing. A major challenge for neuromorphic computing is that learning algorithms for traditional artificial neural networks (ANNs) do not transfer directly to spiking neural networks (SNNs) due to the discrete spikes and more complex neuronal dynamics. As a consequence, SNNs have not yet been successfully applied to complex, large-scale tasks. In this article, we focus on the self-supervised learning problem of optical flow estimation from event-based camera inputs, and investigate the changes that are necessary to the state-of-the-art ANN training pipeline in order to successfully tackle it with SNNs. More specifically, we first modify the input event representation to encode a much smaller time slice with minimal explicit temporal information. Consequently, we make the network's neuronal dynamics and recurrent connections responsible for integrating information over time. Moreover, we reformulate the self-supervised loss function for event-based optical flow to improve its convexity. We perform experiments with various types of recurrent ANNs and SNNs using the proposed pipeline. Concerning SNNs, we investigate the effects of elements such as parameter initialization and optimization, surrogate gradient shape, and adaptive neuronal mechanisms. We find that initialization and surrogate gradient width play a crucial part in enabling learning with sparse inputs, while the inclusion of adaptivity and learnable neuronal parameters can improve performance. We show that the performance of the proposed ANNs and SNNs are on par with that of the current state-of-the-art ANNs trained in a self-supervised manner. </details>
<details>	<summary>邮件日期</summary>	2021年06月04日</details>

# 145、可微点过程及其在脉冲神经网络中的应用
- [ ] A Differentiable Point Process with Its Application to Spiking Neural Networks 
时间：2021年06月03日                         第一作者：Hiroshi Kajino                       [链接](https://arxiv.org/abs/2106.00901).                     
<details>	<summary>注释</summary>	Accepted to ICML 2021 </details>
<details>	<summary>邮件日期</summary>	2021年06月04日</details>

# 144、可微点过程及其在脉冲神经网络中的应用
- [ ] A Differentiable Point Process with Its Application to Spiking Neural Networks 
时间：2021年06月02日                         第一作者：Hiroshi Kajino                       [链接](https://arxiv.org/abs/2106.00901).                     
## 摘要：本文研究了一种脉冲神经网络概率模型的学习算法。Jimenez-Rezende和Gerstner（2014）提出了一种随机变分推理算法来训练具有隐藏神经元的snn。该算法利用分数函数梯度估计更新变分分布，其高方差往往阻碍整个学习算法。提出了一种基于路径梯度估计的snn梯度估计方法。主要的技术难点是缺乏一种通用的方法来区分任意点过程的实现，这是导出路径梯度估计器所必需的。我们发展了一个可微点过程，这是本文的技术亮点，并将其应用于推导SNNs的路径梯度估计。通过数值模拟研究了梯度估计的有效性。
<details>	<summary>英文摘要</summary>	This paper is concerned about a learning algorithm for a probabilistic model of spiking neural networks (SNNs). Jimenez Rezende & Gerstner (2014) proposed a stochastic variational inference algorithm to train SNNs with hidden neurons. The algorithm updates the variational distribution using the score function gradient estimator, whose high variance often impedes the whole learning algorithm. This paper presents an alternative gradient estimator for SNNs based on the path-wise gradient estimator. The main technical difficulty is a lack of a general method to differentiate a realization of an arbitrary point process, which is necessary to derive the path-wise gradient estimator. We develop a differentiable point process, which is the technical highlight of this paper, and apply it to derive the path-wise gradient estimator for SNNs. We investigate the effectiveness of our gradient estimator through numerical simulation. </details>
<details>	<summary>注释</summary>	Accepted to ICML 2021 </details>
<details>	<summary>邮件日期</summary>	2021年06月03日</details>

# 143、通过信息瓶颈学习脉冲神经网络的时间译码
- [ ] Learning to Time-Decode in Spiking Neural Networks Through the Information Bottleneck 
时间：2021年06月02日                         第一作者：Nicolas Skatchkovsky                       [链接](https://arxiv.org/abs/2106.01177).                     
## 摘要：训练脉冲神经网络（SNNs）的一个关键挑战是，目标输出通常以自然信号的形式出现，例如用于分类的标签或用于生成模型的图像，并且需要编码成脉冲。这是通过手工制作目标脉冲信号来实现的，这又隐含地修复了用于将脉冲解码为自然信号的机制，例如速率解码。目标信号和解码规则的任意选择通常会削弱SNN在脉冲定时中编码和处理信息的能力。为了解决这一问题，本文提出了一种混合变分自动编码器结构，由编码SNN和译码人工神经网络（ANN）组成。解码神经网络的作用是学习如何将SNN输出的脉冲信号最佳地转换为目标自然信号。提出了一种新的端到端学习规则，通过代理梯度优化有向信息瓶颈训练准则。我们证明了该技术在各种任务的实验环境中的适用性，包括真实的数据集。
<details>	<summary>英文摘要</summary>	One of the key challenges in training Spiking Neural Networks (SNNs) is that target outputs typically come in the form of natural signals, such as labels for classification or images for generative models, and need to be encoded into spikes. This is done by handcrafting target spiking signals, which in turn implicitly fixes the mechanisms used to decode spikes into natural signals, e.g., rate decoding. The arbitrary choice of target signals and decoding rule generally impairs the capacity of the SNN to encode and process information in the timing of spikes. To address this problem, this work introduces a hybrid variational autoencoder architecture, consisting of an encoding SNN and a decoding Artificial Neural Network (ANN). The role of the decoding ANN is to learn how to best convert the spiking signals output by the SNN into the target natural signal. A novel end-to-end learning rule is introduced that optimizes a directed information bottleneck training criterion via surrogate gradients. We demonstrate the applicability of the technique in an experimental settings on various tasks, including real-life datasets. </details>
<details>	<summary>注释</summary>	Under review for conference publication </details>
<details>	<summary>邮件日期</summary>	2021年06月03日</details>

# 142、自下而上和自上而下的神经处理系统设计：自然智能和人工智能融合的神经形态智能
- [ ] Bottom-Up and Top-Down Neural Processing Systems Design: Neuromorphic Intelligence as the Convergence of Natural and Artificial Intelligence 
时间：2021年06月02日                         第一作者：Charlotte Frenkel                       [链接](https://arxiv.org/abs/2106.01288).                     
## 摘要：虽然摩尔定律推动了人们对计算能力的指数预期，但它的接近尾声呼唤着改善系统整体性能的新途径。这些途径之一是探索新的替代大脑启发的计算架构，承诺实现生物神经处理系统的灵活性和计算效率。在这一背景下，神经形态智能代表了一个范式的转变，在计算的基础上实现了脉冲神经网络结构紧密地协同定位处理和记忆。在本文中，我们提供了该领域的全面概述，强调了现有硅实现中存在的不同粒度级别，比较了旨在复制自然智能（自下而上）和旨在解决实际人工智能应用（自上而下）的方法，并评估用于实现这些目标的不同电路设计风格的好处。首先，我们介绍了模拟、混合信号和数字电路的设计风格，通过时间复用、内存计算和新型器件来确定处理和内存之间的边界。接下来，我们将重点介绍自底向上和自顶向下方法的关键权衡，调查它们的硅实现，并进行详细的比较分析以提取设计准则。最后，我们确定了实现神经形态边缘计算相对于传统机器学习加速器的竞争优势所需的必要协同作用和缺失元素，并概述了神经形态智能框架的关键元素。
<details>	<summary>英文摘要</summary>	While Moore's law has driven exponential computing power expectations, its nearing end calls for new avenues for improving the overall system performance. One of these avenues is the exploration of new alternative brain-inspired computing architectures that promise to achieve the flexibility and computational efficiency of biological neural processing systems. Within this context, neuromorphic intelligence represents a paradigm shift in computing based on the implementation of spiking neural network architectures tightly co-locating processing and memory. In this paper, we provide a comprehensive overview of the field, highlighting the different levels of granularity present in existing silicon implementations, comparing approaches that aim at replicating natural intelligence (bottom-up) versus those that aim at solving practical artificial intelligence applications (top-down), and assessing the benefits of the different circuit design styles used to achieve these goals. First, we present the analog, mixed-signal and digital circuit design styles, identifying the boundary between processing and memory through time multiplexing, in-memory computation and novel devices. Next, we highlight the key tradeoffs for each of the bottom-up and top-down approaches, survey their silicon implementations, and carry out detailed comparative analyses to extract design guidelines. Finally, we identify both necessary synergies and missing elements required to achieve a competitive advantage for neuromorphic edge computing over conventional machine-learning accelerators, and outline the key elements for a framework toward neuromorphic intelligence. </details>
<details>	<summary>邮件日期</summary>	2021年06月03日</details>

# 141、基于平衡脉冲神经网络的振动异常在线检测
- [ ] Online Detection of Vibration Anomalies Using Balanced Spiking Neural Networks 
时间：2021年06月01日                         第一作者：Nik Dennler                       [链接](https://arxiv.org/abs/2106.00687).                     
## 摘要：振动模式产生了关于运行机器健康状态的有价值的信息，这通常用于大型工业系统的预测性维护任务。然而，在尺寸、复杂性和功率预算方面，利用这些信息的经典方法所需的开销对于较小规模的应用（如自动汽车、无人机或机器人）通常是禁止的。在这里，我们提出了一种神经形态的方法来执行振动分析使用脉冲神经网络，可以应用于广泛的场景。我们提出了一种基于脉冲的端到端管道，能够使用与模拟-数字神经形态电路兼容的构建块从振动数据中检测系统异常。该管道以在线无监督方式运行，依赖于耳蜗模型、反馈自适应和平衡脉冲神经网络。我们证明了所提出的方法在两个公开的数据集上达到了最先进的性能或更好的性能。此外，我们还演示了在异步神经形态处理器设备上实现的工作概念证明。这项工作是朝着设计和实现用于在线振动监测的自主低功耗边缘计算设备迈出的重要一步。
<details>	<summary>英文摘要</summary>	Vibration patterns yield valuable information about the health state of a running machine, which is commonly exploited in predictive maintenance tasks for large industrial systems. However, the overhead, in terms of size, complexity and power budget, required by classical methods to exploit this information is often prohibitive for smaller-scale applications such as autonomous cars, drones or robotics. Here we propose a neuromorphic approach to perform vibration analysis using spiking neural networks that can be applied to a wide range of scenarios. We present a spike-based end-to-end pipeline able to detect system anomalies from vibration data, using building blocks that are compatible with analog-digital neuromorphic circuits. This pipeline operates in an online unsupervised fashion, and relies on a cochlea model, on feedback adaptation and on a balanced spiking neural network. We show that the proposed method achieves state-of-the-art performance or better against two publicly available data sets. Further, we demonstrate a working proof-of-concept implemented on an asynchronous neuromorphic processor device. This work represents a significant step towards the design and implementation of autonomous low-power edge-computing devices for online vibration monitoring. </details>
<details>	<summary>注释</summary>	This work is presented at the 2021 IEEE AICAS </details>
<details>	<summary>邮件日期</summary>	2021年06月03日</details>

# 140、基于事件的反向传播可以精确计算脉冲神经网络的梯度
- [ ] Event-Based Backpropagation can compute Exact Gradients for Spiking Neural Networks 
时间：2021年05月31日                         第一作者：Timo C. Wunderlich                       [链接](https://arxiv.org/abs/2009.08378).                     
<details>	<summary>邮件日期</summary>	2021年06月02日</details>

# 139、STDP训练的脉冲神经网络预处理对时空动作识别的影响研究
- [ ] A Study On the Effects of Pre-processing On Spatio-temporal Action Recognition Using Spiking Neural Networks Trained with STDP 
时间：2021年05月31日                         第一作者：El-Assal Mireille                        [链接](https://arxiv.org/abs/2105.14740).                     
## 摘要：近年来，脉冲神经网络受到越来越多的关注。snn被视为解决ann在模式识别中的瓶颈问题（如能源效率）的假设性解决方案。但是目前的方法，如ANN-to-SNN转换和反向传播等，并没有充分利用这些网络，无监督方法还没有达到与先进的人工神经网络相媲美的成功。研究非监督学习方法训练的snn在视频分类任务中的行为非常重要，例如脉冲时间依赖可塑性（STDP），包括利用脉冲模拟运动信息的机制，因为这些信息对于视频理解至关重要。本文提出了多种方法将时间信息转换成静态格式，然后使用延迟编码将视觉信息转换成脉冲。这些方法与早期和晚期两种时间融合方法相结合，用于帮助脉冲神经网络捕获视频中的时空特征。本文利用STDP训练的卷积脉冲神经网络的网络结构，测试了该网络在动作识别任务中的性能。了解脉冲神经网络如何响应不同的运动提取和表示方法，有助于缩小snn和ann之间的性能差距。本文利用脉冲神经网络研究了动作形状和速度的相似性对动作识别的影响，并与其它方法进行了比较。
<details>	<summary>英文摘要</summary>	There has been an increasing interest in spiking neural networks in recent years. SNNs are seen as hypothetical solutions for the bottlenecks of ANNs in pattern recognition, such as energy efficiency. But current methods such as ANN-to-SNN conversion and back-propagation do not take full advantage of these networks, and unsupervised methods have not yet reached a success comparable to advanced artificial neural networks. It is important to study the behavior of SNNs trained with unsupervised learning methods such as spike-timing dependent plasticity (STDP) on video classification tasks, including mechanisms to model motion information using spikes, as this information is critical for video understanding. This paper presents multiple methods of transposing temporal information into a static format, and then transforming the visual information into spikes using latency coding. These methods are paired with two types of temporal fusion known as early and late fusion, and are used to help the spiking neural network in capturing the spatio-temporal features from videos. In this paper, we rely on the network architecture of a convolutional spiking neural network trained with STDP, and we test the performance of this network when challenged with action recognition tasks. Understanding how a spiking neural network responds to different methods of movement extraction and representation can help reduce the performance gap between SNNs and ANNs. In this paper we show the effect of the similarity in the shape and speed of certain actions on action recognition with spiking neural networks, we also highlight the effectiveness of some methods compared to others. </details>
<details>	<summary>邮件日期</summary>	2021年06月01日</details>

# 138、基于脉冲神经网络的硅视网膜生物视觉注意模式分类
- [ ] Bio-inspired visual attention for silicon retinas based on spiking neural networks applied to pattern classification 
时间：2021年05月31日                         第一作者：Am\'elie Gruel                        [链接](https://arxiv.org/abs/2105.14753).                     
## 摘要：视觉注意可以定义为一种行为和认知过程，即有选择地集中在感官线索的一个离散方面，而忽略其他可感知的信息。这种生物机制，特别是显著性检测，长期以来被用于多媒体索引中，只对图像或视频的相关部分进行分析，以便进一步处理。最近出现的硅视网膜（或称事件摄像机——测量亮度像素级变化并相应输出异步事件的传感器）提出了一个问题，即如何使注意力和显著性适应这种传感器的非常规输出类型。硅视网膜旨在重现视网膜的生物学行为。在这方面，它们在时间上产生准时的事件，这些事件可以被解释为神经脉冲，并被神经网络解释为神经脉冲。特别是，脉冲神经网络（Spiking Neural Networks，SNNs）代表了一种比传统人工网络更接近生物学的异步型人工神经网络，主要是因为它们试图模拟神经膜和动作电位随时间的动态变化。snn以脉冲序列的形式接收和处理信息。因此，它们为硅视网膜测量的传入事件模式的有效处理和分类提供了合适的候选者。在这篇论文中，我们回顾了注意机制背后的生物学背景，并介绍了一个案例研究事件视频分类与SNNs，使用一个基于生物学的低水平计算注意机制，并有有趣的初步结果。
<details>	<summary>英文摘要</summary>	Visual attention can be defined as the behavioral and cognitive process of selectively focusing on a discrete aspect of sensory cues while disregarding other perceivable information. This biological mechanism, more specifically saliency detection, has long been used in multimedia indexing to drive the analysis only on relevant parts of images or videos for further processing. The recent advent of silicon retinas (or event cameras -- sensors that measure pixel-wise changes in brightness and output asynchronous events accordingly) raises the question of how to adapt attention and saliency to the unconventional type of such sensors' output. Silicon retina aims to reproduce the biological retina behaviour. In that respect, they produce punctual events in time that can be construed as neural spikes and interpreted as such by a neural network. In particular, Spiking Neural Networks (SNNs) represent an asynchronous type of artificial neural network closer to biology than traditional artificial networks, mainly because they seek to mimic the dynamics of neural membrane and action potentials over time. SNNs receive and process information in the form of spike trains. Therefore, they make for a suitable candidate for the efficient processing and classification of incoming event patterns measured by silicon retinas. In this paper, we review the biological background behind the attentional mechanism, and introduce a case study of event videos classification with SNNs, using a biology-grounded low-level computational attention mechanism, with interesting preliminary results. </details>
<details>	<summary>注释</summary>	6 pages, 3 figures. To be published in Content-Based Multimedia Indexing (CBMI) 2021, Lille, France. This work was supported by the European Union's ERA-NET CHIST-ERA 2018 research and innovation programme under grant agreement ANR-19-CHR3-0008 </details>
<details>	<summary>邮件日期</summary>	2021年06月01日</details>

# 137、脉冲时变塑性训练脉冲神经网络的泛化特征
- [ ] Characterization of Generalizability of Spike Time Dependent Plasticity trained Spiking Neural Networks 
时间：2021年05月31日                         第一作者：Biswadeep Chakraborty                       [链接](https://arxiv.org/abs/2105.14677).                     
## 摘要：脉冲时间依赖可塑性（STDP）训练的脉冲神经网络（SNN）是一种神经启发的无监督学习方法，适用于各种机器学习应用。本文利用学习算法轨迹的Hausdorff维数研究了STDP学习过程的概化性质。本文分析了STDP学习模型和相关超参数对SNN可概化性质的影响，刻画了SNN的可概化性与可学习性的权衡。该分析被用来开发一种贝叶斯优化方法来优化STDP模型的超参数，以提高SNN的泛化性能。
<details>	<summary>英文摘要</summary>	A Spiking Neural Network (SNN) trained with Spike Time Dependent Plasticity (STDP) is a neuro-inspired unsupervised learning method for various machine learning applications. This paper studies the generalizability properties of the STDP learning processes using the Hausdorff dimension of the trajectories of the learning algorithm. The paper analyzes the effects of STDP learning models and associated hyper-parameters on the generalizability properties of an SNN and characterizes the generalizability vs learnability trade-off in an SNN. The analysis is used to develop a Bayesian optimization approach to optimize the hyper-parameters for an STDP model to improve the generalizability properties of an SNN. </details>
<details>	<summary>注释</summary>	15 pages, submitted to Frontiers in Neuroscience. arXiv admin note: text overlap with arXiv:2010.08195, arXiv:2006.09313 by other authors </details>
<details>	<summary>邮件日期</summary>	2021年06月01日</details>

# 136、利用生物似然奖赏传播调整卷积脉冲神经网络
- [ ] Tuning Convolutional Spiking Neural Network with Biologically-plausible Reward Propagation 
时间：2021年05月31日                         第一作者：Tielin Zhang                        [链接](https://arxiv.org/abs/2010.04434).                     
<details>	<summary>注释</summary>	Final Version. Accepted by IEEE Transactions on Neural Networks and Learning Systems </details>
<details>	<summary>邮件日期</summary>	2021年06月01日</details>

# 135、在脉冲卷积神经网络中实现一个中心凹激发滤波器的初步研究
- [ ] Implementing a foveal-pit inspired filter in a Spiking Convolutional Neural Network: a preliminary study 
时间：2021年05月29日                         第一作者：Shriya T.P. Gupta                       [链接](https://arxiv.org/abs/2105.14326).                     
## 摘要：我们提出了一个脉冲卷积神经网络（SCNN），它结合了视网膜中央凹的高斯滤波器和秩序编码的启发差异。该模型是用一种适应于脉冲神经元的反向传播算法来训练的，如在Nengo库中实现的那样。我们已经在两个公开的数据集上评估了我们的模型的性能-一个用于数字识别任务，另一个用于车辆识别任务。该网络已达到90%的精度，其中损失是计算使用交叉熵函数。这是一个提高了57%左右的准确率获得的替代方法执行分类没有任何类型的神经滤波。总的来说，我们的概念验证研究表明，在现有的SCNN结构中引入生物学上合理的滤波可以很好地处理有噪声的输入图像，例如在我们的车辆识别任务中。基于我们的研究结果，我们计划通过在秩排序之前集成基于侧抑制的冗余约简来增强SCNN，这将进一步提高网络的分类精度。
<details>	<summary>英文摘要</summary>	We have presented a Spiking Convolutional Neural Network (SCNN) that incorporates retinal foveal-pit inspired Difference of Gaussian filters and rank-order encoding. The model is trained using a variant of the backpropagation algorithm adapted to work with spiking neurons, as implemented in the Nengo library. We have evaluated the performance of our model on two publicly available datasets - one for digit recognition task, and the other for vehicle recognition task. The network has achieved up to 90% accuracy, where loss is calculated using the cross-entropy function. This is an improvement over around 57% accuracy obtained with the alternate approach of performing the classification without any kind of neural filtering. Overall, our proof-of-concept study indicates that introducing biologically plausible filtering in existing SCNN architecture will work well with noisy input images such as those in our vehicle recognition task. Based on our results, we plan to enhance our SCNN by integrating lateral inhibition-based redundancy reduction prior to rank-ordering, which will further improve the classification accuracy by the network. </details>
<details>	<summary>注释</summary>	8 pages, 8 figures, 4 tables. 2020 International Joint Conference on Neural Networks (IJCNN) ACM-class: I.2.10; I.4.5; I.4.10 DOI: 10.1109/IJCNN48605.2020.9207612 </details>
<details>	<summary>邮件日期</summary>	2021年06月01日</details>

# 134、DVS脉冲反应的中心凹激发滤波
- [ ] Foveal-pit inspired filtering of DVS spike response 
时间：2021年05月29日                         第一作者：Shriya T.P. Gupta                       [链接](https://arxiv.org/abs/2105.14331).                     
## 摘要：在本文中，我们提出了处理动态视觉传感器（DVS）记录的视觉模式与视网膜模型的基础上，中心凹坑启发差异高斯（狗）滤波器。用不同空间频率的垂直白条和黑条以恒定速度水平移动来刺激DVS传感器。由DVS传感器产生的输出脉冲被作为输入应用到一组狗过滤器，其灵感来自灵长类视觉通路的感受野结构。特别是，这些滤光片模拟了侏儒和副交感神经节细胞（视网膜的脉冲神经元）的感受野，这些细胞为中央凹的光受体服务。用中心凹模型提取的特征被用于进一步的分类，使用了一个适应于脉冲神经网络的反向传播变量训练的脉冲卷积神经网络。
<details>	<summary>英文摘要</summary>	In this paper, we present results of processing Dynamic Vision Sensor (DVS) recordings of visual patterns with a retinal model based on foveal-pit inspired Difference of Gaussian (DoG) filters. A DVS sensor was stimulated with varying number of vertical white and black bars of different spatial frequencies moving horizontally at a constant velocity. The output spikes generated by the DVS sensor were applied as input to a set of DoG filters inspired by the receptive field structure of the primate visual pathway. In particular, these filters mimic the receptive fields of the midget and parasol ganglion cells (spiking neurons of the retina) that sub-serve the photo-receptors of the foveal-pit. The features extracted with the foveal-pit model are used for further classification using a spiking convolutional neural network trained with a backpropagation variant adapted for spiking neural networks. </details>
<details>	<summary>注释</summary>	6 pages, 4 figures, 2 tables. 2021 55th Annual Conference on Information Sciences and Systems (CISS), 2021 ACM-class: I.2.10; I.4.5; I.4.10 DOI: 10.1109/CISS50987.2021.9400245 </details>
<details>	<summary>邮件日期</summary>	2021年06月01日</details>

# 133、基于突触级强化学习的无梯度神经网络训练
- [ ] Gradient-Free Neural Network Training via Synaptic-Level Reinforcement Learning 
时间：2021年05月29日                         第一作者：Aman Bhargava                       [链接](https://arxiv.org/abs/2105.14383).                     
## 摘要：神经信息处理中的一个持续挑战是：神经元如何调整它们的连接性以随着时间的推移提高任务绩效（即实现学习）？人们普遍认为，在实现学习的特定大脑区域有一个一致的、突触水平的学习机制。然而，这一机制的确切性质仍不清楚。本文提出了一种基于强化学习（RL）的多层感知器（MLP）模型的简单突触级学习策略。在该算法中，每个MLP突触的动作空间由对突触权重的微小增加、减少或零动作组成，每个突触的状态由最后两个动作和奖赏信号组成。二元奖励信号表示任务绩效的改善或恶化。相对于自适应策略，静态策略产生更好的训练效果，并且与激活函数、网络形状和任务无关。训练mlp产生的字符识别性能可与梯度下降训练的同形网络相媲美。0隐单位字符识别测试的平均验证准确率为88.28%，比用梯度下降法训练的同一MLP高1.86$\pm$0.47%。32个隐单位字符识别测试的平均验证准确率为88.45%，比用梯度下降法训练的同一MLP低1.11$\pm$0.79%。鲁棒性和对梯度计算的不依赖性为训练难以区分的人工神经网络（如脉冲神经网络（SNNs）和递归神经网络（RNNs））的新技术打开了大门。此外，该方法的简单性为进一步开发类似于元胞自动机的机器智能局部规则驱动的多代理连接模型提供了独特的机会。
<details>	<summary>英文摘要</summary>	An ongoing challenge in neural information processing is: how do neurons adjust their connectivity to improve task performance over time (i.e., actualize learning)? It is widely believed that there is a consistent, synaptic-level learning mechanism in specific brain regions that actualizes learning. However, the exact nature of this mechanism remains unclear. Here we propose an algorithm based on reinforcement learning (RL) to generate and apply a simple synaptic-level learning policy for multi-layer perceptron (MLP) models. In this algorithm, the action space for each MLP synapse consists of a small increase, decrease, or null action on the synapse weight, and the state for each synapse consists of the last two actions and reward signals. A binary reward signal indicates improvement or deterioration in task performance. The static policy produces superior training relative to the adaptive policy and is agnostic to activation function, network shape, and task. Trained MLPs yield character recognition performance comparable to identically shaped networks trained with gradient descent. 0 hidden unit character recognition tests yielded an average validation accuracy of 88.28%, 1.86$\pm$0.47% higher than the same MLP trained with gradient descent. 32 hidden unit character recognition tests yielded an average validation accuracy of 88.45%, 1.11$\pm$0.79% lower than the same MLP trained with gradient descent. The robustness and lack of reliance on gradient computations opens the door for new techniques for training difficult-to-differentiate artificial neural networks such as spiking neural networks (SNNs) and recurrent neural networks (RNNs). Further, the method's simplicity provides a unique opportunity for further development of local rule-driven multi-agent connectionist models for machine intelligence analogous to cellular automata. </details>
<details>	<summary>注释</summary>	10 pages, 3 figures, submitted to NeurIPS 2021 MSC-class: 68T07 ACM-class: I.2.6 </details>
<details>	<summary>邮件日期</summary>	2021年06月01日</details>

# 132、BSNN：实现人工神经网络向双稳态神经元脉冲神经网络的更快更好的转换
- [ ] BSNN: Towards Faster and Better Conversion of Artificial Neural Networks to Spiking Neural Networks with Bistable Neurons 
时间：2021年05月27日                         第一作者：Yang Li                       [链接](https://arxiv.org/abs/2105.12917).                     
## 摘要：脉冲神经网络（SNN）通过离散的二进制事件来计算和传递信息。在新兴的神经形态硬件中，它被认为比人工神经网络（ANN）在生物学上更合理、更节能。然而，由于SNN的不连续性和不可微性，训练SNN是一项相对具有挑战性的任务。最近的工作通过将ANN转换为SNN，在获得优异性能方面取得了重要进展。由于信息处理的差异，转换后的深度SNN通常会遭受严重的性能损失和较大的时延。本文分析了性能下降的原因，提出了一种新的双稳态脉冲神经网络（BSNN），解决了由相位超前和相位滞后引起的失活神经元脉冲问题。同时，基于ResNet结构的神经网络在转换时，由于快捷路径的快速传递，输出神经元的信息是不完整的。我们设计了同步神经元（SN）来帮助有效地提高性能。实验结果表明，该方法仅需1/4-1/10的时间步长即可实现几乎无损的转换。我们在具有挑战性的数据集（包括CIFAR-10（95.16%top-1）、CIFAR-100（78.12%top-1）和ImageNet（72.64%top-1））上演示了VGG16、ResNet20和ResNet34最先进的ANN-SNN转换。
<details>	<summary>英文摘要</summary>	The spiking neural network (SNN) computes and communicates information through discrete binary events. It is considered more biologically plausible and more energy-efficient than artificial neural networks (ANN) in emerging neuromorphic hardware. However, due to the discontinuous and non-differentiable characteristics, training SNN is a relatively challenging task. Recent work has achieved essential progress on an excellent performance by converting ANN to SNN. Due to the difference in information processing, the converted deep SNN usually suffers serious performance loss and large time delay. In this paper, we analyze the reasons for the performance loss and propose a novel bistable spiking neural network (BSNN) that addresses the problem of spikes of inactivated neurons (SIN) caused by the phase lead and phase lag. Also, when ResNet structure-based ANNs are converted, the information of output neurons is incomplete due to the rapid transmission of the shortcut path. We design synchronous neurons (SN) to help efficiently improve performance. Experimental results show that the proposed method only needs 1/4-1/10 of the time steps compared to previous work to achieve nearly lossless conversion. We demonstrate state-of-the-art ANN-SNN conversion for VGG16, ResNet20, and ResNet34 on challenging datasets including CIFAR-10 (95.16% top-1), CIFAR-100 (78.12% top-1), and ImageNet (72.64% top-1). </details>
<details>	<summary>邮件日期</summary>	2021年05月28日</details>

# 131、BackEISNN：一种具有自适应自反馈和平衡兴奋抑制神经元的深脉冲神经网络
- [ ] BackEISNN: A Deep Spiking Neural Network with Adaptive Self-Feedback and Balanced Excitatory-Inhibitory Neurons 
时间：2021年05月27日                         第一作者：Dongcheng Zhao                       [链接](https://arxiv.org/abs/2105.13004).                     
## 摘要：脉冲神经网络（SNNs）通过离散脉冲传递信息，在处理时空信息方面有很好的表现。由于snn的不可微性，设计性能良好的snn仍然存在困难。最近，由于梯度近似的提出，用反向传播训练的snn表现出了优越的性能。然而，对于复杂任务的处理性能，离深度神经网络还有很大的距离。我们从大脑中连接有自反馈连接的棘波神经元的自陷性中得到启发，在膜电位上应用自适应延时自反馈来调节棘波的精确度。同时，我们运用平衡的兴奋性和抑制性神经元机制来动态控制脉冲神经元的输出。结合这两种机制，我们提出了一种具有自适应自反馈和平衡兴奋和抑制神经元的深脉冲神经网络（BackEISNN）。在多个标准数据集上的实验结果表明，这两个模块不仅加快了网络的收敛速度，而且提高了精度。对于MNIST、FashionMNIST和N-MNIST数据集，我们的模型实现了最先进的性能。对于CIFAR10数据集，我们的BackEISNN在相对较轻的结构上也获得了显著的性能，与最先进的snn竞争。
<details>	<summary>英文摘要</summary>	Spiking neural networks (SNNs) transmit information through discrete spikes, which performs well in processing spatial-temporal information. Due to the non-differentiable characteristic, there still exist difficulties in designing well-performed SNNs. Recently, SNNs trained with backpropagation have shown superior performance due to the proposal of the gradient approximation. However, the performance on complex tasks is still far away from the deep neural networks. Taking inspiration from the autapse in the brain which connects the spiking neurons with a self-feedback connection, we apply an adaptive time-delayed self-feedback on the membrane potential to regulate the spike precisions. As well as, we apply the balanced excitatory and inhibitory neurons mechanism to control the spiking neurons' output dynamically. With the combination of the two mechanisms, we propose a deep spiking neural network with adaptive self-feedback and balanced excitatory and inhibitory neurons (BackEISNN). The experimental results on several standard datasets have shown that the two modules not only accelerate the convergence of the network but also improve the accuracy. For the MNIST, FashionMNIST, and N-MNIST datasets, our model has achieved state-of-the-art performance. For the CIFAR10 dataset, our BackEISNN also gets remarkable performance on a relatively light structure that competes against state-of-the-art SNNs. </details>
<details>	<summary>邮件日期</summary>	2021年05月28日</details>

# 130、基于时序神经网络的在线学习微体系结构实现框架
- [ ] A Microarchitecture Implementation Framework for Online Learning with Temporal Neural Networks 
时间：2021年05月27日                         第一作者：Harideep Nair                       [链接](https://arxiv.org/abs/2105.13262).                     
## 摘要：时间神经网络（TNNs）是一种利用时间作为资源来表示和处理信息的脉冲神经网络，类似于哺乳动物的大脑皮层。与采用单独训练和推理阶段的计算密集型深度神经网络相比，TNNs能够非常有效地进行在线增量/连续学习，是构建边缘本地感官处理单元的优秀候选。本文提出了一个用标准CMOS实现TNNs的微体系结构框架。给出了三个关键模块的门级实现：1）多突触神经元，2）多神经元列，3）基于脉冲时间依赖可塑性（STDP）的无监督和有监督在线学习算法。TNN微体系结构体现在一组特征标度方程中，用于评估任何TNN设计的门计数、面积、延迟和功耗。在45nmcmos中给出了设计的后合成结果，并证明了其在线增量学习能力。
<details>	<summary>英文摘要</summary>	Temporal Neural Networks (TNNs) are spiking neural networks that use time as a resource to represent and process information, similar to the mammalian neocortex. In contrast to compute-intensive Deep Neural Networks that employ separate training and inference phases, TNNs are capable of extremely efficient online incremental/continuous learning and are excellent candidates for building edge-native sensory processing units. This work proposes a microarchitecture framework for implementing TNNs using standard CMOS. Gate-level implementations of three key building blocks are presented: 1) multi-synapse neurons, 2) multi-neuron columns, and 3) unsupervised and supervised online learning algorithms based on Spike Timing Dependent Plasticity (STDP). The TNN microarchitecture is embodied in a set of characteristic scaling equations for assessing the gate count, area, delay and power consumption for any TNN design. Post-synthesis results (in 45nm CMOS) for the proposed designs are presented, and their online incremental learning capability is demonstrated. </details>
<details>	<summary>注释</summary>	To be published in ISVLSI 2021. arXiv admin note: substantial text overlap with arXiv:2009.00457 </details>
<details>	<summary>邮件日期</summary>	2021年05月28日</details>

# 129、用于深脉冲神经网络快速准确推理的最佳ANN-SNN转换
- [ ] Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks 
时间：2021年05月25日                         第一作者：Jianhao Ding                       [链接](https://arxiv.org/abs/2105.11654).                     
## 摘要：脉冲神经网络（Spiking Neural Networks，SNNs）作为一种受生物启发的节能神经网络，受到了研究者和工业界的广泛关注。训练深层SNN最有效的方法是通过ANN-SNN转换。然而，这种转换通常存在精度损失和推理时间长的问题，阻碍了SNN的实际应用。本文从理论上分析了ANN-SNN变换，给出了最佳变换的充分条件。为了更好地关联ANN-SNN并获得更高的准确度，我们提出了速率范数层来代替源ANN训练中的ReLU激活函数，实现了从训练的ANN到SNN的直接转换。此外，我们提出了一个最佳拟合曲线来量化源神经网络的激活值与目标SNN的实际发射率之间的拟合。结果表明，通过优化修正后的神经网络拟合曲线的上界，可以缩短推理时间，实现快速推理。我们的理论可以解释现有的快速推理工作，得到更好的结果。实验结果表明，该方法在VGG-16、PreActResNet-18和较深的结构上实现了近无损耗的转换。在典型方法能耗为0.265倍的情况下，推理速度提高了8.6倍。代码可在https://github.com/DingJianhao/OptSNNConvertion-RNL-RIL.
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNNs), as bio-inspired energy-efficient neural networks, have attracted great attentions from researchers and industry. The most efficient way to train deep SNNs is through ANN-SNN conversion. However, the conversion usually suffers from accuracy loss and long inference time, which impede the practical application of SNN. In this paper, we theoretically analyze ANN-SNN conversion and derive sufficient conditions of the optimal conversion. To better correlate ANN-SNN and get greater accuracy, we propose Rate Norm Layer to replace the ReLU activation function in source ANN training, enabling direct conversion from a trained ANN to an SNN. Moreover, we propose an optimal fit curve to quantify the fit between the activation value of source ANN and the actual firing rate of target SNN. We show that the inference time can be reduced by optimizing the upper bound of the fit curve in the revised ANN to achieve fast inference. Our theory can explain the existing work on fast reasoning and get better results. The experimental results show that the proposed method achieves near loss less conversion with VGG-16, PreActResNet-18, and deeper structures. Moreover, it can reach 8.6x faster reasoning performance under 0.265x energy consumption of the typical method. The code is available at https://github.com/DingJianhao/OptSNNConvertion-RNL-RIL. </details>
<details>	<summary>注释</summary>	9 pages, 7 figures, 2 tables. To appear in the 30th International Joint Conference on Artificial Intelligence (IJCAI 2021) </details>
<details>	<summary>邮件日期</summary>	2021年05月26日</details>

# 128、深度脉冲神经网络的梯度重排剪枝
- [ ] Pruning of Deep Spiking Neural Networks through Gradient Rewiring 
时间：2021年05月20日                         第一作者：Yanqi Chen                       [链接](https://arxiv.org/abs/2105.04916).                     
<details>	<summary>注释</summary>	9 pages, 7 figures, 4 tables. To appear in the 30th International Joint Conference on Artificial Intelligence (IJCAI 2021) </details>
<details>	<summary>邮件日期</summary>	2021年05月21日</details>

# 127、结合反向传播和STDP的半监督学习：STDP通过反向传播在脉冲神经网络中使用少量的标记数据来增强学习
- [ ] Semi-supervised learning combining backpropagation and STDP: STDP enhances learning by backpropagation with a small amount of labeled data in a spiking neural network 
时间：2021年05月19日                         第一作者：Kotaro Furuya                        [链接](https://arxiv.org/abs/2102.10530).                     
<details>	<summary>注释</summary>	9 pages, 12 figures </details>
<details>	<summary>邮件日期</summary>	2021年05月20日</details>

# 126、稀疏脉冲梯度下降
- [ ] Sparse Spiking Gradient Descent 
时间：2021年05月18日                         第一作者：Nicolas Perez-Nieves                        [链接](https://arxiv.org/abs/2105.08810).                     
## 摘要：在神经形态计算设备上模拟脉冲神经网络（Spiking Neural Networks，SNNs）由于其能耗低而受到越来越多的关注。最近的进展使得训练snn在精确度方面开始与传统的人工神经网络（ANNs）竞争，同时在神经形态硬件上运行时具有能量效率。然而，训练snn的过程仍然是基于最初为ann开发的稠密张量运算，而ann没有利用snn的时空稀疏性。我们在这里提出了第一个稀疏SNN反向传播算法，该算法实现了与当前最先进的方法相同或更好的精度，同时显著提高了速度和内存效率。我们在不同复杂度的真实数据集（时尚MNIST、神经性MNIST和海德堡数字脉冲）上展示了我们的方法的有效性，实现了高达70倍的向后传递加速，并且在不损失准确度的情况下提高了40%的内存效率。
<details>	<summary>英文摘要</summary>	There is an increasing interest in emulating Spiking Neural Networks (SNNs) on neuromorphic computing devices due to their low energy consumption. Recent advances have allowed training SNNs to a point where they start to compete with traditional Artificial Neural Networks (ANNs) in terms of accuracy, while at the same time being energy efficient when run on neuromorphic hardware. However, the process of training SNNs is still based on dense tensor operations originally developed for ANNs which do not leverage the spatiotemporally sparse nature of SNNs. We present here the first sparse SNN backpropagation algorithm which achieves the same or better accuracy as current state of the art methods while being significantly faster and more memory efficient. We show the effectiveness of our method on real datasets of varying complexity (Fashion-MNIST, Neuromophic-MNIST and Spiking Heidelberg Digits) achieving a speedup in the backward pass of up to 70x, and 40% more memory efficient, without losing accuracy. </details>
<details>	<summary>邮件日期</summary>	2021年05月20日</details>

# 125、PLSM：一种用于无意行为检测的并行化液态机
- [ ] PLSM: A Parallelized Liquid State Machine for Unintentional Action Detection 
时间：2021年05月06日                         第一作者：Dipayan Das                       [链接](https://arxiv.org/abs/2105.09909).                     
## 摘要：水库计算（RC）为在低端嵌入式系统平台上部署人工智能算法提供了一个可行的选择。液体状态机（LSM）是一种仿生RC模型，它模拟大脑皮层微电路，使用可直接在神经形态硬件上实现的脉冲神经网络（SNN）。在本文中，我们提出了一种新的并行LSM（PLSM）架构，它结合了时空读出层和模型输出的语义约束。据我们所知，这样一个公式在文献中还是第一次，它提供了一个比传统的深度学习模型计算量更轻的替代方案。此外，我们还提出了一个完整的算法来实现与GPU兼容的可并行snn和lsm。利用Oops数据集实现了PLSM模型对无意/意外视频片段进行分类。从视频中无意行为的检测实验结果可以看出，本文提出的模型优于自监督模型和完全监督的传统深度学习模型。所有实现的代码都可以在我们的存储库中找到https://github.com/anonymoussentience2020/Parallelized_LSM_for_Unintentional_Action_Recognition.
<details>	<summary>英文摘要</summary>	Reservoir Computing (RC) offers a viable option to deploy AI algorithms on low-end embedded system platforms. Liquid State Machine (LSM) is a bio-inspired RC model that mimics the cortical microcircuits and uses spiking neural networks (SNN) that can be directly realized on neuromorphic hardware. In this paper, we present a novel Parallelized LSM (PLSM) architecture that incorporates spatio-temporal read-out layer and semantic constraints on model output. To the best of our knowledge, such a formulation has been done for the first time in literature, and it offers a computationally lighter alternative to traditional deep-learning models. Additionally, we also present a comprehensive algorithm for the implementation of parallelizable SNNs and LSMs that are GPU-compatible. We implement the PLSM model to classify unintentional/accidental video clips, using the Oops dataset. From the experimental results on detecting unintentional action in video, it can be observed that our proposed model outperforms a self-supervised model and a fully supervised traditional deep learning model. All the implemented codes can be found at our repository https://github.com/anonymoussentience2020/Parallelized_LSM_for_Unintentional_Action_Recognition. </details>
<details>	<summary>邮件日期</summary>	2021年05月21日</details>

# 124、具有第一脉冲时间的快速节能神经形态深度学习
- [ ] Fast and energy-efficient neuromorphic deep learning with first-spike times 
时间：2021年05月17日                         第一作者：Julian G\"oltz                       [链接](https://arxiv.org/abs/1912.11443).                     
<details>	<summary>注释</summary>	24 pages, 11 figures </details>
<details>	<summary>邮件日期</summary>	2021年05月18日</details>

# 123、SpikE：基于SpikE的多关系图数据嵌入
- [ ] SpikE: spike-based embeddings for multi-relational graph data 
时间：2021年05月17日                         第一作者：Dominik Dold                       [链接](https://arxiv.org/abs/2104.13398).                     
<details>	<summary>注释</summary>	Accepted for publication at IJCNN 2021 </details>
<details>	<summary>邮件日期</summary>	2021年05月18日</details>

# 122、基于遗传算法的皮层脉冲神经网络多目标优化
- [ ] Multi-Objective Optimisation of Cortical Spiking Neural Networks With Genetic Algorithms 
时间：2021年05月14日                         第一作者：James Fitzgerald                        [链接](https://arxiv.org/abs/2105.06824).                     
## 摘要：脉冲神经网络（SNNs）通过神经元的全部或无脉冲活动进行通信。然而，在生物实验中，将大量SNN模型参数与观察到的神经活动模式相匹配仍然是一个挑战。以前使用遗传算法（GA）优化特定有效SNN模型的工作，使用Izhikevich神经元模型，仅限于单个参数和目标。这项工作应用了一种称为非支配排序遗传算法（NSGA-III）的遗传算法，以证明对同一SNN进行多目标优化的可行性，重点是搜索网络连接参数，以实现兴奋性和抑制性神经元类型的目标放电率，包括跨不同网络连接的稀疏性。我们表明，NSGA-III可以很容易地优化各种发射率。值得注意的是，当兴奋性神经放电率高于或等于抑制性神经元时，误差很小。此外，当连接稀疏性作为优化参数时，最优解需要稀疏的网络连接。我们还发现，对于兴奋性神经元的放电率低于抑制性神经元，误差通常较大。总的来说，我们成功地证明了对递归和稀疏SNN网络参数进行多目标遗传优化的可行性。
<details>	<summary>英文摘要</summary>	Spiking neural networks (SNNs) communicate through the all-or-none spiking activity of neurons. However, fitting the large number of SNN model parameters to observed neural activity patterns, for example, in biological experiments, remains a challenge. Previous work using genetic algorithm (GA) optimisation on a specific efficient SNN model, using the Izhikevich neuronal model, was limited to a single parameter and objective. This work applied a version of GA, called non-dominated sorting GA (NSGA-III), to demonstrate the feasibility of performing multi-objective optimisation on the same SNN, focusing on searching network connectivity parameters to achieve target firing rates of excitatory and inhibitory neuronal types, including across different network connectivity sparsity. We showed that NSGA-III could readily optimise for various firing rates. Notably, when the excitatory neural firing rates were higher than or equal to that of inhibitory neurons, the errors were small. Moreover, when connectivity sparsity was considered as a parameter to be optimised, the optimal solutions required sparse network connectivity. We also found that for excitatory neural firing rates lower than that of inhibitory neurons, the errors were generally larger. Overall, we have successfully demonstrated the feasibility of implementing multi-objective GA optimisation on network parameters of recurrent and sparse SNN. </details>
<details>	<summary>注释</summary>	In: 32nd Irish Signals and Systems Conference (ISSC) 2021 </details>
<details>	<summary>邮件日期</summary>	2021年05月17日</details>

# 121、基于基数编码的高效脉冲神经网络
- [ ] Efficient Spiking Neural Networks with Radix Encoding 
时间：2021年05月14日                         第一作者：Zhehui Wang                       [链接](https://arxiv.org/abs/2105.06943).                     
## 摘要：与传统的人工神经网络相比，脉冲神经网络（SNNs）由于其事件驱动的计算机制和用加法代替能耗加权乘法，在延迟和能量效率方面具有优势。然而，为了达到神经网络的精度，通常需要长脉冲序列来保证精度。传统上，一个脉冲序列需要大约一千个时间步才能达到与人工神经网络相似的精度。这抵消了snn带来的计算效率，因为更长的脉冲序列意味着更多的操作和更长的延迟。本文提出了一种具有超短脉冲序列的基数编码SNN。在新模型中，脉冲列车只需不到10个时间步。实验结果表明，与VGG-16网络体系结构和CIFAR-10数据集的最新研究成果相比，该方法具有25倍的加速比和1.1%的精度提高。
<details>	<summary>英文摘要</summary>	Spiking neural networks (SNNs) have advantages in latency and energy efficiency over traditional artificial neural networks (ANNs) due to its event-driven computation mechanism and replacement of energy-consuming weight multiplications with additions. However, in order to reach accuracy of its ANN counterpart, it usually requires long spike trains to ensure the accuracy. Traditionally, a spike train needs around one thousand time steps to approach similar accuracy as its ANN counterpart. This offsets the computation efficiency brought by SNNs because longer spike trains mean a larger number of operations and longer latency. In this paper, we propose a radix encoded SNN with ultra-short spike trains. In the new model, the spike train takes less than ten time steps. Experiments show that our method demonstrates 25X speedup and 1.1% increment on accuracy, compared with the state-of-the-art work on VGG-16 network architecture and CIFAR-10 dataset. </details>
<details>	<summary>邮件日期</summary>	2021年05月17日</details>

# 120、SpikeMS：用于运动分割的深脉冲神经网络
- [ ] SpikeMS: Deep Spiking Neural Network for Motion Segmentation 
时间：2021年05月13日                         第一作者：Chethan M. Parameshwara                       [链接](https://arxiv.org/abs/2105.06562).                     
## 摘要：脉冲神经网络（SNN）是所谓的第三代神经网络，它试图更紧密地匹配生物大脑的功能。它们固有地对时间数据进行编码，允许以较少的能量使用进行训练，并且当在神经形态硬件上编码时，可以非常节能。此外，它们非常适合于涉及基于事件的传感器的任务，这与SNN基于事件的特性相匹配。然而，由于算法和训练的复杂性，snn还没有像标准人工神经网络（ANNs）那样有效地应用于实际的大规模任务中。为了使情况进一步恶化，输入表示是非常规的，需要仔细分析和深入理解。在本文中，我们提出了第一个深度编码-解码器SNN体系结构\textit{SpikeMS}，用于解决以基于事件的DVS摄像机为输入的大规模运动分割问题。为了实现这一点，我们引入了一种新的时空损失公式，它包括脉冲计数和分类标签，并结合使用新的SNN反向传播技术。此外，我们还证明了\textit{SpikeMS}能够进行\textit{incremental predictions}，或者从比训练数据量更小的测试数据中进行预测。这对于为低延迟应用程序和需要快速预测的应用程序提供部分输入数据的输出是非常宝贵的。我们对来自EV-IMO、EED和MOD数据集的具有挑战性的合成和真实世界序列进行了评估，并取得了与可比较的ANN方法相当的结果，但使用的功率可能减少了50倍。
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNN) are the so-called third generation of neural networks which attempt to more closely match the functioning of the biological brain. They inherently encode temporal data, allowing for training with less energy usage and can be extremely energy efficient when coded on neuromorphic hardware. In addition, they are well suited for tasks involving event-based sensors, which match the event-based nature of the SNN. However, SNNs have not been as effectively applied to real-world, large-scale tasks as standard Artificial Neural Networks (ANNs) due to the algorithmic and training complexity. To exacerbate the situation further, the input representation is unconventional and requires careful analysis and deep understanding. In this paper, we propose \textit{SpikeMS}, the first deep encoder-decoder SNN architecture for the real-world large-scale problem of motion segmentation using the event-based DVS camera as input. To accomplish this, we introduce a novel spatio-temporal loss formulation that includes both spike counts and classification labels in conjunction with the use of new techniques for SNN backpropagation. In addition, we show that \textit{SpikeMS} is capable of \textit{incremental predictions}, or predictions from smaller amounts of test data than it is trained on. This is invaluable for providing outputs even with partial input data for low-latency applications and those requiring fast predictions. We evaluated \textit{SpikeMS} on challenging synthetic and real-world sequences from EV-IMO, EED and MOD datasets and achieving results on a par with a comparable ANN method, but using potentially 50 times less power. </details>
<details>	<summary>注释</summary>	7 pages, 6 figures, 3 tables, Under review IROS 2021 </details>
<details>	<summary>邮件日期</summary>	2021年05月17日</details>

# 119、基于深度连续局部学习的深脉冲卷积神经网络单目标定位
- [ ] Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning 
时间：2021年05月12日                         第一作者：Sami Barchid                       [链接](https://arxiv.org/abs/2105.05609).                     
## 摘要：随着神经形态硬件的出现，脉冲神经网络可以成为人工神经网络的一个很好的节能替代品。然而，使用脉冲神经网络来执行计算机视觉任务仍然是有限的，主要集中在简单的任务，如数字识别。由于针对这些任务的深脉冲神经网络的研究较少，因此很难处理更复杂的任务（如分割、目标检测）。本论文的目的是利用监督脉冲神经网络向现代计算机视觉迈出第一步。提出了一种用于灰度图像中单个目标定位的深度卷积脉冲神经网络。我们提出了一种基于decole的网络，decole是一种基于局部代理梯度学习的脉冲模型。Oxford IIIT Pet上报告的令人鼓舞的结果验证了脉冲神经网络在未来更精细的视觉任务中的应用。
<details>	<summary>英文摘要</summary>	With the advent of neuromorphic hardware, spiking neural networks can be a good energy-efficient alternative to artificial neural networks. However, the use of spiking neural networks to perform computer vision tasks remains limited, mainly focusing on simple tasks such as digit recognition. It remains hard to deal with more complex tasks (e.g. segmentation, object detection) due to the small number of works on deep spiking neural networks for these tasks. The objective of this paper is to make the first step towards modern computer vision with supervised spiking neural networks. We propose a deep convolutional spiking neural network for the localization of a single object in a grayscale image. We propose a network based on DECOLLE, a spiking model that enables local surrogate gradient-based learning. The encouraging results reported on Oxford-IIIT-Pet validates the exploitation of spiking neural networks with a supervised learning approach for more elaborate vision tasks in the future. </details>
<details>	<summary>邮件日期</summary>	2021年05月13日</details>

# 118、深度脉冲神经网络的梯度重排剪枝
- [ ] Pruning of Deep Spiking Neural Networks through Gradient Rewiring 
时间：2021年05月11日                         第一作者：Yanqi Chen                       [链接](https://arxiv.org/abs/2105.04916).                     
## 摘要：脉冲神经网络（Spiking Neural Networks，SNNs）因其在神经形态芯片上的生物合理性和高能量利用率而备受关注。由于这些芯片通常是资源受限的，因此snn的压缩在snn的实际应用中至关重要。现有的方法大多直接将人工神经网络中的剪枝方法应用于snn，忽略了ann与snn的区别，从而限制了被剪枝snn的性能。此外，这些方法只适用于浅层snn。本文受神经系统中突触形成和突触消除的启发，提出了一种基于连通性和权值的SNNs联合学习算法gradr（gradr），使我们能够在不受再训练的情况下无缝地优化网络结构。我们的关键创新是重新定义梯度到一个新的突触参数，允许通过充分利用剪枝和连接再生之间的竞争来更好地探索网络结构。实验结果表明，该方法在MNIST和CIFAR-10数据集上实现了最小的SNNs性能损失。此外，在前所未有的0.73%连通度下，其精度损失达到3.5%，显示了SNNs显著的结构细化能力。我们的工作表明，在深度snn中存在着极高的冗余度。我们的代码可从\url获得{https://github.com/Yanqi-Chen/Gradient-Rewiring}.
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNNs) have been attached great importance due to their biological plausibility and high energy-efficiency on neuromorphic chips. As these chips are usually resource-constrained, the compression of SNNs is thus crucial along the road of practical use of SNNs. Most existing methods directly apply pruning approaches in artificial neural networks (ANNs) to SNNs, which ignore the difference between ANNs and SNNs, thus limiting the performance of the pruned SNNs. Besides, these methods are only suitable for shallow SNNs. In this paper, inspired by synaptogenesis and synapse elimination in the neural system, we propose gradient rewiring (Grad R), a joint learning algorithm of connectivity and weight for SNNs, that enables us to seamlessly optimize network structure without retrain. Our key innovation is to redefine the gradient to a new synaptic parameter, allowing better exploration of network structures by taking full advantage of the competition between pruning and regrowth of connections. The experimental results show that the proposed method achieves minimal loss of SNNs' performance on MNIST and CIFAR-10 dataset so far. Moreover, it reaches a $\sim$3.5% accuracy loss under unprecedented 0.73% connectivity, which reveals remarkable structure refining capability in SNNs. Our work suggests that there exists extremely high redundancy in deep SNNs. Our codes are available at \url{https://github.com/Yanqi-Chen/Gradient-Rewiring}. </details>
<details>	<summary>注释</summary>	9 pages,7 figures. Accepted by IJCAI 2021 </details>
<details>	<summary>邮件日期</summary>	2021年05月12日</details>

# 117、神经形态处理器上多层脉冲神经网络的硬件学习
- [ ] In-Hardware Learning of Multilayer Spiking Neural Networks on a Neuromorphic Processor 
时间：2021年05月08日                         第一作者：Amar Shrestha                       [链接](https://arxiv.org/abs/2105.03649).                     
## 摘要：尽管反向传播在机器学习中有着广泛的应用，但它不能直接应用于SNN训练，在模拟生物神经元和突触的神经形态处理器上也不可行。本文提出了一种具有生物似然局部更新规则的基于脉冲的反向传播算法，并对其进行了改进以适应神经形态硬件中的约束条件。该算法在intelloihi芯片上实现，实现了移动应用中多层snn的低功耗硬件监督在线学习。我们在MNIST、Fashion MNIST、CIFAR-10和MSTAR数据集上测试了这个实现，并展示了用这个实现进行增量在线学习的可能性。
<details>	<summary>英文摘要</summary>	Although widely used in machine learning, backpropagation cannot directly be applied to SNN training and is not feasible on a neuromorphic processor that emulates biological neuron and synapses. This work presents a spike-based backpropagation algorithm with biological plausible local update rules and adapts it to fit the constraint in a neuromorphic hardware. The algorithm is implemented on Intel Loihi chip enabling low power in-hardware supervised online learning of multilayered SNNs for mobile applications. We test this implementation on MNIST, Fashion-MNIST, CIFAR-10 and MSTAR datasets with promising performance and energy-efficiency, and demonstrate a possibility of incremental online learning with the implementation. </details>
<details>	<summary>注释</summary>	6 pages, 5 figures, accepted for Design Automation Conference (DAC) 2021 </details>
<details>	<summary>邮件日期</summary>	2021年05月11日</details>

# 116、Izhikevich激发的具有兴奋和抑制输入的光电神经元用于高效能光子脉冲神经网络
- [ ] Izhikevich-Inspired Optoelectronic Neurons with Excitatory and Inhibitory Inputs for Energy-Efficient Photonic Spiking Neural Networks 
时间：2021年05月03日                         第一作者：Yun-jhu Lee                       [链接](https://arxiv.org/abs/2105.02809).                     
## 摘要：据我们所知，我们第一次设计、原型化和实验演示了一个受Izhikevich模型启发的光电脉冲神经元，该模型结合了兴奋性和抑制性光脉冲输入，并相应地产生光脉冲输出。光电神经元由三个晶体管组成，作为电脉冲电路，一个垂直腔面发射激光器（VCSEL）用于光脉冲输出，两个光电探测器用于激发和抑制光脉冲输入。附加的电容器和电阻完成了伊日克维奇启发的光电神经元，接收兴奋性和抑制性光脉冲作为其他光电神经元的输入。我们在Verilog-a中建立了一个详细的光电神经元模型，并模拟了各种情况下具有兴奋性输入和抑制性输入信号的电路级操作。实验结果与模拟结果非常相似，证明了兴奋性输入是如何触发光脉冲输出的，而抑制性输入是如何抑制光脉冲输出的。利用模拟的神经元模型，我们使用完全连接（FC）和卷积神经网络（CNN）进行了模拟。用MNIST手写体数字识别的仿真结果表明，无监督学习的识别率为90%，改进的有监督FC神经网络的识别率为97%。我们进一步设计了一个利用量子阻抗转换的纳米级光电神经元，其中200aj/脉冲输入可以触发具有10fj/脉冲的片上纳米激光器的输出。纳米级神经元在神经网络中以10 GSpikes/s的速度运行时，可以支持约80的扇出或克服19 dB的多余光损耗，与最先进的电子神经形态硬件（如Loihi和NeuroGrid）相比，这相当于100倍的吞吐量和1000倍的能效提高。
<details>	<summary>英文摘要</summary>	We designed, prototyped, and experimentally demonstrated, for the first time to our knowledge, an optoelectronic spiking neuron inspired by the Izhikevich model incorporating both excitatory and inhibitory optical spiking inputs and producing optical spiking outputs accordingly. The optoelectronic neurons consist of three transistors acting as electrical spiking circuits, a vertical-cavity surface-emitting laser (VCSEL) for optical spiking outputs, and two photodetectors for excitatory and inhibitory optical spiking inputs. Additional inclusion of capacitors and resistors complete the Izhikevich-inspired optoelectronic neurons, which receive excitatory and inhibitory optical spikes as inputs from other optoelectronic neurons. We developed a detailed optoelectronic neuron model in Verilog-A and simulated the circuit-level operation of various cases with excitatory input and inhibitory input signals. The experimental results closely resemble the simulated results and demonstrate how the excitatory inputs trigger the optical spiking outputs while the inhibitory inputs suppress the outputs. Utilizing the simulated neuron model, we conducted simulations using fully connected (FC) and convolutional neural networks (CNN). The simulation results using MNIST handwritten digits recognition show 90% accuracy on unsupervised learning and 97% accuracy on a supervised modified FC neural network. We further designed a nanoscale optoelectronic neuron utilizing quantum impedance conversion where a 200 aJ/spike input can trigger the output from on-chip nanolasers with 10 fJ/spike. The nanoscale neuron can support a fanout of ~80 or overcome 19 dB excess optical loss while running at 10 GSpikes/second in the neural network, which corresponds to 100x throughput and 1000x energy-efficiency improvement compared to state-of-art electrical neuromorphic hardware such as Loihi and NeuroGrid. </details>
<details>	<summary>注释</summary>	24 pages, 13 figures </details>
<details>	<summary>邮件日期</summary>	2021年05月07日</details>

# 115、神经形态计算中的动态可靠性管理
- [ ] Dynamic Reliability Management in Neuromorphic Computing 
时间：2021年05月05日                         第一作者：Shihao Song                       [链接](https://arxiv.org/abs/2105.02038).                     
## 摘要：神经形态计算系统利用非易失性存储器（NVM）实现高密度、低能的突触存储。操作nvm所需的电压和电流升高会导致每个神经元中基于CMOS的晶体管和硬件中的突触电路老化，使晶体管的参数偏离其标称值。激进的设备缩放增加功率密度和温度，加速老化，挑战神经形态系统的可靠运行。现有的面向可靠性的技术周期性地以固定的时间间隔消除硬件中所有神经元和突触电路的压力，假设最坏的运行条件，而不实际跟踪它们在运行时的老化情况。为了消除这些电路的应力，必须中断正常操作，这会在脉冲生成和传播中引入延迟，影响脉冲间隔，从而影响性能，例如精度。我们提出了一种新的架构技术，通过设计一个智能运行时管理器（NCRTM）来缓解神经形态系统中与老化相关的可靠性问题，该管理器在执行机器学习工作负载的过程中，针对CMOS晶体管的短期老化，动态地降低神经元和突触电路的压力，以达到可靠性目标。NCRTM仅在绝对必要时才对这些电路进行去应力处理，否则，通过将去应力操作安排在关键路径之外来降低性能影响。我们评估NCRTM与国家的最先进的机器学习工作负荷的神经形态硬件。我们的结果表明，NCRTM显著提高了神经形态硬件的可靠性，对性能的影响很小。
<details>	<summary>英文摘要</summary>	Neuromorphic computing systems uses non-volatile memory (NVM) to implement high-density and low-energy synaptic storage. Elevated voltages and currents needed to operate NVMs cause aging of CMOS-based transistors in each neuron and synapse circuit in the hardware, drifting the transistor's parameters from their nominal values. Aggressive device scaling increases power density and temperature, which accelerates the aging, challenging the reliable operation of neuromorphic systems. Existing reliability-oriented techniques periodically de-stress all neuron and synapse circuits in the hardware at fixed intervals, assuming worst-case operating conditions, without actually tracking their aging at run time. To de-stress these circuits, normal operation must be interrupted, which introduces latency in spike generation and propagation, impacting the inter-spike interval and hence, performance, e.g., accuracy. We propose a new architectural technique to mitigate the aging-related reliability problems in neuromorphic systems, by designing an intelligent run-time manager (NCRTM), which dynamically destresses neuron and synapse circuits in response to the short-term aging in their CMOS transistors during the execution of machine learning workloads, with the objective of meeting a reliability target. NCRTM de-stresses these circuits only when it is absolutely necessary to do so, otherwise reducing the performance impact by scheduling de-stress operations off the critical path. We evaluate NCRTM with state-of-the-art machine learning workloads on a neuromorphic hardware. Our results demonstrate that NCRTM significantly improves the reliability of neuromorphic hardware, with marginal impact on performance. </details>
<details>	<summary>注释</summary>	Accepted in ACM JETC </details>
<details>	<summary>邮件日期</summary>	2021年05月06日</details>

# 114、neuroxplorer1.0：一个带脉冲神经网络的可扩展架构探索框架
- [ ] NeuroXplorer 1.0: An Extensible Framework for Architectural Exploration with Spiking Neural Networks 
时间：2021年05月04日                         第一作者：Adarsha Balaji                        [链接](https://arxiv.org/abs/2105.01795).                     
## 摘要：最近，工业界和学术界都提出了许多不同的神经形态结构来执行用脉冲神经网络（SNN）设计的应用程序。因此，越来越需要一个可扩展的仿真框架来进行SNNs的架构探索，包括当今硬件的基于平台的设计，以及未来的软硬件协同设计和设计技术协同优化。我们介绍了NeuroXplorer，这是一个快速且可扩展的框架，它基于一个通用的模板来建模一个神经形态的架构，该架构可以注入给定硬件和/或技术的特定细节。NeuroXplorer可以执行低级别的周期精确架构模拟和数据流抽象的高级分析。NeuroXplorer的优化引擎可以结合面向硬件的指标，如能量、吞吐量和延迟，以及面向SNN的指标，如脉冲间隔失真和脉冲紊乱，这些指标直接影响SNN性能。我们通过许多最先进的机器学习模型的案例研究来展示NeuroXplorer的架构探索能力。
<details>	<summary>英文摘要</summary>	Recently, both industry and academia have proposed many different neuromorphic architectures to execute applications that are designed with Spiking Neural Network (SNN). Consequently, there is a growing need for an extensible simulation framework that can perform architectural explorations with SNNs, including both platform-based design of today's hardware, and hardware-software co-design and design-technology co-optimization of the future. We present NeuroXplorer, a fast and extensible framework that is based on a generalized template for modeling a neuromorphic architecture that can be infused with the specific details of a given hardware and/or technology. NeuroXplorer can perform both low-level cycle-accurate architectural simulations and high-level analysis with data-flow abstractions. NeuroXplorer's optimization engine can incorporate hardware-oriented metrics such as energy, throughput, and latency, as well as SNN-oriented metrics such as inter-spike interval distortion and spike disorder, which directly impact SNN performance. We demonstrate the architectural exploration capabilities of NeuroXplorer through case studies with many state-of-the-art machine learning models. </details>
<details>	<summary>邮件日期</summary>	2021年05月06日</details>

# 113、基于层次图像分割和关系预测的医院和实验室液体样品计算机视觉
- [ ] Computer vision for liquid samples in hospitals and medical labs using hierarchical image segmentation and relations prediction 
时间：2021年05月04日                         第一作者：Sagi Eppel                       [链接](https://arxiv.org/abs/2105.01456).                     
## 摘要：这项工作探讨了如何利用计算机视觉对透明容器（如试管、注射器、输液袋）中的医用液体样本进行图像分割和分类。处理输液、血液和尿样等液体是医学实验室和医院工作的重要组成部分。从图像中准确识别和分割液体和盛装液体的容器的能力有助于实现这些过程的自动化。现代计算机视觉通常涉及到在大量的带注释图像数据集上训练深层神经网络。这项工作提出了一个新的数据集，其中包含1300个医学样本的注释图像，包括含有液体和固体物质的血管。图像标注有液体类型（如血液、尿液）、材料相（如液体、固体、泡沫、悬浮液）、血管类型（如注射器、管子、杯子、输液瓶/袋）和血管属性（透明、不透明）。此外，容器零件（如软木塞、标签、钉子和阀门）也会进行注释。容器和材料之间的关系和层次结构也会被注释，例如哪个容器包含哪个材料，或者哪个容器相互链接或包含。在数据集上训练三个神经网络：一个网络学习检测血管，第二个网络检测每个血管内的材料和零件，第三个网络识别血管之间的关系和连通性。
<details>	<summary>英文摘要</summary>	This work explores the use of computer vision for image segmentation and classification of medical fluid samples in transparent containers (for example, tubes, syringes, infusion bags). Handling fluids such as infusion fluids, blood, and urine samples is a significant part of the work carried out in medical labs and hospitals. The ability to accurately identify and segment the liquids and the vessels that contain them from images can help in automating such processes. Modern computer vision typically involves training deep neural nets on large datasets of annotated images. This work presents a new dataset containing 1,300 annotated images of medical samples involving vessels containing liquids and solid material. The images are annotated with the type of liquid (e.g., blood, urine), the phase of the material (e.g., liquid, solid, foam, suspension), the type of vessel (e.g., syringe, tube, cup, infusion bottle/bag), and the properties of the vessel (transparent, opaque). In addition, vessel parts such as corks, labels, spikes, and valves are annotated. Relations and hierarchies between vessels and materials are also annotated, such as which vessel contains which material or which vessels are linked or contain each other. Three neural networks are trained on the dataset: One network learns to detect vessels, a second net detects the materials and parts inside each vessel, and a third net identifies relationships and connectivity between vessels. </details>
<details>	<summary>邮件日期</summary>	2021年05月05日</details>

# 112、在神经形态处理器Loihi上利用脉冲神经网络实现资源受限导航
- [ ] Simplified Klinokinesis using Spiking Neural Networks for Resource-Constrained Navigation on the Neuromorphic Processor Loihi 
时间：2021年05月04日                         第一作者：Apoorv Kishore                       [链接](https://arxiv.org/abs/2105.01358).                     
## 摘要：C。线虫通过Klingokinesis显示趋化性，蠕虫基于单个浓度传感器感知浓度，计算浓度梯度，通过梯度上升/下降到目标浓度，然后进行轮廓跟踪，从而进行觅食。仿生的实现需要具有多离子通道动力学的复杂神经元以及中间神经元来控制。虽然这是自主机器人的一项关键功能，但在英特尔的Loihi等节能神经形态硬件上实现这一功能需要对网络进行自适应，以适应特定于硬件的约束，但这一点尚未实现。在本文中，我们证明了基于klinokinesis的趋化性对Loihi的适应性，通过仅用LIF神经元实现必要的神经元动力学以及所有功能（如Heaviside函数和减法）的完全基于脉冲的实现。我们的结果表明，Loihi实现在性能方面与Python上的软件相当——无论是在觅食还是轮廓跟踪过程中。Loihi结果在噪声环境中也具有弹性。因此，我们证明了Loihi上趋化性的成功适应-现在可以结合丰富的SNN块阵列用于基于SNN的复杂机器人控制。
<details>	<summary>英文摘要</summary>	C. elegans shows chemotaxis using klinokinesis where the worm senses the concentration based on a single concentration sensor to compute the concentration gradient to perform foraging through gradient ascent/descent towards the target concentration followed by contour tracking. The biomimetic implementation requires complex neurons with multiple ion channel dynamics as well as interneurons for control. While this is a key capability of autonomous robots, its implementation on energy-efficient neuromorphic hardware like Intel's Loihi requires adaptation of the network to hardware-specific constraints, which has not been achieved. In this paper, we demonstrate the adaptation of chemotaxis based on klinokinesis to Loihi by implementing necessary neuronal dynamics with only LIF neurons as well as a complete spike-based implementation of all functions e.g. Heaviside function and subtractions. Our results show that Loihi implementation is equivalent to the software counterpart on Python in terms of performance - both during foraging and contour tracking. The Loihi results are also resilient in noisy environments. Thus, we demonstrate a successful adaptation of chemotaxis on Loihi - which can now be combined with the rich array of SNN blocks for SNN based complex robotic control. </details>
<details>	<summary>邮件日期</summary>	2021年05月05日</details>

# 111、光谱机器学习在胰腺肿块影像分类中的应用
- [ ] Spectral Machine Learning for Pancreatic Mass Imaging Classification 
时间：2021年05月03日                         第一作者：Yiming Liu                       [链接](https://arxiv.org/abs/2105.00728).                     
## 摘要：我们提出了一种新的光谱机器学习（SML）方法用于胰腺肿块的CT筛查。我们的算法是基于公共数据源，用250名患者（50名胰腺正常患者和200名胰腺异常患者）的大约30000张图像进行训练的。样本外诊断分类的准确率为94.6%，基于113例患者共约15000张图像，其中32例胰腺正常患者和81例胰腺异常患者中有26例得到正确诊断。SML能够在诊断分类中自动选择基本图像（平均每个病人5或9张图像），达到上述精度。在一台具有标准CPU运行环境的笔记本电脑上，诊断113例患者的计算时间为75秒。影响光谱学习与机器学习结合的因素包括：1）在分类训练中，利用样本协方差矩阵的几个最大特征值对应的特征向量（脉冲特征向量）来选择输入属性，只考虑原始图像的基本信息，噪声较小；2） 基于平均水平谱检验去除无关像素，在保持较高分类精度的同时，降低了对存储容量的挑战，提高了计算效率；3） 采用最先进的机器学习分类、梯度提升和随机森林。我们的方法展示了在人工智能时代胰腺肿块筛查的实用性和提高的图像诊断准确率。
<details>	<summary>英文摘要</summary>	We present a novel spectral machine learning (SML) method in screening for pancreatic mass using CT imaging. Our algorithm is trained with approximately 30,000 images from 250 patients (50 patients with normal pancreas and 200 patients with abnormal pancreas findings) based on public data sources. A test accuracy of 94.6 percents was achieved in the out-of-sample diagnosis classification based on a total of approximately 15,000 images from 113 patients, whereby 26 out of 32 patients with normal pancreas and all 81 patients with abnormal pancreas findings were correctly diagnosed. SML is able to automatically choose fundamental images (on average 5 or 9 images for each patient) in the diagnosis classification and achieve the above mentioned accuracy. The computational time is 75 seconds for diagnosing 113 patients in a laptop with standard CPU running environment. Factors that influenced high performance of a well-designed integration of spectral learning and machine learning included: 1) use of eigenvectors corresponding to several of the largest eigenvalues of sample covariance matrix (spike eigenvectors) to choose input attributes in classification training, taking into account only the fundamental information of the raw images with less noise; 2) removal of irrelevant pixels based on mean-level spectral test to lower the challenges of memory capacity and enhance computational efficiency while maintaining superior classification accuracy; 3) adoption of state-of-the-art machine learning classification, gradient boosting and random forest. Our methodology showcases practical utility and improved accuracy of image diagnosis in pancreatic mass screening in the era of AI. </details>
<details>	<summary>注释</summary>	17 pages, 3 figures MSC-class: 62P10 </details>
<details>	<summary>邮件日期</summary>	2021年05月04日</details>

# 110、Neko：探索神经形态学习规则的图书馆
- [ ] Neko: a Library for Exploring Neuromorphic Learning Rules 
时间：2021年05月01日                         第一作者：Zixuan Zhao                       [链接](https://arxiv.org/abs/2105.00324).                     
## 摘要：神经形态计算领域正处于一个积极探索的时期。虽然已经开发了许多工具来模拟神经元动力学或将深层网络转换为脉冲模型，但用于学习规则的通用软件库仍然没有得到充分的探索。这在一定程度上是由于设计新的学习规则的多样性和挑战性，从编码方法到梯度近似，从模仿贝叶斯大脑的群体方法到部署在忆阻器横杆上的约束学习算法。为了解决这一差距，我们提出了Neko，一个模块化的，可扩展的图书馆，重点是帮助设计新的学习算法。我们在三个例子中展示了Neko的实用性：在线局部学习、概率学习和模拟设备学习。我们的结果表明，Neko可以复制最先进的算法，并且在一种情况下，在精度和速度上有显著的优势。此外，它还提供了包括梯度比较在内的工具，可以帮助开发新的算法变体。Neko是一个开源的Python库，支持PyTorch和TensorFlow后端。
<details>	<summary>英文摘要</summary>	The field of neuromorphic computing is in a period of active exploration. While many tools have been developed to simulate neuronal dynamics or convert deep networks to spiking models, general software libraries for learning rules remain underexplored. This is partly due to the diverse, challenging nature of efforts to design new learning rules, which range from encoding methods to gradient approximations, from population approaches that mimic the Bayesian brain to constrained learning algorithms deployed on memristor crossbars. To address this gap, we present Neko, a modular, extensible library with a focus on aiding the design of new learning algorithms. We demonstrate the utility of Neko in three exemplar cases: online local learning, probabilistic learning, and analog on-device learning. Our results show that Neko can replicate the state-of-the-art algorithms and, in one case, lead to significant outperformance in accuracy and speed. Further, it offers tools including gradient comparison that can help develop new algorithmic variants. Neko is an open source Python library that supports PyTorch and TensorFlow backends. </details>
<details>	<summary>邮件日期</summary>	2021年05月04日</details>

# 109、一种新的脉冲神经网络近似汉明权值计算方法：一种FPGA友好结构
- [ ] A Novel Approximate Hamming Weight Computing for Spiking Neural Networks: an FPGA Friendly Architecture 
时间：2021年04月29日                         第一作者：Kaveh Akbarzadeh-Sherbaf                       [链接](https://arxiv.org/abs/2104.14594).                     
## 摘要：稀疏长二值向量的Hamming权值是许多科学应用中的重要模块，特别是在我们感兴趣的脉冲神经网络中。为了提高FPGA实现的面积和延迟，我们从突触传输失败的角度出发，提出了一种利用FPGA查找表压缩长输入向量的方法。为了评估这种方法的有效性，我们使用一个简单的线性加法器来计算压缩向量的'1'个数。我们将压缩器分为具有两级以上查找表的浅压缩器和具有两级以上查找表的深压缩器。该方法生成的体系结构显示，对于不同配置的浅层压缩器，面积和延迟分别减少了82%和35%。此外，我们的模拟结果显示，仅使用深压缩器计算一个脉冲神经网络1024位向量的汉明权值，保留了网络的混沌行为，但对学习性能影响不大。
<details>	<summary>英文摘要</summary>	Hamming weights of sparse and long binary vectors are important modules in many scientific applications, particularly in spiking neural networks that are of our interest. To improve both area and latency of their FPGA implementations, we propose a method inspired from synaptic transmission failure for exploiting FPGA lookup tables to compress long input vectors. To evaluate the effectiveness of this approach, we count the number of `1's of the compressed vector using a simple linear adder. We classify the compressors into shallow ones with up to two levels of lookup tables and deep ones with more than two levels. The architecture generated by this approach shows up to 82% and 35% reductions for different configurations of shallow compressors in area and latency respectively. Moreover, our simulation results show that calculating the Hamming weight of a 1024-bit vector of a spiking neural network by the use of only deep compressors preserves the chaotic behavior of the network while slightly impacts on the learning performance. </details>
<details>	<summary>邮件日期</summary>	2021年05月03日</details>

# 108、Hessian感知的脉冲神经网络量化
- [ ] Hessian Aware Quantization of Spiking Neural Networks 
时间：2021年04月29日                         第一作者：Hin Wai Lui                        [链接](https://arxiv.org/abs/2104.14117).                     
## 摘要：为了实现脉冲神经网络（SNNs）的低延迟、高吞吐量和能量效率优势，减少在神经形态硬件上运行时的内存和计算需求是一个重要的步骤。神经形态结构允许大规模并行计算，具有可变和局部位精度。然而，如何将不同的比特精度分配给网络的不同层或连接并非易事。在这项工作中，我们演示了分层Hessian跟踪分析如何测量损耗对层权重的任何扰动的敏感性，这可以用来指导量化SNN时特定于层的比特精度的分配。另外，目前基于梯度的SNN训练方法采用的是多状态变量的复杂神经元模型，计算效率和记忆效率都不理想。为了应对这一挑战，我们提出了一个简化的神经元模型，该模型将状态变量的数量减少了4倍，同时仍然兼容基于梯度的训练。我们发现，使用逐层位精度时对模型精度的影响与该层的Hessian轨迹密切相关。优化后的量化网络精度仅下降了0.2%，但网络规模却减小了58%。这减少了内存使用，并允许使用具有更简单数字电路的定点算法，从而提高了总体吞吐量和能源效率。
<details>	<summary>英文摘要</summary>	To achieve the low latency, high throughput, and energy efficiency benefits of Spiking Neural Networks (SNNs), reducing the memory and compute requirements when running on a neuromorphic hardware is an important step. Neuromorphic architecture allows massively parallel computation with variable and local bit-precisions. However, how different bit-precisions should be allocated to different layers or connections of the network is not trivial. In this work, we demonstrate how a layer-wise Hessian trace analysis can measure the sensitivity of the loss to any perturbation of the layer's weights, and this can be used to guide the allocation of a layer-specific bit-precision when quantizing an SNN. In addition, current gradient based methods of SNN training use a complex neuron model with multiple state variables, which is not ideal for compute and memory efficiency. To address this challenge, we present a simplified neuron model that reduces the number of state variables by 4-fold while still being compatible with gradient based training. We find that the impact on model accuracy when using a layer-wise bit-precision correlated well with that layer's Hessian trace. The accuracy of the optimal quantized network only dropped by 0.2%, yet the network size was reduced by 58%. This reduces memory usage and allows fixed-point arithmetic with simpler digital circuits to be used, increasing the overall throughput and energy efficiency. </details>
<details>	<summary>邮件日期</summary>	2021年04月30日</details>

# 107、用于语音分类的液态机中硬件友好的突触顺序和时间标度
- [ ] Hardware-Friendly Synaptic Orders and Timescales in Liquid State Machines for Speech Classification 
时间：2021年04月29日                         第一作者：Vivek Saraswat                       [链接](https://arxiv.org/abs/2104.14264).                     
## 摘要：液体状态机是一种受大脑启发的脉冲神经网络（SNNs），具有随机存储连接和仿生神经元和突触模型。为了解决时间分类问题，提出了储层计算网络作为深度神经网络的替代方法。以往的研究表明，二阶（双指数）突触波形是实现高精度的TI-46语音数字识别的关键。长时间范围（ms）仿生突触波形的提出是对紧凑且节能的神经形态硬件的挑战。在这项工作中，我们分析了突触顺序的作用，即：{\delta}（单时间步的高输出），0th（有限脉冲宽度的矩形），一阶（指数下降）和二阶（指数上升和下降）以及突触时间尺度对水库输出响应和更全面参数扫描下TI-46语音数字分类精度的影响。我们发现最佳操作点与油藏中的最佳峰值活动范围相关。此外，提出的第0级突触的表现与生物学上合理的第2级突触相当。这对电路设计者来说是一个很大的放松，因为突触是SNN内存中实现中最丰富的组件。强调了0阶synapse模拟和混合信号实现的电路优势，通过消除运算放大器和数模转换器电路，在面积和功耗方面节省了2-3个数量级。这对一个完整的神经网络实现有着重要的影响，重点在于外围限制和克服这些限制的算法简化。
<details>	<summary>英文摘要</summary>	Liquid State Machines are brain inspired spiking neural networks (SNNs) with random reservoir connectivity and bio-mimetic neuronal and synaptic models. Reservoir computing networks are proposed as an alternative to deep neural networks to solve temporal classification problems. Previous studies suggest 2nd order (double exponential) synaptic waveform to be crucial for achieving high accuracy for TI-46 spoken digits recognition. The proposal of long-time range (ms) bio-mimetic synaptic waveforms is a challenge to compact and power efficient neuromorphic hardware. In this work, we analyze the role of synaptic orders namely: {\delta} (high output for single time step), 0th (rectangular with a finite pulse width), 1st (exponential fall) and 2nd order (exponential rise and fall) and synaptic timescales on the reservoir output response and on the TI-46 spoken digits classification accuracy under a more comprehensive parameter sweep. We find the optimal operating point to be correlated to an optimal range of spiking activity in the reservoir. Further, the proposed 0th order synapses perform at par with the biologically plausible 2nd order synapses. This is substantial relaxation for circuit designers as synapses are the most abundant components in an in-memory implementation for SNNs. The circuit benefits for both analog and mixed-signal realizations of 0th order synapse are highlighted demonstrating 2-3 orders of savings in area and power consumptions by eliminating Op-Amps and Digital to Analog Converter circuits. This has major implications on a complete neural network implementation with focus on peripheral limitations and algorithmic simplifications to overcome them. </details>
<details>	<summary>邮件日期</summary>	2021年04月30日</details>

# 106、神经形态计算是图灵完备的
- [ ] Neuromorphic Computing is Turing-Complete 
时间：2021年04月28日                         第一作者：Prasanna Date                       [链接](https://arxiv.org/abs/2104.13983).                     
## 摘要：神经形态计算是一种非冯诺依曼计算范式，通过模拟人脑来执行计算。神经形态的系统是非常节能的，并且已知消耗的能量比CPU和GPU少数千倍。它们有可能在未来推动诸如自动车辆、边缘计算和物联网等关键用例。出于这个原因，它们被寻求成为未来计算领域不可或缺的一部分。神经形态系统主要用于基于脉冲的机器学习应用，尽管在图论、微分方程和基于脉冲的仿真中也有一些非机器学习的应用。这些应用表明，神经形态计算可能是通用计算能力。然而，神经形态计算的通用可计算性尚未建立。在这项工作中，我们证明了神经形态计算是图灵完备的，因此能够进行通用计算。具体来说，我们提出了一个神经形态计算模型，只有两个神经元参数（阈值和泄漏）和两个突触参数（权重和延迟）。我们设计了用于计算所有{mu}递归函数（即常数、后继函数和投影函数）和所有{mu}递归算子（即合成算子、本原递归算子和极小化算子）的神经形态电路。鉴于{\mu}-递归函数和算子正是可以用图灵机计算的函数和算子，本文建立了神经形态计算的图灵完备性。
<details>	<summary>英文摘要</summary>	Neuromorphic computing is a non-von Neumann computing paradigm that performs computation by emulating the human brain. Neuromorphic systems are extremely energy-efficient and known to consume thousands of times less power than CPUs and GPUs. They have the potential to drive critical use cases such as autonomous vehicles, edge computing and internet of things in the future. For this reason, they are sought to be an indispensable part of the future computing landscape. Neuromorphic systems are mainly used for spike-based machine learning applications, although there are some non-machine learning applications in graph theory, differential equations, and spike-based simulations. These applications suggest that neuromorphic computing might be capable of general-purpose computing. However, general-purpose computability of neuromorphic computing has not been established yet. In this work, we prove that neuromorphic computing is Turing-complete and therefore capable of general-purpose computing. Specifically, we present a model of neuromorphic computing, with just two neuron parameters (threshold and leak), and two synaptic parameters (weight and delay). We devise neuromorphic circuits for computing all the {\mu}-recursive functions (i.e., constant, successor and projection functions) and all the {\mu}-recursive operators (i.e., composition, primitive recursion and minimization operators). Given that the {\mu}-recursive functions and operators are precisely the ones that can be computed using a Turing machine, this work establishes the Turing-completeness of neuromorphic computing. </details>
<details>	<summary>邮件日期</summary>	2021年04月30日</details>

# 105、SpikE：基于SpikE的多关系图数据嵌入
- [ ] SpikE: spike-based embeddings for multi-relational graph data 
时间：2021年04月27日                         第一作者：Dominik Dold                       [链接](https://arxiv.org/abs/2104.13398).                     
## 摘要：尽管最近成功地将基于脉冲的编码与错误反向传播算法相结合，脉冲神经网络仍然主要应用于源于感觉处理的任务，操作于传统的数据结构，如视觉或听觉数据。一种在工业和研究中得到广泛应用的丰富数据表示是所谓的知识图——一种基于图的结构，其中实体被描述为节点，实体之间的关系被描述为边。像分子、社会网络和工业工厂系统这样的复杂系统可以用知识图的公共语言来描述，允许使用图嵌入算法在这些信息密集的环境中进行上下文感知的预测。我们提出了一种基于脉冲的算法，其中图中的节点由神经元群体的单脉冲时间表示，而群体之间的关系则由脉冲时间差表示。学习这种基于脉冲的嵌入只需要有关脉冲时间和脉冲时间差的知识，这与最近提出的训练脉冲神经网络的框架是一致的。所提出的模型可以很容易地映射到当前的神经形态硬件系统，从而将知识图上的推理转移到这些体系结构蓬勃发展的领域，为这项技术开辟了一个很有前途的工业应用领域。
<details>	<summary>英文摘要</summary>	Despite the recent success of reconciling spike-based coding with the error backpropagation algorithm, spiking neural networks are still mostly applied to tasks stemming from sensory processing, operating on traditional data structures like visual or auditory data. A rich data representation that finds wide application in industry and research is the so-called knowledge graph - a graph-based structure where entities are depicted as nodes and relations between them as edges. Complex systems like molecules, social networks and industrial factory systems can be described using the common language of knowledge graphs, allowing the usage of graph embedding algorithms to make context-aware predictions in these information-packed environments. We propose a spike-based algorithm where nodes in a graph are represented by single spike times of neuron populations and relations as spike time differences between populations. Learning such spike-based embeddings only requires knowledge about spike times and spike time differences, compatible with recently proposed frameworks for training spiking neural networks. The presented model is easily mapped to current neuromorphic hardware systems and thereby moves inference on knowledge graphs into a domain where these architectures thrive, unlocking a promising industrial application area for this technology. </details>
<details>	<summary>注释</summary>	Accepted for publication at IJCNN 2021 </details>
<details>	<summary>邮件日期</summary>	2021年04月29日</details>

# 104、基于稀疏脉冲卷积神经网络的事件摄像机学习
- [ ] Learning from Event Cameras with Sparse Spiking Convolutional Neural Networks 
时间：2021年04月26日                         第一作者：Lo\"ic Cordone                       [链接](https://arxiv.org/abs/2104.12579).                     
## 摘要：卷积神经网络（CNNs）由于其令人印象深刻的结果和易于学习的特点，现已成为解决计算机视觉问题的实际方法。这些网络由一层层相互连接的单元组成，这些单元被称为人工神经元，松散地模拟了生物大脑中的神经元。然而，它们在传统硬件（CPU/GPU）上的实现导致了高功耗，使得它们在嵌入式系统上的集成变得困难。以汽车为例，嵌入式算法在能量、延迟和精度方面都有很高的限制。为了设计更有效的计算机视觉算法，我们建议采用事件摄像机和脉冲神经网络（SNNs）的端到端生物启发方法。事件摄像机输出异步和稀疏的事件，提供了一个非常有效的数据源，但是用同步和密集的算法（如CNNs）处理这些事件并没有产生任何显著的好处。为了解决这一局限性，我们使用了脉冲神经网络（SNNs），这是一种更具生物真实感的神经网络，其中单位使用离散脉冲进行通信。由于它们的操作性质，它们对硬件友好且节能，但培训它们仍然是一项挑战。我们的方法使用流行的深度学习框架PyTorch，直接在事件数据上训练稀疏脉冲卷积神经网络。在流行的DVS128手势数据集上，在准确性、稀疏性和训练时间方面的性能使得这种仿生方法有可能在低功耗的神经形态硬件上嵌入实时应用程序。
<details>	<summary>英文摘要</summary>	Convolutional neural networks (CNNs) are now the de facto solution for computer vision problems thanks to their impressive results and ease of learning. These networks are composed of layers of connected units called artificial neurons, loosely modeling the neurons in a biological brain. However, their implementation on conventional hardware (CPU/GPU) results in high power consumption, making their integration on embedded systems difficult. In a car for example, embedded algorithms have very high constraints in term of energy, latency and accuracy. To design more efficient computer vision algorithms, we propose to follow an end-to-end biologically inspired approach using event cameras and spiking neural networks (SNNs). Event cameras output asynchronous and sparse events, providing an incredibly efficient data source, but processing these events with synchronous and dense algorithms such as CNNs does not yield any significant benefits. To address this limitation, we use spiking neural networks (SNNs), which are more biologically realistic neural networks where units communicate using discrete spikes. Due to the nature of their operations, they are hardware friendly and energy-efficient, but training them still remains a challenge. Our method enables the training of sparse spiking convolutional neural networks directly on event data, using the popular deep learning framework PyTorch. The performances in terms of accuracy, sparsity and training time on the popular DVS128 Gesture Dataset make it possible to use this bio-inspired approach for the future embedding of real-time applications on low-power neuromorphic hardware. </details>
<details>	<summary>注释</summary>	Accepted to the International Joint Conference on Neural Networks (IJCNN) 2021 </details>
<details>	<summary>邮件日期</summary>	2021年04月27日</details>

# 103、脉冲神经网络第二部分：时空模式检测
- [ ] Spiking Neural Networks -- Part II: Detecting Spatio-Temporal Patterns 
时间：2021年04月26日                         第一作者：Nicolas Skatchkovsky                       [链接](https://arxiv.org/abs/2010.14217).                     
<details>	<summary>注释</summary>	The first two authors have equally contributed to this work. This version corrects some errors in the published paper </details>
<details>	<summary>邮件日期</summary>	2021年04月27日</details>

# 102、STDP在联想信息存储和检索中的神经动力学作用
- [ ] Neurodynamical Role of STDP in Storage and Retrieval of Associative Information 
时间：2021年04月25日                         第一作者：Hongkyu Yoon                        [链接](https://arxiv.org/abs/2104.12249).                     
## 摘要：棘突时间依赖性可塑性（STDP）是一个生物学过程，在这个过程中，神经元棘突的精确顺序和时间影响突触修饰的程度。虽然已经有许多研究集中于STDP在神经编码中的作用，但STDP在大脑宏观层面的功能意义尚未得到充分的探索。在这项工作中，我们提出STDP在一个脉冲神经元群中呈现以“记忆平面”的形式存储高维信息。基于STDP的神经活动将周期性的时空输入模式转换为相应的记忆平面，在该记忆平面中，存储的信息可以通过适当的提示动态恢复。利用显示输入和记忆平面之间解析关系的动力系统理论，我们能够演示高维关联数据集的特定记忆过程。在自联想记忆任务中，可以从振荡的神经状态中提取连续流到系统中的一组图像。第二个应用程序处理从句子中嵌入语义记忆成分的过程。结果表明，词汇可以同时回忆多个句子，也可以只回忆一个句子，这取决于它们的语法关系。这意味着该框架易于处理多组具有复合结构的联想记忆。
<details>	<summary>英文摘要</summary>	Spike-timing-dependent plasticity (STDP) is a biological process in which the precise order and timing of neuronal spikes affect the degree of synaptic modification. While there has been numerous research focusing on the role of STDP in neural coding, the functional implications of STDP at the macroscopic level in the brain have not been fully explored yet. In this work, we propose that STDP in an ensemble of spiking neurons renders storing high dimensional information in the form of a `memory plane'. Neural activity based on STDP transforms periodic spatio-temporal input patterns into the corresponding memory plane, where the stored information can be dynamically revived with a proper cue. Using the dynamical systems theory that shows the analytic relation between the input and the memory plane, we were able to demonstrate a specific memory process for high-dimensional associative data sets. In the auto-associative memory task, a group of images that were continuously streamed to the system can be retrieved from the oscillating neural state. The second application deals with the process of semantic memory components that are embedded from sentences. The results show that words can recall multiple sentences simultaneously or one exclusively, depending on their grammatical relations. This implies that the proposed framework is apt to process multiple groups of associative memories with a composite structure. </details>
<details>	<summary>注释</summary>	14 pages of main text followed by 19 pages of supplements. Source for simplified MATLAB programs performing two numerical tests presented in this article can be found in the following link: https://github.com/hkyoon94/NRSTDP.git </details>
<details>	<summary>邮件日期</summary>	2021年04月27日</details>

# 101、基于生物激励优化器的深度神经网络学习
- [ ] Learning in Deep Neural Networks Using a Biologically Inspired Optimizer 
时间：2021年04月23日                         第一作者：Giorgia Dellaferrera                       [链接](https://arxiv.org/abs/2104.11604).                     
## 摘要：众所周知，大脑中的可塑性回路通过突触整合和突触强度的局部调节机制受到突触重量分布的影响。然而，迄今为止设计的大多数人工神经网络训练算法都忽略了刺激依赖性可塑性与局部学习信号之间的复杂相互作用。在这里，我们提出了一个新的生物启发优化人工神经网络（ANNs）和脉冲神经网络（SNNs），它结合了在皮层神经元树突中观察到的突触整合的关键原理：GRAPES（调整错误信号传播的群体责任）。GRAPES在神经网络的每个节点上对误差信号进行依赖于权值分布的调制。结果表明，这种生物激励机制使神经网络的收敛速度得到了系统的提高，并通过前馈结构和递归结构大大提高了神经网络和snn的分类精度。此外，我们证明了GRAPES支持复杂度不断增加的模型的性能可伸缩性，并通过使网络基于先前获得的知识泛化到不可见的任务来减轻灾难性遗忘。GRAPES的本地特性最小化了所需的内存资源，使其最适合专用硬件实现。总的来说，我们的工作表明协调神经生理学和机器智能是提高神经网络性能的关键。
<details>	<summary>英文摘要</summary>	Plasticity circuits in the brain are known to be influenced by the distribution of the synaptic weights through the mechanisms of synaptic integration and local regulation of synaptic strength. However, the complex interplay of stimulation-dependent plasticity with local learning signals is disregarded by most of the artificial neural network training algorithms devised so far. Here, we propose a novel biologically inspired optimizer for artificial (ANNs) and spiking neural networks (SNNs) that incorporates key principles of synaptic integration observed in dendrites of cortical neurons: GRAPES (Group Responsibility for Adjusting the Propagation of Error Signals). GRAPES implements a weight-distribution dependent modulation of the error signal at each node of the neural network. We show that this biologically inspired mechanism leads to a systematic improvement of the convergence rate of the network, and substantially improves classification accuracy of ANNs and SNNs with both feedforward and recurrent architectures. Furthermore, we demonstrate that GRAPES supports performance scalability for models of increasing complexity and mitigates catastrophic forgetting by enabling networks to generalize to unseen tasks based on previously acquired knowledge. The local characteristics of GRAPES minimize the required memory resources, making it optimally suited for dedicated hardware implementations. Overall, our work indicates that reconciling neurophysiology insights with machine intelligence is key to boosting the performance of neural networks. </details>
<details>	<summary>邮件日期</summary>	2021年04月26日</details>

# 100、膜电位和激活阈稳态的持续学习和适应
- [ ] Continuous Learning and Adaptation with Membrane Potential and Activation Threshold Homeostasis 
时间：2021年04月22日                         第一作者：Alex                       [链接](https://arxiv.org/abs/2104.10851).                     
## 摘要：大多数经典（非脉冲）神经网络模型忽略了内部神经元动力学，将神经元视为简单的输入积分器。然而，生物神经元的内部状态受复杂动力学控制，在学习、适应以及整个网络活动和行为中起着至关重要的作用。本文提出了一种膜电位和激活阈稳态（MPATH）神经元模型，该模型结合了多种生物激励机制，用一个类似于生物神经元膜时间常数的参数来有效地模拟神经元内部动力学。该模型允许神经元在输入波动时通过自动调节其活动来维持一种形式的动态平衡。MPATH模型的一个结果是，它给神经元灌输了一种时间感，而不需要反复连接，为建立依赖于神经元活动时间方面的过程模型铺平了道路。实验证明了该模型能够适应并不断地从输入中学习。
<details>	<summary>英文摘要</summary>	Most classical (non-spiking) neural network models disregard internal neuron dynamics and treat neurons as simple input integrators. However, biological neurons have an internal state governed by complex dynamics that plays a crucial role in learning, adaptation and the overall network activity and behaviour. This paper presents the Membrane Potential and Activation Threshold Homeostasis (MPATH) neuron model, which combines several biologically inspired mechanisms to efficiently simulate internal neuron dynamics with a single parameter analogous to the membrane time constant in biological neurons. The model allows neurons to maintain a form of dynamic equilibrium by automatically regulating their activity when presented with fluctuating input. One consequence of the MPATH model is that it imbues neurons with a sense of time without recurrent connections, paving the way for modelling processes that depend on temporal aspects of neuron activity. Experiments demonstrate the model's ability to adapt to and continually learn from its input. </details>
<details>	<summary>注释</summary>	19 pages </details>
<details>	<summary>邮件日期</summary>	2021年04月23日</details>

# 99、具有时间信息的抗噪声深脉冲神经网络
- [ ] Noise-Robust Deep Spiking Neural Networks with Temporal Information 
时间：2021年04月22日                         第一作者：Seongsik Park                       [链接](https://arxiv.org/abs/2104.11169).                     
## 摘要：脉冲神经网络（SNNs）是一种具有时间信息的节能神经网络。SNNs在神经形态器件上表现出了优越的效率，但是这种器件容易受到噪声的影响，阻碍了其在实际应用中的应用。一些研究提高了噪声鲁棒性，但大多数研究既没有考虑深度snn，也没有考虑时间信息。本文采用不同的神经编码方法研究了噪声对深度SNN的影响，提出了一种具有时间信息的抗噪声深度SNN。通过这些方法，我们实现了一个对脉冲删除和抖动有效且鲁棒的深度SNN。
<details>	<summary>英文摘要</summary>	Spiking neural networks (SNNs) have emerged as energy-efficient neural networks with temporal information. SNNs have shown a superior efficiency on neuromorphic devices, but the devices are susceptible to noise, which hinders them from being applied in real-world applications. Several studies have increased noise robustness, but most of them considered neither deep SNNs nor temporal information. In this paper, we investigate the effect of noise on deep SNNs with various neural coding methods and present a noise-robust deep SNN with temporal information. With the proposed methods, we have achieved a deep SNN that is efficient and robust to spike deletion and jitter. </details>
<details>	<summary>注释</summary>	Accepted to DAC 2021 </details>
<details>	<summary>邮件日期</summary>	2021年04月23日</details>

# 98、一种用于高能效目标检测的全脉冲混合神经网络
- [ ] A Fully Spiking Hybrid Neural Network for Energy-Efficient Object Detection 
时间：2021年04月21日                         第一作者：Biswadeep Chakraborty                       [链接](https://arxiv.org/abs/2104.10719).                     
## 摘要：该文提出了一种用于资源受限平台中能量有效且鲁棒的目标检测的全脉冲混合神经网络（FSHNN）。该网络结构基于卷积SNN，采用漏泄集成火灾神经元模型。该模型将无监督脉冲时变塑性（STDP）学习与反向传播（STBP）学习方法相结合，并采用蒙特卡罗方法对不确定性误差进行估计。与基于DNN的目标探测器相比，FSHNN提供了更好的精度，同时具有150倍的能效。当受到噪声输入数据和标记较少的训练数据的影响时，它的性能也优于这些目标检测器，具有较低的不确定性误差。
<details>	<summary>英文摘要</summary>	This paper proposes a Fully Spiking Hybrid Neural Network (FSHNN) for energy-efficient and robust object detection in resource-constrained platforms. The network architecture is based on Convolutional SNN using leaky-integrate-fire neuron models. The model combines unsupervised Spike Time-Dependent Plasticity (STDP) learning with back-propagation (STBP) learning methods and also uses Monte Carlo Dropout to get an estimate of the uncertainty error. FSHNN provides better accuracy compared to DNN based object detectors while being 150X energy-efficient. It also outperforms these object detectors, when subjected to noisy input data and less labeled training data with a lower uncertainty error. </details>
<details>	<summary>注释</summary>	10 pages, Submitted Manuscript </details>
<details>	<summary>邮件日期</summary>	2021年04月23日</details>

# 97、时间模式学习的神经形态算法硬件协同设计
- [ ] Neuromorphic Algorithm-hardware Codesign for Temporal Pattern Learning 
时间：2021年04月21日                         第一作者：Haowen Fang                       [链接](https://arxiv.org/abs/2104.10712).                     
## 摘要：神经形态计算和脉冲神经网络（SNN）模拟生物系统的行为，以其高能量效率完成认知任务的潜力引起了人们的兴趣。然而，时间动力学和脉冲计时等因素对信息处理至关重要，但往往被现有的研究所忽视，限制了神经形态计算的性能和应用。一方面，由于缺乏有效的SNN训练算法，很难利用时态神经动力学。许多现有的算法仍然统计处理神经元激活。另一方面，利用时间神经动力学也对硬件设计提出了挑战。突触表现出时间的动态性，作为保存历史信息的记忆单位，但通常被简化为与重量的联系。目前大多数的模型将突触激活整合到一些存储介质中，以表示膜电位，并在神经元发出脉冲信号后重新设置膜电位。这样做是因为它的硬件简单，只需要一个“清晰”的信号来擦除存储介质，但会破坏存储在神经元中的时间信息。在这项工作中，我们提出了一个有效的训练算法，可以训练SNN学习复杂的时空模式。我们在两个复杂的数据集上获得了有竞争力的精确度。我们还通过一个新的时间模式关联任务证明了该模型的优越性。利用该算法，我们开发了一个基于记忆器的神经元和突触网络的CMOS电路实现，该网络保留了关键的神经动力学特性，降低了复杂度。对神经元模型的电路实现进行了仿真，验证了该模型对具有自适应阈值的时间脉冲模式的反应能力。
<details>	<summary>英文摘要</summary>	Neuromorphic computing and spiking neural networks (SNN) mimic the behavior of biological systems and have drawn interest for their potential to perform cognitive tasks with high energy efficiency. However, some factors such as temporal dynamics and spike timings prove critical for information processing but are often ignored by existing works, limiting the performance and applications of neuromorphic computing. On one hand, due to the lack of effective SNN training algorithms, it is difficult to utilize the temporal neural dynamics. Many existing algorithms still treat neuron activation statistically. On the other hand, utilizing temporal neural dynamics also poses challenges to hardware design. Synapses exhibit temporal dynamics, serving as memory units that hold historical information, but are often simplified as a connection with weight. Most current models integrate synaptic activations in some storage medium to represent membrane potential and institute a hard reset of membrane potential after the neuron emits a spike. This is done for its simplicity in hardware, requiring only a "clear" signal to wipe the storage medium, but destroys temporal information stored in the neuron. In this work, we derive an efficient training algorithm for Leaky Integrate and Fire neurons, which is capable of training a SNN to learn complex spatial temporal patterns. We achieved competitive accuracy on two complex datasets. We also demonstrate the advantage of our model by a novel temporal pattern association task. Codesigned with this algorithm, we have developed a CMOS circuit implementation for a memristor-based network of neuron and synapses which retains critical neural dynamics with reduced complexity. This circuit implementation of the neuron model is simulated to demonstrate its ability to react to temporal spiking patterns with an adaptive threshold. </details>
<details>	<summary>邮件日期</summary>	2021年04月23日</details>

# 96、脉冲神经网络无监督模式识别的权值散度易化原理
- [ ] The principle of weight divergence facilitation for unsupervised pattern recognition in spiking neural networks 
时间：2021年04月20日                         第一作者：Oleg Nikitin                       [链接](https://arxiv.org/abs/2104.09943).                     
## 摘要：信号处理任务和生物神经元之间的相似性使我们理解了输入信号识别的自组织优化原理。在本文中，我们讨论了生物系统和技术系统之间的相似性。我们建议在众所周知的STDP突触可塑性规则的基础上，将权值调整指向与背景噪声和相关信号之间的最大差异相关的状态。物理约束的重量增长原理被用作控制重量变化的基础。有人提出，生物突触的直接修饰受到可塑性发育所需的生化物质的存在和产生的限制。本文利用信噪比信息来控制这类物质的产生和储存，并驱动神经元的突触压力达到信噪比最佳的状态。通过几个不同输入信号模式的实验来了解该方法的功能。
<details>	<summary>英文摘要</summary>	Parallels between the signal processing tasks and biological neurons lead to an understanding of the principles of self-organized optimization of input signal recognition. In the present paper, we discuss such similarities among biological and technical systems. We propose the addition to the well-known STDP synaptic plasticity rule to directs the weight modification towards the state associated with the maximal difference between the background noise and correlated signals. The principle of physically constrained weight growth is used as a basis for such control of the modification of the weights. It is proposed, that biological synaptic straight modification is restricted by the existence and production of bio-chemical 'substances' needed for plasticity development. In this paper, the information about the noise-to-signal ratio is used to control such a substances' production and storage and to drive the neuron's synaptic pressures towards the state with the best signal-to-noise ratio. Several experiments with different input signal regimes are considered to understand the functioning of the proposed approach. </details>
<details>	<summary>注释</summary>	9 pages, 5 figures, submitted to the conference ICANN 2021 MSC-class: 68T05 ACM-class: I.2.6 </details>
<details>	<summary>邮件日期</summary>	2021年04月21日</details>

# 95、脉冲神经网络的基本组成模型
- [ ] A Basic Compositional Model for Spiking Neural Networks 
时间：2021年04月20日                         第一作者：Nancy Lynch                        [链接](https://arxiv.org/abs/1808.03884).                     
<details>	<summary>邮件日期</summary>	2021年04月21日</details>

# 94、基于原始语音训练的CNNs中间卷积层解释
- [ ] Interpreting intermediate convolutional layers of CNNs trained on raw speech 
时间：2021年04月19日                         第一作者：Ga\v{s}per Begu\v{s}                        [链接](https://arxiv.org/abs/2104.09489).                     
## 摘要：提出了一种基于原始语音数据的CNNs中间层的非监督解释与可视化技术。我们表明，在每个卷积层的ReLU激活后，对特征映射进行平均可以得到可解释的时间序列数据。提出的技术可以对中间卷积层进行声学分析。为了揭示语音中有意义的表征是如何在cnn的中间层被编码的，我们将个体的潜在变量操纵到训练范围之外的边缘水平。我们在两个模型上训练和探索内部表示——一个是裸GAN架构，另一个是ciwGAN扩展，它迫使生成器输出信息数据，并导致出现有语言意义的表示。对语音的三个基本声学特性进行了解释和可视化：周期振动（对应元音）、非周期噪声振动（对应擦音）和沉默（对应停止）。我们还认为，所提出的技术允许对中间层进行声学分析，这与对人类语音数据的声学分析类似：我们可以从中间层提取F0、强度、持续时间、共振峰和其他声学特性，以便测试CNNs在何处以及如何编码各种类型的信息。这些模型是在两个不同复杂度的语音过程上训练的：一个简单的[s]和一个计算复杂的重叠（复制材料）。观察插值和中间层变化之间的因果关系可以揭示单个变量如何转化为中间层激活的脉冲。利用这种技术，我们可以分析语音中有意义的单位是如何在不同的卷积层中被编码的。
<details>	<summary>英文摘要</summary>	This paper presents a technique to interpret and visualize intermediate layers in CNNs trained on raw speech data in an unsupervised manner. We show that averaging over feature maps after ReLU activation in each convolutional layer yields interpretable time-series data. The proposed technique enables acoustic analysis of intermediate convolutional layers. To uncover how meaningful representation in speech gets encoded in intermediate layers of CNNs, we manipulate individual latent variables to marginal levels outside of the training range. We train and probe internal representations on two models -- a bare GAN architecture and a ciwGAN extension which forces the Generator to output informative data and results in emergence of linguistically meaningful representations. Interpretation and visualization is performed for three basic acoustic properties of speech: periodic vibration (corresponding to vowels), aperiodic noise vibration (corresponding to fricatives), and silence (corresponding to stops). We also argue that the proposed technique allows acoustic analysis of intermediate layers that parallels the acoustic analysis of human speech data: we can extract F0, intensity, duration, formants, and other acoustic properties from intermediate layers in order to test where and how CNNs encode various types of information. The models are trained on two speech processes with different degrees of complexity: a simple presence of [s] and a computationally complex presence of reduplication (copied material). Observing the causal effect between interpolation and the resulting changes in intermediate layers can reveal how individual variables get transformed into spikes in activation in intermediate layers. Using the proposed technique, we can analyze how linguistically meaningful units in speech get encoded in different convolutional layers. </details>
<details>	<summary>邮件日期</summary>	2021年04月20日</details>

# 93、一种新的视觉处理器神经元模型
- [ ] A Novel Neuron Model of Visual Processor 
时间：2021年04月15日                         第一作者：Jizhao Liu                       [链接](https://arxiv.org/abs/2104.07257).                     
## 摘要：模拟和模仿人类或哺乳动物的神经网络是模式识别和计算机视觉领域多年来研究的热点。受猫初级视皮层神经元传导特性的启发，脉冲耦合神经网络（PCNNs）可以表现出同步振荡行为，无需训练即可处理数字图像。然而，根据对猫初级视皮层单个细胞的研究，当一个神经元受到外部周期性信号的刺激时，脉冲间间隔（ISI）分布表现为多峰分布。这种现象不能用所有的PCNN模型来解释。通过分析PCNN的工作机制，提出了一种新的由连续耦合神经网络（CCNN）构成的初级视皮层神经元模型。该模型继承了原PCNN模型的阈值指数衰减和同步脉冲振荡特性，能表现出与猫初级视皮层神经元测试结果一致的混沌行为。因此，我们的CCNN模型更接近真实的视觉神经网络。对于图像分割任务，基于CCNN模型的算法比现有的视觉皮层神经网络模型具有更好的性能。我们的方法的优势在于，它有助于神经生理学家进一步了解初级视觉皮层是如何工作的，并可用于定量预测真实神经网络的时空行为。CCNN还可能激励工程师为人工智能目的创建大脑启发的深度学习网络。
<details>	<summary>英文摘要</summary>	Simulating and imitating the neuronal network of humans or mammals is a popular topic that has been explored for many years in the fields of pattern recognition and computer vision. Inspired by neuronal conduction characteristics in the primary visual cortex of cats, pulse-coupled neural networks (PCNNs) can exhibit synchronous oscillation behavior, which can process digital images without training. However, according to the study of single cells in the cat primary visual cortex, when a neuron is stimulated by an external periodic signal, the interspike-interval (ISI) distributions represent a multimodal distribution. This phenomenon cannot be explained by all PCNN models. By analyzing the working mechanism of the PCNN, we present a novel neuron model of the primary visual cortex consisting of a continuous-coupled neural network (CCNN). Our model inherited the threshold exponential decay and synchronous pulse oscillation property of the original PCNN model, and it can exhibit chaotic behavior consistent with the testing results of cat primary visual cortex neurons. Therefore, our CCNN model is closer to real visual neural networks. For image segmentation tasks, the algorithm based on CCNN model has better performance than the state-of-art of visual cortex neural network model. The strength of our approach is that it helps neurophysiologists further understand how the primary visual cortex works and can be used to quantitatively predict the temporal-spatial behavior of real neural networks. CCNN may also inspire engineers to create brain-inspired deep learning networks for artificial intelligence purposes. </details>
<details>	<summary>邮件日期</summary>	2021年04月16日</details>

# 92、与神经形态处理器兼容的误差传播脉冲神经网络
- [ ] An error-propagation spiking neural network compatible with neuromorphic processors 
时间：2021年04月12日                         第一作者：Matteo Cartiglia                       [链接](https://arxiv.org/abs/2104.05241).                     
## 摘要：脉冲神经网络在低功耗感知处理和边缘计算硬件平台的设计中显示出巨大的潜力。然而，在这种结构上实现片上学习算法仍然是一个开放的挑战，特别是对于依赖于反向传播算法的多层网络。本文提出了一种基于峰值的学习方法，该方法利用局部权值更新机制来逼近反向传播，并与模拟/数字混合神经形态电路兼容。我们介绍了一种网络结构，它使突触权值更新机制能够跨层反向传播错误信号，并提出了一种网络，该网络可以被训练来区分具有相同平均放电率但不同脉冲计时的两种基于脉冲的模式。这项工作是朝着设计超低功耗混合信号神经形态处理系统迈出的第一步，该系统具有片上学习电路，可被训练以识别不同的脉冲活动时空模式（例如，由基于事件的视觉或听觉传感器产生）。
<details>	<summary>英文摘要</summary>	Spiking neural networks have shown great promise for the design of low-power sensory-processing and edge-computing hardware platforms. However, implementing on-chip learning algorithms on such architectures is still an open challenge, especially for multi-layer networks that rely on the back-propagation algorithm. In this paper, we present a spike-based learning method that approximates back-propagation using local weight update mechanisms and which is compatible with mixed-signal analog/digital neuromorphic circuits. We introduce a network architecture that enables synaptic weight update mechanisms to back-propagate error signals across layers and present a network that can be trained to distinguish between two spike-based patterns that have identical mean firing rates, but different spike-timings. This work represents a first step towards the design of ultra-low power mixed-signal neuromorphic processing systems with on-chip learning circuits that can be trained to recognize different spatio-temporal patterns of spiking activity (e.g. produced by event-based vision or auditory sensors). </details>
<details>	<summary>注释</summary>	2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) </details>
<details>	<summary>邮件日期</summary>	2021年04月13日</details>

# 91、实值输入到脉冲序列的自适应转换
- [ ] Adaptive conversion of real-valued input into spike trains 
时间：2021年04月12日                         第一作者：Alex                       [链接](https://arxiv.org/abs/2104.05401).                     
## 摘要：本文提出了一种生物学上可行的方法，将实值输入转化为脉冲序列，用脉冲神经网络进行处理。所提出的方法模仿视网膜神经节细胞的适应性行为，并允许输入神经元适应其对输入统计量变化的反应。因此，输入层不是被动地接收值并将其转发到隐藏层和输出层，而是充当一个自我调节滤波器，它强调与平均值的偏差，同时允许输入神经元对平均值本身有效地脱敏。该方法的另一个优点是每个变量只需要一个输入神经元，而不是像常用的基于高斯感受野的转换方法那样需要整个神经元群。此外，由于输入的统计数据随着时间的推移而自然出现，因此在将数据馈送到网络之前不必对其进行预处理。这使得脉冲神经网络能够处理原始的、非标准化的流数据。通过概念验证实验验证了该方法的有效性。
<details>	<summary>英文摘要</summary>	This paper presents a biologically plausible method for converting real-valued input into spike trains for processing with spiking neural networks. The proposed method mimics the adaptive behaviour of retinal ganglion cells and allows input neurons to adapt their response to changes in the statistics of the input. Thus, rather than passively receiving values and forwarding them to the hidden and output layers, the input layer acts as a self-regulating filter which emphasises deviations from the average while allowing the input neurons to become effectively desensitised to the average itself. Another merit of the proposed method is that it requires only one input neuron per variable, rather than an entire population of neurons as in the case of the commonly used conversion method based on Gaussian receptive fields. In addition, since the statistics of the input emerge naturally over time, it becomes unnecessary to pre-process the data before feeding it to the network. This enables spiking neural networks to process raw, non-normalised streaming data. A proof-of-concept experiment is performed to demonstrate that the proposed method operates as expected. </details>
<details>	<summary>注释</summary>	8 pages Journal-ref: 2016 International Joint Conference on Neural Networks DOI: 10.1109/IJCNN.2016.7727314 </details>
<details>	<summary>邮件日期</summary>	2021年04月13日</details>

# 90、PrivateSNN：完全隐私保护的脉冲神经网络
- [ ] PrivateSNN: Fully Privacy-Preserving Spiking Neural Networks 
时间：2021年04月07日                         第一作者：Youngeun Kim                       [链接](https://arxiv.org/abs/2104.03414).                     
## 摘要：我们如何在边缘设备上为神经系统带来隐私和能源效率？在本文中，我们提出了PrivateSNN，其目的是从预先训练好的ANN模型中构建低功耗的脉冲神经网络（SNNs），而不泄漏数据集中包含的敏感信息。在这里，我们解决两种类型的泄漏问题：1）在ANN-SNN转换过程中，网络访问真实训练数据时引起的数据泄漏。2） 类泄漏是由网络参数重构类相关特征时产生的泄漏的概念。为了解决数据泄漏问题，我们从预训练的神经网络生成合成图像，并利用生成的图像将神经网络转换为snn。然而，由于权重参数相对于ANN参数具有相同（或缩放）的值，转换后的snn对于类泄漏仍然是脆弱的。因此，我们通过使用基于时间脉冲的学习规则训练SNN来加密SNN权重。利用时间数据更新权值参数，使得网络在空间域难以解释。我们观察到，加密的PrivateSNN不仅可以在没有巨大性能下降（小于~5%）的情况下实现，而且具有显著的能量效率增益（与标准ANN相比大约x60）。我们在各种数据集上进行了广泛的实验，包括CIFAR10、CIFAR100和tinyimagnet，强调了隐私保护SNN训练的重要性。
<details>	<summary>英文摘要</summary>	How can we bring both privacy and energy-efficiency to a neural system on edge devices? In this paper, we propose PrivateSNN, which aims to build low-power Spiking Neural Networks (SNNs) from a pre-trained ANN model without leaking sensitive information contained in a dataset. Here, we tackle two types of leakage problems: 1) Data leakage caused when the networks access real training data during an ANN-SNN conversion process. 2) Class leakage is the concept of leakage caused when class-related features can be reconstructed from network parameters. In order to address the data leakage issue, we generate synthetic images from the pre-trained ANNs and convert ANNs to SNNs using generated images. However, converted SNNs are still vulnerable with respect to the class leakage since the weight parameters have the same (or scaled) value with respect to ANN parameters. Therefore, we encrypt SNN weights by training SNNs with a temporal spike-based learning rule. Updating weight parameters with temporal data makes networks difficult to be interpreted in the spatial domain. We observe that the encrypted PrivateSNN can be implemented not only without the huge performance drop (less than ~5%) but also with significant energy-efficiency gain (about x60 compared to the standard ANN). We conduct extensive experiments on various datasets including CIFAR10, CIFAR100, and TinyImageNet, highlighting the importance of privacy-preserving SNN training. </details>
<details>	<summary>邮件日期</summary>	2021年04月09日</details>

# 89、基于神经形态立体视觉系统的实时立体深度估计
- [ ] Instantaneous Stereo Depth Estimation of Real-World Stimuli with a Neuromorphic Stereo-Vision Setup 
时间：2021年04月06日                         第一作者：Nicoletta Risi                       [链接](https://arxiv.org/abs/2104.02541).                     
## 摘要：在生物学中，立体匹配问题得到了有效的解决，即在两个不同的视图中匹配相应的特征来重建深度。然而，它仍然是经典机器视觉方法的计算瓶颈。利用事件摄像机的特性，最近提出的立体视觉脉冲神经网络（SNN）结构有可能简化立体匹配问题。一些结合事件摄像机和基于峰值的神经形态处理器的解决方案已经存在。然而，他们要么在数字硬件上模拟，要么在简化的刺激物上测试。在这项工作中，我们使用动态视觉传感器3D人体姿势数据集（DHP19）来验证一个基于大脑启发事件的立体匹配架构，该架构是在一个混合信号神经形态处理器上实现的，并具有真实世界的数据。我们的实验表明，这种由重合检测器和视差敏感神经元组成的SNN结构能够在瞬间提供对输入视差的粗略估计，从而实时检测到深度移动的刺激的存在。
<details>	<summary>英文摘要</summary>	The stereo-matching problem, i.e., matching corresponding features in two different views to reconstruct depth, is efficiently solved in biology. Yet, it remains the computational bottleneck for classical machine vision approaches. By exploiting the properties of event cameras, recently proposed Spiking Neural Network (SNN) architectures for stereo vision have the potential of simplifying the stereo-matching problem. Several solutions that combine event cameras with spike-based neuromorphic processors already exist. However, they are either simulated on digital hardware or tested on simplified stimuli. In this work, we use the Dynamic Vision Sensor 3D Human Pose Dataset (DHP19) to validate a brain-inspired event-based stereo-matching architecture implemented on a mixed-signal neuromorphic processor with real-world data. Our experiments show that this SNN architecture, composed of coincidence detectors and disparity sensitive neurons, is able to provide a coarse estimate of the input disparity instantaneously, thereby detecting the presence of a stimulus moving in depth in real-time. </details>
<details>	<summary>邮件日期</summary>	2021年04月07日</details>

# 88、乘性突触脉冲神经网络的非线性计算
- [ ] Nonlinear computations in spiking neural networks through multiplicative synapses 
时间：2021年03月31日                         第一作者：Michele Nardin                       [链接](https://arxiv.org/abs/2009.03857).                     
<details>	<summary>邮件日期</summary>	2021年04月01日</details>

# 87、在BrainScaleS-2移动系统上演示模拟推理
- [ ] Demonstrating Analog Inference on the BrainScaleS-2 Mobile System 
时间：2021年03月29日                         第一作者：Yannik Stradmann                       [链接](https://arxiv.org/abs/2103.15960).                     
## 摘要：我们提出了BrainScaleS-2mobile系统作为一个基于BrainScaleS-2asic的小型模拟推理机，并展示了它在医学心电图数据集分类方面的能力。利用ASIC的模拟网络核心实现了卷积深度神经网络的乘法累加运算。我们测量了ASIC的总能量消耗192uJ，并实现了每个心电图患者样本276us的分类时间。房颤患者在14.0（10%）假阳性时的检出率为93.7%（7%）。该系统具有体积小、功耗高、I/O灵活等优点，可直接应用于边缘推理应用。未来可能的应用还可以在一个BrainScaleS-2asic上，将传统的机器学习层与神经网络的在线学习结合起来。该系统已成功参与德国联邦教育和研究部（BMBF）独立评审的“Pilotinnovationswettbewerb‘Energieeffizientes KI system’”竞赛，并被证明运行可靠。
<details>	<summary>英文摘要</summary>	We present the BrainScaleS-2 mobile system as a compact analog inference engine based on the BrainScaleS-2 ASIC and demonstrate its capabilities at classifying a medical electrocardiogram dataset. The analog network core of the ASIC is utilized to perform the multiply-accumulate operations of a convolutional deep neural network. We measure a total energy consumption of 192uJ for the ASIC and achieve a classification time of 276us per electrocardiographic patient sample. Patients with atrial fibrillation are correctly identified with a detection rate of 93.7(7)% at 14.0(10)% false positives. The system is directly applicable to edge inference applications due to its small size, power envelope and flexible I/O capabilities. Possible future applications can furthermore combine conventional machine learning layers with online-learning in spiking neural networks on a single BrainScaleS-2 ASIC. The system has successfully participated and proven to operate reliably in the independently judged competition "Pilotinnovationswettbewerb 'Energieeffizientes KI-System'" of the German Federal Ministry of Education and Research (BMBF). </details>
<details>	<summary>邮件日期</summary>	2021年03月31日</details>

# 86、基于峰值模式识别的蛋白质结构库计算
- [ ] Protein Structured Reservoir computing for Spike-based Pattern Recognition 
时间：2021年03月29日                         第一作者：Karolos-Alex                       [链接](https://arxiv.org/abs/2008.03330).                     
<details>	<summary>注释</summary>	15 pages, 9 figures DOI: 10.1109/TPDS.2021.3068826 </details>
<details>	<summary>邮件日期</summary>	2021年03月30日</details>

# 85、能量衰减网络（EDeN）
- [ ] Energy Decay Network (EDeN) 
时间：2021年03月10日                         第一作者：Jamie Nicholas Shelley                       [链接](https://arxiv.org/abs/2103.15552).                     
## 摘要：本文和伴随的Python和C++框架是作者感知到的问题与狭窄的（基于歧视的）人工智能的产物。（人工智能）该框架试图通过使用共同的调节/交换值（能量）的潜在结构表达来开发经验的遗传转移，从而创建一个模型，通过遗传和实时信号处理影响，神经结构和所有单元过程相互依赖地共同发展；成功的路径是由每个时期的穗分布的稳定性来定义的，它受遗传编码的形态发育的影响偏见。这些这些原则的目的是建立一个多样化和强大的网络，能够适应一般的任务，通过在一个旨在将学习转移到其他领域的模拟训练规模的媒介。
<details>	<summary>英文摘要</summary>	This paper and accompanying Python and C++ Framework is the product of the authors perceived problems with narrow (Discrimination based) AI. (Artificial Intelligence) The Framework attempts to develop a genetic transfer of experience through potential structural expressions using a common regulation/exchange value (energy) to create a model whereby neural architecture and all unit processes are co-dependently developed by genetic and real time signal processing influences; successful routes are defined by stability of the spike distribution per epoch which is influenced by genetically encoded morphological development biases.These principles are aimed towards creating a diverse and robust network that is capable of adapting to general tasks by training within a simulation designed for transfer learning to other mediums at scale. </details>
<details>	<summary>邮件日期</summary>	2021年03月30日</details>

# 84、利用脉冲间隔对脉冲神经网络的直观解释
- [ ] Visual Explanations from Spiking Neural Networks using Interspike Intervals 
时间：2021年03月26日                         第一作者：Youngeun Kim                       [链接](https://arxiv.org/abs/2103.14441).                     
## 摘要：脉冲神经网络（SNNs）计算并与异步二进制时态事件进行通信，通过神经形态硬件可以显著节省能量。最近在训练snn方面的算法研究表明，snn在各种分类任务上都有很好的性能。然而，目前还没有一种可视化的工具来分析和解释这种时间深度SNNs的内部脉冲行为。在这篇论文中，我们提出了一个新的概念，为SNNs的生物合理的可视化，称为峰激活图（SAM）。提出的SAM避免了脉冲神经元的不可微性，不需要计算梯度来获得直观的解释。相反，SAM通过在不同的时间步长上向前传播输入峰值来计算时间可视化图。SAM通过突出显示具有短峰间期活动的神经元，产生与输入数据的每个时间步相对应的注意图。有趣的是，没有反向传播过程和类标签，SAM在捕获细粒度细节的同时突出了图像的区分区域。利用SAM，我们首次全面分析了内部脉冲在各种SNN训练配置中的工作方式，这取决于优化类型、泄漏行为，以及面对对手的例子时。
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNNs) compute and communicate with asynchronous binary temporal events that can lead to significant energy savings with neuromorphic hardware. Recent algorithmic efforts on training SNNs have shown competitive performance on a variety of classification tasks. However, a visualization tool for analysing and explaining the internal spike behavior of such temporal deep SNNs has not been explored. In this paper, we propose a new concept of bio-plausible visualization for SNNs, called Spike Activation Map (SAM). The proposed SAM circumvents the non-differentiable characteristic of spiking neurons by eliminating the need for calculating gradients to obtain visual explanations. Instead, SAM calculates a temporal visualization map by forward propagating input spikes over different time-steps. SAM yields an attention map corresponding to each time-step of input data by highlighting neurons with short inter-spike interval activity. Interestingly, without both the backpropagation process and the class label, SAM highlights the discriminative region of the image while capturing fine-grained details. With SAM, for the first time, we provide a comprehensive analysis on how internal spikes work in various SNN training configurations depending on optimization types, leak behavior, as well as when faced with adversarial examples. </details>
<details>	<summary>邮件日期</summary>	2021年03月29日</details>

# 83、基于粗糙度指数和粗糙距离的医学图像分割基准研究
- [ ] Roughness Index and Roughness Distance for Benchmarking Medical Segmentation 
时间：2021年03月23日                         第一作者：Vidhiwar Singh Rathour                       [链接](https://arxiv.org/abs/2103.12350).                     
## 摘要：医学图像分割是医学图像分析中最具挑战性的任务之一，在许多临床应用中得到了广泛的发展。现有的大多数度量方法都是先为自然图像设计，然后扩展到医学图像。虽然物体表面在医学分割和定量分析中起着重要的作用，即分析脑肿瘤表面、测量灰质体积，但现有的大多数测量方法在分析物体表面时，特别是在判断给定体积物体的表面光滑度或粗糙度或分析其表面粗糙度时，都是有限的拓扑错误。本文首先分析了现有的各种医学图像分割方法的优缺点，特别是对体数据的分割。在此基础上，提出了一个适合于医学图像分割分析和评价的粗糙度指数和粗糙度距离。我们提出的方法解决了两类分割错误，即（i）边界/曲面上的拓扑错误和（ii）边界/曲面上的不规则性。这项工作的贡献是四个方面：（i）检测表面上的不规则脉冲/孔，（ii）提出粗糙度指数来测量给定物体的表面粗糙度，（iii）提出粗糙度距离来测量两个边界/表面之间的距离，利用提出的粗糙度指数和（iv）提出一种有助于去除的算法使表面光滑的不规则的尖刺/孔。我们提出的粗糙度指数和粗糙度距离是建立在固体表面粗糙度参数已在土木工程中成功开发。
<details>	<summary>英文摘要</summary>	Medical image segmentation is one of the most challenging tasks in medical image analysis and has been widely developed for many clinical applications. Most of the existing metrics have been first designed for natural images and then extended to medical images. While object surface plays an important role in medical segmentation and quantitative analysis i.e. analyze brain tumor surface, measure gray matter volume, most of the existing metrics are limited when it comes to analyzing the object surface, especially to tell about surface smoothness or roughness of a given volumetric object or to analyze the topological errors. In this paper, we first analysis both pros and cons of all existing medical image segmentation metrics, specially on volumetric data. We then propose an appropriate roughness index and roughness distance for medical image segmentation analysis and evaluation. Our proposed method addresses two kinds of segmentation errors, i.e. (i)topological errors on boundary/surface and (ii)irregularities on the boundary/surface. The contribution of this work is four-fold: (i) detect irregular spikes/holes on a surface, (ii) propose roughness index to measure surface roughness of a given object, (iii) propose a roughness distance to measure the distance of two boundaries/surfaces by utilizing the proposed roughness index and (iv) suggest an algorithm which helps to remove the irregular spikes/holes to smooth the surface. Our proposed roughness index and roughness distance are built upon the solid surface roughness parameter which has been successfully developed in the civil engineering. </details>
<details>	<summary>注释</summary>	Paper has been accepted at BIOIMAGING2021 </details>
<details>	<summary>邮件日期</summary>	2021年03月24日</details>

# 82、论系统软件在神经形态计算能量管理中的作用
- [ ] On the Role of System Software in Energy Management of Neuromorphic Computing 
时间：2021年03月22日                         第一作者：Twisha Titirsha                       [链接](https://arxiv.org/abs/2103.12231).                     
## 摘要：最近，DYNAPs和Loihi等神经形态计算系统被引入计算机界，以提高机器学习程序的性能和能量效率，特别是那些使用脉冲神经网络（Spiking Neural Network，SNN）实现的程序。神经形态系统的系统软件的作用是对一个大型机器学习模型（例如，有许多神经元和突触）进行聚类，并将这些聚类映射到硬件的计算资源。在这项工作中，我们建立了一个神经形态硬件的能量消耗，考虑了神经元和突触所消耗的能量，以及互连上通信脉冲所消耗的能量。基于这样的公式，我们首先评估了系统软件在管理神经形态系统能量消耗方面的作用。接下来，我们提出一个简单的启发式映射方法，将神经元和突触放置到计算资源上，以减少能量消耗。我们用10个机器学习应用来评估我们的方法，并证明所提出的映射方法可以显著降低神经形态计算系统的能量消耗。
<details>	<summary>英文摘要</summary>	Neuromorphic computing systems such as DYNAPs and Loihi have recently been introduced to the computing community to improve performance and energy efficiency of machine learning programs, especially those that are implemented using Spiking Neural Network (SNN). The role of a system software for neuromorphic systems is to cluster a large machine learning model (e.g., with many neurons and synapses) and map these clusters to the computing resources of the hardware. In this work, we formulate the energy consumption of a neuromorphic hardware, considering the power consumed by neurons and synapses, and the energy consumed in communicating spikes on the interconnect. Based on such formulation, we first evaluate the role of a system software in managing the energy consumption of neuromorphic systems. Next, we formulate a simple heuristic-based mapping approach to place the neurons and synapses onto the computing resources to reduce energy consumption. We evaluate our approach with 10 machine learning applications and demonstrate that the proposed mapping approach leads to a significant reduction of energy consumption of neuromorphic computing systems. </details>
<details>	<summary>注释</summary>	To appear in 18th Computer Frontiers 2021 </details>
<details>	<summary>邮件日期</summary>	2021年03月24日</details>

# 81、皮层振荡在脉冲神经网络中实现了基于采样的计算
- [ ] Cortical oscillations implement a backbone for sampling-based computation in spiking neural networks 
时间：2021年03月22日                         第一作者：Agnes Korcsak-Gorzo                       [链接](https://arxiv.org/abs/2006.11099).                     
<details>	<summary>注释</summary>	30 pages, 11 figures </details>
<details>	<summary>邮件日期</summary>	2021年03月24日</details>

# 80、融合流网：使用传感器融合和深度融合脉冲模拟网络架构的节能光流估计
- [ ] Fusion-FlowNet: Energy-Efficient Optical Flow Estimation using Sensor Fusion and Deep Fused Spiking-Analog Network Architectures 
时间：2021年03月19日                         第一作者：Chankyu Lee                       [链接](https://arxiv.org/abs/2103.10592).                     
## 摘要：标准的基于帧的相机采样光强度帧严重影响了高速运动的运动模糊，当动态范围较大时，无法准确地感知场景。另一方面，基于事件的相机通过异步检测单个像素强度的变化来克服这些限制。但是，事件摄影机仅提供运动中像素的信息，导致数据稀疏。因此，估计像素的整体密集行为是困难的。为了解决与传感器相关的问题，我们提出了Fusion FlowNet，一个传感器融合框架，用于利用基于帧和基于事件的传感器的能量高效光流估计，利用它们的互补特性。我们提出的网络结构也是一个融合了脉冲神经网络（SNNs）和模拟神经网络（ANNs）的网络，其中每个网络分别被设计为同时处理异步事件流和基于规则帧的图像。我们的网络使用无监督学习进行端到端训练，以避免昂贵的视频注释。该方法在不同的环境（快速运动和具有挑战性的光照条件）下具有良好的通用性，并在多车辆立体事件相机（MVSEC）数据集上展示了最先进的光流预测。此外，我们的网络在网络参数数量和计算能量成本方面提供了大量的节省。
<details>	<summary>英文摘要</summary>	Standard frame-based cameras that sample light intensity frames are heavily impacted by motion blur for high-speed motion and fail to perceive scene accurately when the dynamic range is high. Event-based cameras, on the other hand, overcome these limitations by asynchronously detecting the variation in individual pixel intensities. However, event cameras only provide information about pixels in motion, leading to sparse data. Hence, estimating the overall dense behavior of pixels is difficult. To address such issues associated with the sensors, we present Fusion-FlowNet, a sensor fusion framework for energy-efficient optical flow estimation using both frame- and event-based sensors, leveraging their complementary characteristics. Our proposed network architecture is also a fusion of Spiking Neural Networks (SNNs) and Analog Neural Networks (ANNs) where each network is designed to simultaneously process asynchronous event streams and regular frame-based images, respectively. Our network is end-to-end trained using unsupervised learning to avoid expensive video annotations. The method generalizes well across distinct environments (rapid motion and challenging lighting conditions) and demonstrates state-of-the-art optical flow prediction on the Multi-Vehicle Stereo Event Camera (MVSEC) dataset. Furthermore, our network offers substantial savings in terms of the number of network parameters and computational energy cost. </details>
<details>	<summary>邮件日期</summary>	2021年03月22日</details>

# 79、皮层振荡在脉冲神经网络中实现了基于采样的计算
- [ ] Cortical oscillations implement a backbone for sampling-based computation in spiking neural networks 
时间：2021年03月19日                         第一作者：Agnes Korcsak-Gorzo                       [链接](https://arxiv.org/abs/2006.11099).                     
<details>	<summary>注释</summary>	33 pages, 11 figures </details>
<details>	<summary>邮件日期</summary>	2021年03月22日</details>

# 78、基于自适应脉冲递归神经网络的精确高效时域分类
- [ ] Accurate and efficient time-domain classification with adaptive spiking recurrent neural networks 
时间：2021年03月12日                         第一作者：Bojian Yin                       [链接](https://arxiv.org/abs/2103.12593).                     
## 摘要：受生物神经元更详细模型的启发，脉冲神经网络（Spiking neural networks，SNNs）作为一种更具生物合理性和潜在更强大的神经计算模型被研究，其目的是提取生物神经元的能量效率；然而，与传统的人工神经网络（ANNs）相比，这种网络的性能仍然很差。在这里，我们展示了一个新的替代梯度与可调和自适应脉冲神经元的循环网络相结合如何在时域的挑战性基准（如语音和手势识别）上产生snn的最新技术。这也超过了标准的经典递归神经网络（RNN）的性能，接近现代最好的人工神经网络。由于这些snn表现出稀疏脉冲，我们证明它们在理论上比具有类似性能的rnn计算效率高一到三个数量级。总之，SNNs是人工智能硬件实现的一个有吸引力的解决方案。
<details>	<summary>英文摘要</summary>	Inspired by more detailed modeling of biological neurons, Spiking neural networks (SNNs) have been investigated both as more biologically plausible and potentially more powerful models of neural computation, and also with the aim of extracting biological neurons' energy efficiency; the performance of such networks however has remained lacking compared to classical artificial neural networks (ANNs). Here, we demonstrate how a novel surrogate gradient combined with recurrent networks of tunable and adaptive spiking neurons yields state-of-the-art for SNNs on challenging benchmarks in the time-domain, like speech and gesture recognition. This also exceeds the performance of standard classical recurrent neural networks (RNNs) and approaches that of the best modern ANNs. As these SNNs exhibit sparse spiking, we show that they theoretically are one to three orders of magnitude more computationally efficient compared to RNNs with comparable performance. Together, this positions SNNs as an attractive solution for AI hardware implementations. </details>
<details>	<summary>注释</summary>	11 pages </details>
<details>	<summary>邮件日期</summary>	2021年03月24日</details>

# 77、脉冲神经元的线性约束学习
- [ ] Linear Constraints Learning for Spiking Neurons 
时间：2021年03月10日                         第一作者：Huy Le Nguyen                       [链接](https://arxiv.org/abs/2103.12564).                     
## 摘要：利用脉冲编码神经元对信息进行精确的脉冲定时编码，已经被证明比速率编码方法具有更强的计算能力。然而，现有的针对脉冲神经元的监督学习算法大多比较复杂，时间复杂度较差。针对这些局限性，我们提出了一种有监督的多脉冲学习算法，减少了所需的训练迭代次数。我们通过将大量的权值更新描述为一个线性约束满足问题来实现这一点，可以有效地解决这个问题。实验结果表明，该方法在MNIST数据集上比现有算法具有更好的效率。此外，我们提供了LIF神经元模型的分类能力的实验结果，与系统的几个参数有关。
<details>	<summary>英文摘要</summary>	Encoding information with precise spike timings using spike-coded neurons has been shown to be more computationally powerful than rate-coded approaches. However, most existing supervised learning algorithms for spiking neurons are complicated and offer poor time complexity. To address these limitations, we propose a supervised multi-spike learning algorithm which reduces the required number of training iterations. We achieve this by formulating a large number of weight updates as a linear constraint satisfaction problem, which can be solved efficiently. Experimental results show this method offers better efficiency compared to existing algorithms on the MNIST dataset. Additionally, we provide experimental results on the classification capacity of the LIF neuron model, relative to several parameters of the system. </details>
<details>	<summary>注释</summary>	17 pages, 12 figures </details>
<details>	<summary>邮件日期</summary>	2021年03月24日</details>

# 76、约束塑性储备作为神经网络频率和权值控制的一种自然方法
- [ ] Constrained plasticity reserve as a natural way to control frequency and weights in spiking neural networks 
时间：2021年03月15日                         第一作者：Oleg Nikitin                        [链接](https://arxiv.org/abs/2103.08143).                     
## 摘要：生物神经元具有自适应性，并进行复杂的计算，包括过滤冗余信息。这种处理通常与贝叶斯推理相联系。然而，最常见的神经细胞模型，包括生物学上合理的模型，如霍奇金-赫胥黎或伊兹克维奇，在单个细胞水平上并不具备预测动力学。现代的突触可塑性或互联适应规则也不能为神经元适应不断变化的输入信号强度的能力提供基础。虽然自然神经元突触生长受到蛋白质供应和循环的精确控制和限制，但广泛使用的STDP等重量校正规则在变化率和范围上是有效的无限制的。在这篇文章中，我们将介绍一种新的机制，通过抽象蛋白质储备限制的STDP生长，并通过细胞内优化算法来控制神经元放电率稳态和重量变化之间的联系。我们将展示，这些细胞动力学如何帮助神经元过滤强烈的信号，帮助神经元保持稳定的放电频率。我们还将检验这种滤波不影响神经元在无监督模式下识别相关输入的能力。这种方法可用于机器学习领域，以提高人工智能系统的鲁棒性。
<details>	<summary>英文摘要</summary>	Biological neurons have adaptive nature and perform complex computations involving the filtering of redundant information. Such processing is often associated with Bayesian inference. Yet most common models of neural cells, including biologically plausible, such as Hodgkin-Huxley or Izhikevich do not possess predictive dynamics on the level of a single cell. The modern rules of synaptic plasticity or interconnections weights adaptation also do not provide grounding for the ability of neurons to adapt to the ever-changing input signal intensity. While natural neuron synaptic growth is precisely controlled and restricted by protein supply and recycling, weight correction rules such as widely used STDP are efficiently unlimited in change rate and scale. In the present article, we will introduce new mechanics of interconnection between neuron firing rate homeostasis and weight change by means of STDP growth bounded by abstract protein reserve, controlled by the intracellular optimization algorithm. We will show, how these cellular dynamics help neurons to filter out the intense signals to help neurons keep a stable firing rate. We will also examine that such filtering does not affect the ability of neurons to recognize the correlated inputs in unsupervised mode. Such an approach might be used in the machine learning domain to improve the robustness of AI systems. </details>
<details>	<summary>注释</summary>	24 pages, 12 figures MSC-class: 68T05 ACM-class: I.2.6 </details>
<details>	<summary>邮件日期</summary>	2021年03月16日</details>

# 75、事件摄影机的时间顺序最近事件（TORE）卷
- [ ] Time-Ordered Recent Event (TORE) Volumes for Event Cameras 
时间：2021年03月10日                         第一作者：R. Wes Baldwin                       [链接](https://arxiv.org/abs/2103.06108).                     
## 摘要：事件摄像机是一种令人兴奋的新型传感器，能够以极低的延迟和宽的动态范围实现高速成像。不幸的是，大多数机器学习体系结构都不是直接处理稀疏数据的，比如从事件摄像机生成的数据。许多最先进的事件摄像机算法依赖于内插事件表示法——模糊了关键的定时信息，增加了数据量，限制了整体网络性能。本文详细介绍了一种称为时间顺序最近事件（TORE）卷的事件表示。存储卷被设计成以最小的信息丢失紧凑地存储原始峰值定时信息。这种仿生设计内存效率高，计算速度快，避免时间阻塞（即固定和预定义的帧速率），并包含来自过去数据的“本地内存”。该设计在一系列具有挑战性的任务（如事件去噪、图像重建、分类和人体姿态估计）上进行了评估，并显示出显著提高了最先进的性能。存储卷是当前使用事件表示的任何算法的易于实现的替代品。
<details>	<summary>英文摘要</summary>	Event cameras are an exciting, new sensor modality enabling high-speed imaging with extremely low-latency and wide dynamic range. Unfortunately, most machine learning architectures are not designed to directly handle sparse data, like that generated from event cameras. Many state-of-the-art algorithms for event cameras rely on interpolated event representations - obscuring crucial timing information, increasing the data volume, and limiting overall network performance. This paper details an event representation called Time-Ordered Recent Event (TORE) volumes. TORE volumes are designed to compactly store raw spike timing information with minimal information loss. This bio-inspired design is memory efficient, computationally fast, avoids time-blocking (i.e. fixed and predefined frame rates), and contains "local memory" from past data. The design is evaluated on a wide range of challenging tasks (e.g. event denoising, image reconstruction, classification, and human pose estimation) and is shown to dramatically improve state-of-the-art performance. TORE volumes are an easy-to-implement replacement for any algorithm currently utilizing event representations. </details>
<details>	<summary>邮件日期</summary>	2021年03月11日</details>

# 74、具有耐久性的脉冲神经网络到神经形态硬件的映射
- [ ] Endurance-Aware Mapping of Spiking Neural Networks to Neuromorphic Hardware 
时间：2021年03月09日                         第一作者：Twisha Titirsha                       [链接](https://arxiv.org/abs/2103.05707).                     
## 摘要：神经形态计算系统正在采用忆阻器来实现高密度和低功耗的突触存储，如硬件中的交叉阵列。这些系统在执行脉冲神经网络（SNNs）时是节能的。我们观察到记忆型纵横制中的长位线和字线是寄生电压降的主要来源，寄生电压降会造成电流不对称。通过电路仿真，我们发现了这种不对称性导致的显著耐久性变化。因此，如果临界忆阻器（耐久性较低的忆阻器）被过度利用，它们可能会导致交叉杆寿命的缩短。我们提出eSpine，这是一种新的技术，通过在映射机器学习工作负载的每个纵横杆中加入耐久性变化来提高寿命，确保具有更高激活的突触总是在具有更高耐久性的忆阻器上实现，反之亦然。eSpine分两步工作。首先，它使用Kernighan-Lin图划分算法将工作负载划分为神经元和突触的簇，每个簇可以放在一个横杆中。第二，利用粒子群优化算法（PSO）的一个实例将簇映射到分片上，通过分析簇在工作负载中的激活情况，将簇的突触放置到十字杆的忆阻器上。我们评估了一个国家的最先进的神经形态硬件模型与相变记忆（PCM）为基础的忆阻器eSpine。使用10个SNN工作负载，我们证明了有效生存期的显著改进。
<details>	<summary>英文摘要</summary>	Neuromorphic computing systems are embracing memristors to implement high density and low power synaptic storage as crossbar arrays in hardware. These systems are energy efficient in executing Spiking Neural Networks (SNNs). We observe that long bitlines and wordlines in a memristive crossbar are a major source of parasitic voltage drops, which create current asymmetry. Through circuit simulations, we show the significant endurance variation that results from this asymmetry. Therefore, if the critical memristors (ones with lower endurance) are overutilized, they may lead to a reduction of the crossbar's lifetime. We propose eSpine, a novel technique to improve lifetime by incorporating the endurance variation within each crossbar in mapping machine learning workloads, ensuring that synapses with higher activation are always implemented on memristors with higher endurance, and vice versa. eSpine works in two steps. First, it uses the Kernighan-Lin Graph Partitioning algorithm to partition a workload into clusters of neurons and synapses, where each cluster can fit in a crossbar. Second, it uses an instance of Particle Swarm Optimization (PSO) to map clusters to tiles, where the placement of synapses of a cluster to memristors of a crossbar is performed by analyzing their activation within the workload. We evaluate eSpine for a state-of-the-art neuromorphic hardware model with phase-change memory (PCM)-based memristors. Using 10 SNN workloads, we demonstrate a significant improvement in the effective lifetime. </details>
<details>	<summary>注释</summary>	Accepted for publication in IEEE Transactions on Parallel and Distributed Systems (TPDS) </details>
<details>	<summary>邮件日期</summary>	2021年03月11日</details>

# 73、一种用于无监督特征学习的高并行度类初启脉冲神经网络
- [ ] High-parallelism Inception-like Spiking Neural Networks for Unsupervised Feature Learning 
时间：2021年03月09日                         第一作者：Mingyuan Meng                       [链接](https://arxiv.org/abs/2001.01680).                     
<details>	<summary>注释</summary>	Published at Neurocomputing DOI: 10.1016/j.neucom.2021.02.027 </details>
<details>	<summary>邮件日期</summary>	2021年03月10日</details>

# 72、基于在线进化脉冲神经网络的流数据无监督异常检测
- [ ] Unsupervised Anomaly Detection in Stream Data with Online Evolving Spiking Neural Networks 
时间：2021年03月08日                         第一作者：Piotr S. Maci\k{a}g (1)                       [链接](https://arxiv.org/abs/1912.08785).                     
<details>	<summary>注释</summary>	52 pages Journal-ref: Neural Networks, Volume 139, 2021, Pages 118-139 DOI: 10.1016/j.neunet.2021.02.017 </details>
<details>	<summary>邮件日期</summary>	2021年03月10日</details>

# 71、一点点能量就有很大的帮助：高效节能，从卷积神经网络到脉冲神经网络的精确转换
- [ ] A Little Energy Goes a Long Way: Energy-Efficient, Accurate Conversion from Convolutional Neural Networks to Spiking Neural Networks 
时间：2021年03月06日                         第一作者：Dengyu Wu                       [链接](https://arxiv.org/abs/2103.00944).                     
<details>	<summary>邮件日期</summary>	2021年03月09日</details>

# 70、神经形态平台上强化学习的双记忆结构
- [ ] A Dual-Memory Architecture for Reinforcement Learning on Neuromorphic Platforms 
时间：2021年03月05日                         第一作者：Wilkie Olin-Ammentorp                       [链接](https://arxiv.org/abs/2103.04780).                     
## 摘要：强化学习（RL）是生物系统中学习的基础，并提供了一个框架来解决现实世界人工智能应用的众多挑战。RL技术的有效实现允许部署在边缘用例中的代理获得新的能力，例如改进的导航、理解复杂情况和关键决策。为了实现这个目标，我们描述了一个灵活的架构来在神经形态平台上进行强化学习。该体系结构是使用Intel神经形态处理器实现的，并演示了如何使用脉冲动力学解决各种任务。我们的研究为现实世界的RL应用提出了一个可用的节能解决方案，并证明了神经形态平台对RL问题的适用性。
<details>	<summary>英文摘要</summary>	Reinforcement learning (RL) is a foundation of learning in biological systems and provides a framework to address numerous challenges with real-world artificial intelligence applications. Efficient implementations of RL techniques could allow for agents deployed in edge-use cases to gain novel abilities, such as improved navigation, understanding complex situations and critical decision making. Towards this goal, we describe a flexible architecture to carry out reinforcement learning on neuromorphic platforms. This architecture was implemented using an Intel neuromorphic processor and demonstrated solving a variety of tasks using spiking dynamics. Our study proposes a usable energy efficient solution for real-world RL applications and demonstrates applicability of the neuromorphic platforms for RL problems. </details>
<details>	<summary>注释</summary>	20 pages, 6 figures ACM-class: I.2 </details>
<details>	<summary>邮件日期</summary>	2021年03月09日</details>

# 69、基于在线元学习的脉冲神经网络快速设备自适应
- [ ] Fast On-Device Adaptation for Spiking Neural Networks via Online-Within-Online Meta-Learning 
时间：2021年02月21日                         第一作者：Bleema Rosenfeld                       [链接](https://arxiv.org/abs/2103.03901).                     
## 摘要：脉冲神经网络（Spiking Neural Networks，SNNs）由于其低功耗特性，近年来在移动医疗管理和自然语言处理等应用中作为边缘智能的机器学习模型得到了广泛的应用。在这种高度个人化的用例中，模型必须能够用最少的训练数据来适应个体的独特特征。元学习被认为是一种训练模型的方法，这种模型能够快速适应新的任务。为数不多的现有snn元学习解决方案离线运行，并且需要某种形式的反向传播，这与当前的神经形态边缘设备不兼容。在这篇论文中，我们提出了一个SNN的在线内在线元学习规则OWOML-SNN，它能够在任务流上实现终身学习，并且依赖于本地的、无后台的、嵌套的更新。
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNNs) have recently gained popularity as machine learning models for on-device edge intelligence for applications such as mobile healthcare management and natural language processing due to their low power profile. In such highly personalized use cases, it is important for the model to be able to adapt to the unique features of an individual with only a minimal amount of training data. Meta-learning has been proposed as a way to train models that are geared towards quick adaptation to new tasks. The few existing meta-learning solutions for SNNs operate offline and require some form of backpropagation that is incompatible with the current neuromorphic edge-devices. In this paper, we propose an online-within-online meta-learning rule for SNNs termed OWOML-SNN, that enables lifelong learning on a stream of tasks, and relies on local, backprop-free, nested updates. </details>
<details>	<summary>注释</summary>	Accepted for publication at DSLW 2021 </details>
<details>	<summary>邮件日期</summary>	2021年03月09日</details>

# 68、机器人神经形态感知工具箱
- [ ] A toolbox for neuromorphic sensing in robotics 
时间：2021年03月03日                         第一作者：Julien Dupeyroux                       [链接](https://arxiv.org/abs/2103.02751).                     
## 摘要：由神经形态计算引入的第三代人工智能（AI）正在彻底改变机器人和自主系统感知世界、处理信息以及与环境交互的方式。神经形态系统的高灵活性、能量效率和鲁棒性的承诺得到了模拟脉冲神经网络的软件工具和硬件集成（神经形态处理器）的广泛支持。然而，尽管人们在神经形态视觉（基于事件的摄像机）方面做出了努力，但值得注意的是，大多数机器人可用的传感器与神经形态计算（信息被编码成脉冲）本质上仍然不兼容。为了方便传统传感器的使用，我们需要将输出信号转换成脉冲流，即一系列事件（+1，-1）及其相应的时间戳。在这篇论文中，我们从机器人学的角度对编码算法进行了回顾，并进一步通过一个基准测试来评估它们的性能。我们还引入了ROS（机器人操作系统）工具箱来编码和解码来自机器人上任何类型传感器的输入信号。这项倡议旨在刺激和促进神经形态人工智能的机器人集成，并有机会使传统的现成传感器适应最强大的机器人工具之一ROS中的脉冲神经网络。
<details>	<summary>英文摘要</summary>	The third generation of artificial intelligence (AI) introduced by neuromorphic computing is revolutionizing the way robots and autonomous systems can sense the world, process the information, and interact with their environment. The promises of high flexibility, energy efficiency, and robustness of neuromorphic systems is widely supported by software tools for simulating spiking neural networks, and hardware integration (neuromorphic processors). Yet, while efforts have been made on neuromorphic vision (event-based cameras), it is worth noting that most of the sensors available for robotics remain inherently incompatible with neuromorphic computing, where information is encoded into spikes. To facilitate the use of traditional sensors, we need to convert the output signals into streams of spikes, i.e., a series of events (+1, -1) along with their corresponding timestamps. In this paper, we propose a review of the coding algorithms from a robotics perspective and further supported by a benchmark to assess their performance. We also introduce a ROS (Robot Operating System) toolbox to encode and decode input signals coming from any type of sensor available on a robot. This initiative is meant to stimulate and facilitate robotic integration of neuromorphic AI, with the opportunity to adapt traditional off-the-shelf sensors to spiking neural nets within one of the most powerful robotic tools, ROS. </details>
<details>	<summary>注释</summary>	7 pages, 3 figures, 3 tables, 7 algorithms </details>
<details>	<summary>邮件日期</summary>	2021年03月05日</details>

# 67、基于事件的合成孔径成像
- [ ] Event-based Synthetic Aperture Imaging 
时间：2021年03月03日                         第一作者：Xiang Zhang                       [链接](https://arxiv.org/abs/2103.02376).                     
## 摘要：合成孔径成像（syntheticapertureimaging，SAI）是通过模糊掉离焦的前景遮挡，并从多视点图像中重建出在焦遮挡的目标，从而达到透视效果。然而，非常密集的遮挡和极端的光照条件可能会对基于传统帧相机的SAI带来显著的干扰，导致性能退化。为了解决这些问题，我们提出了一种基于事件摄像机的SAI系统，它可以产生具有极低延迟和高动态范围的异步事件。因此，它可以通过几乎连续的视图来消除密集遮挡的干扰，同时解决过度/不足曝光的问题。为了重建遮挡目标，提出了一种由脉冲神经网络（SNNs）和卷积神经网络（CNNs）组成的混合编解码网络。在混合网络中，首先对采集到的事件的时空信息进行SNN层编码，然后通过样式转换CNN解码器将其转换为遮挡目标的视觉图像。实验结果表明，该方法在处理高密度遮挡和极端光照条件下具有良好的性能，可以用纯事件数据重建高质量的视觉图像。
<details>	<summary>英文摘要</summary>	Synthetic aperture imaging (SAI) is able to achieve the see through effect by blurring out the off-focus foreground occlusions and reconstructing the in-focus occluded targets from multi-view images. However, very dense occlusions and extreme lighting conditions may bring significant disturbances to SAI based on conventional frame-based cameras, leading to performance degeneration. To address these problems, we propose a novel SAI system based on the event camera which can produce asynchronous events with extremely low latency and high dynamic range. Thus, it can eliminate the interference of dense occlusions by measuring with almost continuous views, and simultaneously tackle the over/under exposure problems. To reconstruct the occluded targets, we propose a hybrid encoder-decoder network composed of spiking neural networks (SNNs) and convolutional neural networks (CNNs). In the hybrid network, the spatio-temporal information of the collected events is first encoded by SNN layers, and then transformed to the visual image of the occluded targets by a style-transfer CNN decoder. Through experiments, the proposed method shows remarkable performance in dealing with very dense occlusions and extreme lighting conditions, and high quality visual images can be reconstructed using pure event data. </details>
<details>	<summary>注释</summary>	9 pages, 7 figures </details>
<details>	<summary>邮件日期</summary>	2021年03月04日</details>

# 66、一点点能量就有很大的帮助：高效节能，从卷积神经网络到脉冲神经网络的精确转换
- [ ] A Little Energy Goes a Long Way: Energy-Efficient, Accurate Conversion from Convolutional Neural Networks to Spiking Neural Networks 
时间：2021年03月01日                         第一作者：Dengyu Wu                       [链接](https://arxiv.org/abs/2103.00944).                     
## 摘要：脉冲神经网络（SNNs）提供了一种处理时空数据的固有能力，也就是说，处理现实世界中的感官数据，但是很难训练出高精度的模型。SNN的一个主要研究方向是将预先训练好的卷积神经网络（CNN）转换成具有相同结构的SNN。最先进的转换方法正在接近精度极限，即SNN对原始CNN的精度损失接近于零。然而，我们注意到，只有当处理输入消耗的能量显著增加时，这才有可能实现。在本文中，我们认为这种“能量换精度”的趋势是不必要的——一点点能量可以大大提高精度损失的接近零。具体来说，我们提出了一种新的CNN到SNN转换方法，该方法能够使用合理的短脉冲序列（例如，CIFAR10图像的256个时间步）来实现接近零的精度损失。新的转换方法称为显式电流控制（ECC），包含三种技术（电流归一化、残差消除阈值和批量归一化一致性维护），以便在处理输入时显式控制流经SNN的电流。我们将ECC实现到一个昵称为SpKeras的工具中，该工具可以方便地导入Keras-CNN模型并将其转换为snn。我们使用该工具进行了一系列广泛的实验——使用VGG16和各种数据集，如CIFAR10和CIFAR100——并与最先进的转换方法进行了比较。结果表明，ECC是一种很有前途的方法，它可以同时优化系统的能耗和精度损失。
<details>	<summary>英文摘要</summary>	Spiking neural networks (SNNs) offer an inherent ability to process spatial-temporal data, or in other words, realworld sensory data, but suffer from the difficulty of training high accuracy models. A major thread of research on SNNs is on converting a pre-trained convolutional neural network (CNN) to an SNN of the same structure. State-of-the-art conversion methods are approaching the accuracy limit, i.e., the near-zero accuracy loss of SNN against the original CNN. However, we note that this is made possible only when significantly more energy is consumed to process an input. In this paper, we argue that this trend of ''energy for accuracy'' is not necessary -- a little energy can go a long way to achieve the near-zero accuracy loss. Specifically, we propose a novel CNN-to-SNN conversion method that is able to use a reasonably short spike train (e.g., 256 timesteps for CIFAR10 images) to achieve the near-zero accuracy loss. The new conversion method, named as explicit current control (ECC), contains three techniques (current normalisation, thresholding for residual elimination, and consistency maintenance for batch-normalisation), in order to explicitly control the currents flowing through the SNN when processing inputs. We implement ECC into a tool nicknamed SpKeras, which can conveniently import Keras CNN models and convert them into SNNs. We conduct an extensive set of experiments with the tool -- working with VGG16 and various datasets such as CIFAR10 and CIFAR100 -- and compare with state-of-the-art conversion methods. Results show that ECC is a promising method that can optimise over energy consumption and accuracy loss simultaneously. </details>
<details>	<summary>邮件日期</summary>	2021年03月02日</details>

# 65、SpikeDyn：一种动态环境下具有连续无监督学习能力的节能型Spiking神经网络框架
- [ ] SpikeDyn: A Framework for Energy-Efficient Spiking Neural Networks with Continual and Unsupervised Learning Capabilities in Dynamic Environments 
时间：2021年02月28日                         第一作者：Rachmad Vidya Wicaksana Putra                       [链接](https://arxiv.org/abs/2103.00424).                     
## 摘要：脉冲神经网络（Spiking Neural Networks，SNNs）由于其生物学上的合理性，具有高效无监督和持续学习能力的潜力，但其复杂性仍然是一个严重的研究挑战，以使其能够针对资源受限的场景（如嵌入式系统、物联网边缘等）进行节能设计。我们提出了SpikeDyn，一个在动态环境中具有连续和无监督学习能力的节能snn的综合框架，用于训练和推理阶段。它是通过以下多种不同的机制实现的：1）减少神经元的操作，用直接的侧抑制代替抑制神经元；2）一种记忆和能量受限的SNN模型搜索算法，该算法利用分析模型来估计不同候选SNN的记忆足迹和能量消耗建立并选择一个Pareto最优SNN模型；3）一个轻量级的连续无监督学习算法，采用自适应学习率、自适应膜阈值电位、权值衰减和减少虚假更新。实验结果表明，对于一个由400个兴奋神经元组成的网络，我们的SpikeDyn在训练和推理方面的平均能耗分别比现有的方法降低了51%和37%。由于改进的学习算法，SpikeDyn对最近学习的任务进行分类，平均比最新技术提高了21%，对以前学习的任务平均提高了8%。
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNNs) bear the potential of efficient unsupervised and continual learning capabilities because of their biological plausibility, but their complexity still poses a serious research challenge to enable their energy-efficient design for resource-constrained scenarios (like embedded systems, IoT-Edge, etc.). We propose SpikeDyn, a comprehensive framework for energy-efficient SNNs with continual and unsupervised learning capabilities in dynamic environments, for both the training and inference phases. It is achieved through the following multiple diverse mechanisms: 1) reduction of neuronal operations, by replacing the inhibitory neurons with direct lateral inhibitions; 2) a memory- and energy-constrained SNN model search algorithm that employs analytical models to estimate the memory footprint and energy consumption of different candidate SNN models and selects a Pareto-optimal SNN model; and 3) a lightweight continual and unsupervised learning algorithm that employs adaptive learning rates, adaptive membrane threshold potential, weight decay, and reduction of spurious updates. Our experimental results show that, for a network with 400 excitatory neurons, our SpikeDyn reduces the energy consumption on average by 51% for training and by 37% for inference, as compared to the state-of-the-art. Due to the improved learning algorithm, SpikeDyn provides on avg. 21% accuracy improvement over the state-of-the-art, for classifying the most recently learned task, and by 8% on average for the previously learned tasks. </details>
<details>	<summary>注释</summary>	To appear at the 58th IEEE/ACM Design Automation Conference (DAC), December 2021, San Francisco, CA, USA </details>
<details>	<summary>邮件日期</summary>	2021年03月02日</details>

# 64、传统人工神经网络到脉冲神经网络的优化转换
- [ ] Optimal Conversion of Conventional Artificial Neural Networks to Spiking Neural Networks 
时间：2021年02月28日                         第一作者：Shikuang Deng                       [链接](https://arxiv.org/abs/2103.00476).                     
## 摘要：脉冲神经网络（SNNs）是一种受生物启发的人工神经网络（ANNs），由脉冲神经元组成，用于处理异步离散信号。由于snn的离散性，使得snn在功耗和推理速度上都有很大的提高，但通常很难直接从零开始训练。另一种方法是通过复制神经网络的权值和调整snn中神经元的峰值阈值电位，将传统的ann转化为snn。研究人员设计了新的SNN结构和转换算法来减小转换误差。然而，一个有效的转换应该解决SNN和ANN体系结构之间的差异，用一个有效的损失函数的近似值，这个函数在这个领域是缺失的。在这项工作中，我们分析了递归归约到分层求和的转换误差，并提出了一种新的策略管道，通过结合阈值平衡和软重置机制将权值转移到目标SNN。这种流水线使得转换后的SNN和传统的ann之间几乎没有精度损失，只有典型SNN模拟时间的$\sim1/10$。我们的方法有望在能量和内存有限的情况下，更好地支持SNNs，并将其移植到嵌入式平台上。
<details>	<summary>英文摘要</summary>	Spiking neural networks (SNNs) are biology-inspired artificial neural networks (ANNs) that comprise of spiking neurons to process asynchronous discrete signals. While more efficient in power consumption and inference speed on the neuromorphic hardware, SNNs are usually difficult to train directly from scratch with spikes due to the discreteness. As an alternative, many efforts have been devoted to converting conventional ANNs into SNNs by copying the weights from ANNs and adjusting the spiking threshold potential of neurons in SNNs. Researchers have designed new SNN architectures and conversion algorithms to diminish the conversion error. However, an effective conversion should address the difference between the SNN and ANN architectures with an efficient approximation \DSK{of} the loss function, which is missing in the field. In this work, we analyze the conversion error by recursive reduction to layer-wise summation and propose a novel strategic pipeline that transfers the weights to the target SNN by combining threshold balance and soft-reset mechanisms. This pipeline enables almost no accuracy loss between the converted SNNs and conventional ANNs with only $\sim1/10$ of the typical SNN simulation time. Our method is promising to get implanted onto embedded platforms with better support of SNNs with limited energy and memory. </details>
<details>	<summary>邮件日期</summary>	2021年03月02日</details>

# 63、SparkXD：一种基于近似DRAM的弹性高效脉冲神经网络推理框架
- [ ] SparkXD: A Framework for Resilient and Energy-Efficient Spiking Neural Network Inference using Approximate DRAM 
时间：2021年02月28日                         第一作者：Rachmad Vidya Wicaksana Putra                       [链接](https://arxiv.org/abs/2103.00421).                     
## 摘要：脉冲神经网络（SNNs）由于其生物稀疏性，具有实现低能耗的潜力。一些研究表明，片外存储器（DRAM）访问是SNN处理中最消耗能量的操作。然而，SNN系统中的最新技术并没有优化每个访问的DRAM能量，因此阻碍了实现高能量效率。为了最大限度地减少每次存取的DRAM能量，一个按键旋钮用于降低DRAM电源电压，但这可能会导致DRAM错误（即所谓的近似DRAM）。针对这一点，我们提出了SparkXD，这是一个新的框架，它提供了一个综合的联合解决方案，用于使用低功耗dram在电压引起的错误下进行弹性和节能SNN推断。SparkXD的关键机制是：（1）通过考虑近似DRAM误码的容错训练来提高SNN的容错性；（2）分析改进的SNN模型的容错性，找到满足目标精度约束的最大可容忍误码率；（3）能量有效的DRAM数据映射对于弹性SNN模型，该模型将权重映射到适当的DRAM位置以最小化DRAM访问能量。通过这些机制，SparkXD减轻了DRAM（近似）错误的负面影响，并提供了所需的精度。实验结果表明，当目标精度在基线设计的1%以内（即SNN没有DRAM错误）时，SparkXD在不同网络规模下平均降低DRAM能量约40%。
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNNs) have the potential for achieving low energy consumption due to their biologically sparse computation. Several studies have shown that the off-chip memory (DRAM) accesses are the most energy-consuming operations in SNN processing. However, state-of-the-art in SNN systems do not optimize the DRAM energy-per-access, thereby hindering achieving high energy-efficiency. To substantially minimize the DRAM energy-per-access, a key knob is to reduce the DRAM supply voltage but this may lead to DRAM errors (i.e., the so-called approximate DRAM). Towards this, we propose SparkXD, a novel framework that provides a comprehensive conjoint solution for resilient and energy-efficient SNN inference using low-power DRAMs subjected to voltage-induced errors. The key mechanisms of SparkXD are: (1) improving the SNN error tolerance through fault-aware training that considers bit errors from approximate DRAM, (2) analyzing the error tolerance of the improved SNN model to find the maximum tolerable bit error rate (BER) that meets the targeted accuracy constraint, and (3) energy-efficient DRAM data mapping for the resilient SNN model that maps the weights in the appropriate DRAM location to minimize the DRAM access energy. Through these mechanisms, SparkXD mitigates the negative impact of DRAM (approximation) errors, and provides the required accuracy. The experimental results show that, for a target accuracy within 1% of the baseline design (i.e., SNN without DRAM errors), SparkXD reduces the DRAM energy by ca. 40% on average across different network sizes. </details>
<details>	<summary>注释</summary>	To appear at the 58th IEEE/ACM Design Automation Conference (DAC), December 2021, San Francisco, CA, USA </details>
<details>	<summary>邮件日期</summary>	2021年03月02日</details>

# 62、结合脉冲神经网络和人工神经网络的图像增强分类
- [ ] Combining Spiking Neural Network and Artificial Neural Network for Enhanced Image Classification 
时间：2021年02月28日                         第一作者：Naoya Muramatsu                        [链接](https://arxiv.org/abs/2102.10592).                     
<details>	<summary>注释</summary>	This paper written for DEIM 2021 (https://db-event.jpn.org/deim2021/) has 12 pages, 6 figures and 3 tables MSC-class: 68T05 (Primary) 68T05 (Secondary) ACM-class: I.2.6 </details>
<details>	<summary>邮件日期</summary>	2021年03月02日</details>

# 61、癫痫发作预测的神经形态计算新方法
- [ ] A New Neuromorphic Computing Approach for Epileptic Seizure Prediction 
时间：2021年02月25日                         第一作者：Fengshi Tian                       [链接](https://arxiv.org/abs/2102.12773).                     
## 摘要：报道了几种利用卷积神经网络（CNNs）预测癫痫发作的高特异性和敏感性方法。然而，cnn的计算成本很高，耗电量也很大。这些不便使得基于CNN的方法很难在可穿戴设备上实现。基于能量有效的脉冲神经网络（SNNs），提出了一种用于癫痫发作预测的神经形态计算方法。该方法利用设计的高斯随机离散编码器从脑电样本中产生脉冲序列，并在结合了CNNs和SNNs优点的脉冲卷积神经网络（spiking-convolutional neural network，spiking-CNN）中进行预测。实验结果表明，该方法的灵敏度、特异性和AUC分别为95.1%、99.2%和0.912%，计算复杂度比CNN降低了98.58%，表明该方法硬件友好，精度高。
<details>	<summary>英文摘要</summary>	Several high specificity and sensitivity seizure prediction methods with convolutional neural networks (CNNs) are reported. However, CNNs are computationally expensive and power hungry. These inconveniences make CNN-based methods hard to be implemented on wearable devices. Motivated by the energy-efficient spiking neural networks (SNNs), a neuromorphic computing approach for seizure prediction is proposed in this work. This approach uses a designed gaussian random discrete encoder to generate spike sequences from the EEG samples and make predictions in a spiking convolutional neural network (Spiking-CNN) which combines the advantages of CNNs and SNNs. The experimental results show that the sensitivity, specificity and AUC can remain 95.1%, 99.2% and 0.912 respectively while the computation complexity is reduced by 98.58% compared to CNN, indicating that the proposed Spiking-CNN is hardware friendly and of high precision. </details>
<details>	<summary>注释</summary>	Accepted to 2021 IEEE International Symposium on Circuits and Systems (ISCAS) Journal-ref: 2021 IEEE International Symposium on Circuits and Systems (ISCAS) </details>
<details>	<summary>邮件日期</summary>	2021年02月26日</details>

# 60、皮层振荡在脉冲神经网络中实现了基于采样的计算
- [ ] Cortical oscillations implement a backbone for sampling-based computation in spiking neural networks 
时间：2021年02月23日                         第一作者：Agnes Korcsak-Gorzo                       [链接](https://arxiv.org/abs/2006.11099).                     
<details>	<summary>注释</summary>	28 pages, 11 figures </details>
<details>	<summary>邮件日期</summary>	2021年02月24日</details>

# 59、STDP通过反向传播增强脉冲神经网络的学习
- [ ] STDP enhances learning by backpropagation in a spiking neural network 
时间：2021年02月21日                         第一作者：Kotaro Furuya                        [链接](https://arxiv.org/abs/2102.10530).                     
## 摘要：提出了一种用于脉冲神经网络的半监督学习方法。该方法由反向传播的有监督学习和脉冲时间依赖可塑性（STDP）的无监督学习组成，STDP是一种生物学上合理的学习规则。数值实验表明，在使用少量标记数据的情况下，该方法在不增加标记的情况下提高了精度。现有的判别模型半监督学习方法还没有实现这一特性。对于事件驱动系统，可以实现所提出的学习方法。因此，如果在神经形态硬件上实现，它在实时性问题上会非常高效。结果表明，STDP在监督学习后的应用中除了自组织外，还起着重要的作用，这不同于以往将STDP作为预训练解释为自组织的方法。
<details>	<summary>英文摘要</summary>	A semi-supervised learning method for spiking neural networks is proposed. The proposed method consists of supervised learning by backpropagation and subsequent unsupervised learning by spike-timing-dependent plasticity (STDP), which is a biologically plausible learning rule. Numerical experiments show that the proposed method improves the accuracy without additional labeling when a small amount of labeled data is used. This feature has not been achieved by existing semi-supervised learning methods of discriminative models. It is possible to implement the proposed learning method for event-driven systems. Hence, it would be highly efficient in real-time problems if it were implemented on neuromorphic hardware. The results suggest that STDP plays an important role other than self-organization when applied after supervised learning, which differs from the previous method of using STDP as pre-training interpreted as self-organization. </details>
<details>	<summary>注释</summary>	9 pages, 12 figures </details>
<details>	<summary>邮件日期</summary>	2021年02月23日</details>

# 58、结合脉冲神经网络和人工神经网络的图像增强分类
- [ ] Combining Spiking Neural Network and Artificial Neural Network for Enhanced Image Classification 
时间：2021年02月21日                         第一作者：Naoya Muramatsu                        [链接](https://arxiv.org/abs/2102.10592).                     
## 摘要：随着深度神经网络的不断创新，更接近生物脑突触的脉冲神经网络（spiking neural networks，SNNs）因其低功耗而备受关注。然而，对于连续数据值，它们必须采用编码过程将值转换为峰值序列。因此，它们还没有超过直接处理这些值的人工神经网络（ANNs）的性能。为此，我们将人工神经网络和神经网络相结合，建立了多功能混合神经网络（HNNs），以提高相关性能。
<details>	<summary>英文摘要</summary>	With the continued innovations of deep neural networks, spiking neural networks (SNNs) that more closely resemble biological brain synapses have attracted attention owing to their low power consumption. However, for continuous data values, they must employ a coding process to convert the values to spike trains. Thus, they have not yet exceeded the performance of artificial neural networks (ANNs), which handle such values directly. To this end, we combine an ANN and an SNN to build versatile hybrid neural networks (HNNs) that improve the concerned performance. </details>
<details>	<summary>注释</summary>	This paper written for DEIM 2021 (https://db-event.jpn.org/deim2021/) has 12 pages, 6 figures and 3 tables MSC-class: 68T05 (Primary) 68T05 (Secondary) ACM-class: I.2.6 </details>
<details>	<summary>邮件日期</summary>	2021年02月23日</details>

# 57、脉冲神经形态芯片学习纠缠量子态
- [ ] Spiking neuromorphic chip learns entangled quantum states 
时间：2021年02月18日                         第一作者：Stefanie Czischek                       [链接](https://arxiv.org/abs/2008.01039).                     
<details>	<summary>注释</summary>	21 pages, 6 figures Submission to SciPost </details>
<details>	<summary>邮件日期</summary>	2021年02月22日</details>

# 56、方程：神经形态实现的脉冲驱动平衡传播
- [ ] EqSpike: Spike-driven Equilibrium Propagation for Neuromorphic Implementations 
时间：2021年02月17日                         第一作者：Erwann Martin                       [链接](https://arxiv.org/abs/2010.07859).                     
<details>	<summary>邮件日期</summary>	2021年02月18日</details>

# 55、阴阳数据集
- [ ] The Yin-Yang dataset 
时间：2021年02月16日                         第一作者：Laura Kriener                       [链接](https://arxiv.org/abs/2102.08211).                     
## 摘要：阴阳数据集是为研究生物似然误差反向传播和脉冲神经网络的深度学习而开发的。它提供了一些优势，可以替代经典的深度学习数据集，特别是在算法和模型原型场景中。首先，它体积更小，因此学习速度更快，因此更适合部署在网络规模有限的神经形态芯片上。第二，与深度神经网络相比，它在使用浅层神经网络所能达到的精度之间存在着非常明显的差距。
<details>	<summary>英文摘要</summary>	The Yin-Yang dataset was developed for research on biologically plausible error backpropagation and deep learning in spiking neural networks. It serves as an alternative to classic deep learning datasets, especially in algorithm- and model-prototyping scenarios, by providing several advantages. First, it is smaller and therefore faster to learn, thereby being better suited for the deployment on neuromorphic chips with limited network sizes. Second, it exhibits a very clear gap between the accuracies achievable using shallow as compared to deep neural networks. </details>
<details>	<summary>注释</summary>	3 pages, 3 figures, 2 tables </details>
<details>	<summary>邮件日期</summary>	2021年02月17日</details>

# 54、用GANs归化神经形态视觉事件流
- [ ] Naturalizing Neuromorphic Vision Event Streams Using GANs 
时间：2021年02月14日                         第一作者：Dennis Robey                       [链接](https://arxiv.org/abs/2102.07243).                     
## 摘要：动态视觉传感器能够在资源受限的环境中以高时间分辨率工作，但代价是捕获静态内容。事件流的稀疏特性使得下游处理任务更高效，因为它们适合于功率高效的脉冲神经网络。与神经形态视觉相关的挑战之一是缺乏事件流的可解释性。虽然大多数应用用例并不打算让事件流被除分类网络之外的任何东西直观地解释，但是在传统高速CMOS传感器无法到达的空间中集成这些传感器的机会将丢失。例如，像内窥镜这样的生物入侵传感器必须符合严格的电源预算，这就不允许以兆赫的速度进行图像集成。虽然动态视觉传感可以填补这一空白，解释的挑战仍然存在，并将降低临床诊断的信心。产生式对抗网络的使用为克服和补偿视觉芯片空间分辨率差和缺乏可解释性提供了一种可能的解决方案。本文系统地应用Pix2Pix网络对CIFAR-10和linnaeus5数据集的事件流进行自然化处理。通过对归化的事件流进行图像分类（其收敛到等效原始图像的2.81%以内），并对CIFAR-10和Linnaeus 5数据集的未处理事件流进行13.19%的相关改进，对网络的质量进行了基准测试。
<details>	<summary>英文摘要</summary>	Dynamic vision sensors are able to operate at high temporal resolutions within resource constrained environments, though at the expense of capturing static content. The sparse nature of event streams enables efficient downstream processing tasks as they are suited for power-efficient spiking neural networks. One of the challenges associated with neuromorphic vision is the lack of interpretability of event streams. While most application use-cases do not intend for the event stream to be visually interpreted by anything other than a classification network, there is a lost opportunity to integrating these sensors in spaces that conventional high-speed CMOS sensors cannot go. For example, biologically invasive sensors such as endoscopes must fit within stringent power budgets, which do not allow MHz-speeds of image integration. While dynamic vision sensing can fill this void, the interpretation challenge remains and will degrade confidence in clinical diagnostics. The use of generative adversarial networks presents a possible solution to overcoming and compensating for a vision chip's poor spatial resolution and lack of interpretability. In this paper, we methodically apply the Pix2Pix network to naturalize the event stream from spike-converted CIFAR-10 and Linnaeus 5 datasets. The quality of the network is benchmarked by performing image classification of naturalized event streams, which converges to within 2.81% of equivalent raw images, and an associated improvement over unprocessed event streams by 13.19% for the CIFAR-10 and Linnaeus 5 datasets. </details>
<details>	<summary>注释</summary>	5 pages, 7 figures </details>
<details>	<summary>邮件日期</summary>	2021年02月16日</details>

# 53、利用混合信号脉冲学习电路实现高效均衡网络
- [ ] Implementing efficient balanced networks with mixed-signal spike-based learning circuits 
时间：2021年02月12日                         第一作者：Julian B\"uchel                       [链接](https://arxiv.org/abs/2010.14353).                     
<details>	<summary>注释</summary>	5 pages, 6 figures. Accepted at IEEE International Symposium on Circuits and Systems 2021 </details>
<details>	<summary>邮件日期</summary>	2021年02月15日</details>

# 52、基于广义期望最大化的脉冲神经网络多样本在线学习
- [ ] Multi-Sample Online Learning for Spiking Neural Networks based on Generalized Expectation Maximization 
时间：2021年02月05日                         第一作者：Hyeryung Jang                        [链接](https://arxiv.org/abs/2102.03280).                     
## 摘要：脉冲神经网络（SNNs）提供了一种新的计算范式，它通过二元神经动态激活来获取生物大脑的一些效率。概率SNN模型通常通过使用对数似然梯度的无偏估计来训练以最大化期望输出的可能性。虽然先前的工作使用单样本估计器从一次运行的网络，本文提出利用多个隔间采样独立的脉冲信号，同时共享突触权重。其关键思想是利用这些信号来获得对数似然训练准则及其梯度的更精确的统计估计。该方法基于广义期望最大化（GEM），利用重要性抽样优化了对数似然的近似。导出的在线学习算法实现了一个具有全局每隔室学习信号的三因素规则。在神经形态MNIST-DVS数据集上的分类任务的实验结果表明，当增加用于训练和推理的隔室数量时，在对数似然性、准确性和校准方面有显著的改进。
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNNs) offer a novel computational paradigm that captures some of the efficiency of biological brains by processing through binary neural dynamic activations. Probabilistic SNN models are typically trained to maximize the likelihood of the desired outputs by using unbiased estimates of the log-likelihood gradients. While prior work used single-sample estimators obtained from a single run of the network, this paper proposes to leverage multiple compartments that sample independent spiking signals while sharing synaptic weights. The key idea is to use these signals to obtain more accurate statistical estimates of the log-likelihood training criterion, as well as of its gradient. The approach is based on generalized expectation-maximization (GEM), which optimizes a tighter approximation of the log-likelihood using importance sampling. The derived online learning algorithm implements a three-factor rule with global per-compartment learning signals. Experimental results on a classification task on the neuromorphic MNIST-DVS data set demonstrate significant improvements in terms of log-likelihood, accuracy, and calibration when increasing the number of compartments used for training and inference. </details>
<details>	<summary>注释</summary>	To be presented at ICASSP 2021. Author's Accepted Manuscript. (A longer version can be found at arXiv:2007.11894), Author's Accepted Manuscript. arXiv admin note: text overlap with arXiv:2007.11894 </details>
<details>	<summary>邮件日期</summary>	2021年02月08日</details>

# 51、优化的脉冲神经元通过双峰时间编码对图像进行高精度分类
- [ ] Optimized spiking neurons classify images with high accuracy through temporal coding with two spikes 
时间：2021年01月26日                         第一作者：Christoph St\"ockl                        [链接](https://arxiv.org/abs/2002.00860).                     
<details>	<summary>注释</summary>	23 pages, 5 figures, 1 tables </details>
<details>	<summary>邮件日期</summary>	2021年01月27日</details>

# 50、一种基于Loihi神经形态处理器的DVS摄像机手势识别算法
- [ ] An Efficient Spiking Neural Network for Recognizing Gestures with a DVS Camera on the Loihi Neuromorphic Processor 
时间：2021年01月25日                         第一作者：Riccardo Massa                       [链接](https://arxiv.org/abs/2006.09985).                     
<details>	<summary>注释</summary>	Accepted for publication at the 2020 International Joint Conference on Neural Networks (IJCNN) </details>
<details>	<summary>邮件日期</summary>	2021年01月26日</details>

# 49、腿型机器人仿生运动的神经形态自适应脉冲CPG
- [ ] Neuromorphic adaptive spiking CPG towards bio-inspired locomotion of legged robots 
时间：2021年01月24日                         第一作者：Pablo Lopez-Osorio                       [链接](https://arxiv.org/abs/2101.09709).                     
## 摘要：近年来，脊椎动物的运动机制为机器人系统性能的提高提供了灵感。这些机制包括它们的运动对通过生物传感器记录的环境变化的适应性。在这方面，我们的目标是复制这种适应性的腿机器人通过一个脉冲中心模式发生器。这种脉冲中心模式发生器产生不同的运动（节奏）模式，这些模式由外部刺激驱动，即连接到机器人的力敏感电阻器的输出，以提供反馈。脉冲中枢模式发生器由五个漏神经元群组成，这些漏神经元群具有特定的拓扑结构，使得节律模式可以由上述外部刺激产生和驱动。因此，末端机器人平台（任意腿机器人）的运动可以通过使用任意传感器作为输入来适应地形。采用brian2模拟器和SpiNNaker神经形态平台，对具有自适应学习的脉冲中心模式发生器进行了软硬件仿真验证。特别是，我们的实验清楚地表明，当输入刺激不同时，脉冲中央模式发生器群体中产生的脉冲之间的振荡频率发生了适应性变化。为了验证脉冲中心模式发生器的鲁棒性和适应性，我们通过改变传感器的输出进行了多次测试。这些实验在brian2和SpiNNaker中进行；两个实现都显示出相似的行为，Pearson相关系数为0.905。
<details>	<summary>英文摘要</summary>	In recent years, locomotion mechanisms exhibited by vertebrate animals have been the inspiration for the improvement in the performance of robotic systems. These mechanisms include the adaptability of their locomotion to any change registered in the environment through their biological sensors. In this regard, we aim to replicate such kind of adaptability in legged robots through a Spiking Central Pattern Generator. This Spiking Central Pattern Generator generates different locomotion (rhythmic) patterns which are driven by an external stimulus, that is, the output of a Force Sensitive Resistor connected to the robot to provide feedback. The Spiking Central Pattern Generator consists of a network of five populations of Leaky Integrate-and-Fire neurons designed with a specific topology in such a way that the rhythmic patterns can be generated and driven by the aforementioned external stimulus. Therefore, the locomotion of the end robotic platform (any-legged robot) can be adapted to the terrain by using any sensor as input. The Spiking Central Pattern Generator with adaptive learning has been numerically validated at software and hardware level, using the Brian 2 simulator and the SpiNNaker neuromorphic platform for the latest. In particular, our experiments clearly show an adaptation in the oscillation frequencies between the spikes produced in the populations of the Spiking Central Pattern Generator while the input stimulus varies. To validate the robustness and adaptability of the Spiking Central Pattern Generator, we have performed several tests by variating the output of the sensor. These experiments were carried out in Brian 2 and SpiNNaker; both implementations showed a similar behavior with a Pearson correlation coefficient of 0.905. </details>
<details>	<summary>注释</summary>	23 pages, 12 figures </details>
<details>	<summary>邮件日期</summary>	2021年01月26日</details>

# 48、事件驱动目标识别的脉冲学习系统
- [ ] A Spike Learning System for Event-driven Object Recognition 
时间：2021年01月21日                         第一作者：Shibo Zhou                       [链接](https://arxiv.org/abs/2101.08850).                     
## 摘要：事件驱动传感器，如激光雷达和动态视觉传感器（DVS）在高分辨率和高速应用中受到越来越多的关注。为了提高识别精度，人们做了大量的工作。然而，对于识别延迟或时间效率这一基本问题的研究还远远不够。在本文中，我们提出了一个脉冲学习系统，该系统使用脉冲神经网络（SNN）和一种新的时态编码来实现精确快速的目标识别。提出的时态编码方案将每个事件的到达时间和数据映射到SNN脉冲时间，使得异步到达的事件立即得到处理而没有延迟。该方案很好地结合了SNN的异步处理能力，提高了时间效率。与现有系统相比的一个关键优势是，每个识别任务的事件累积时间由系统自动确定，而不是由用户预先设置。系统可以在不等待所有输入事件的情况下提前完成识别。在7个激光雷达和DVS数据集上进行了广泛的实验。结果表明，该系统在取得显著时间效率的同时，具有最先进的识别精度。实验结果表明，在不同的实验条件下，在KITTI数据集上，识别延迟降低了56.3%-91.7%。
<details>	<summary>英文摘要</summary>	Event-driven sensors such as LiDAR and dynamic vision sensor (DVS) have found increased attention in high-resolution and high-speed applications. A lot of work has been conducted to enhance recognition accuracy. However, the essential topic of recognition delay or time efficiency is largely under-explored. In this paper, we present a spiking learning system that uses the spiking neural network (SNN) with a novel temporal coding for accurate and fast object recognition. The proposed temporal coding scheme maps each event's arrival time and data into SNN spike time so that asynchronously-arrived events are processed immediately without delay. The scheme is integrated nicely with the SNN's asynchronous processing capability to enhance time efficiency. A key advantage over existing systems is that the event accumulation time for each recognition task is determined automatically by the system rather than pre-set by the user. The system can finish recognition early without waiting for all the input events. Extensive experiments were conducted over a list of 7 LiDAR and DVS datasets. The results demonstrated that the proposed system had state-of-the-art recognition accuracy while achieving remarkable time efficiency. Recognition delay was shown to reduce by 56.3% to 91.7% in various experiment settings over the popular KITTI dataset. </details>
<details>	<summary>注释</summary>	Shibo Zhou and Wei Wang contributed equally to this work ACM-class: I.5.1; I.5.4; I.2.6; I.2.10 </details>
<details>	<summary>邮件日期</summary>	2021年01月25日</details>

# 47、亚稳材料的自主合成
- [ ] Autonomous synthesis of metastable materials 
时间：2021年01月19日                         第一作者：Sebastian Ament                       [链接](https://arxiv.org/abs/2101.07385).                     
## 摘要：人工智能的自主实验为加速科学发现提供了新的范例。非平衡材料合成是复杂的、资源密集型实验的标志，其加速将是材料发现和发展的分水岭。非平衡合成相图的绘制最近通过高通量实验得到了加速，但由于参数空间太大而无法进行详尽的探索，因此仍然限制了材料的研究。我们演示了加速合成和探索亚稳材料通过分层自主实验所管辖的科学自主推理代理（SARA）。SARA集成了机器人材料的合成和表征以及一系列人工智能方法，有效地揭示了加工相图的结构。SARA设计了用于平行材料合成的横向梯度激光脉冲退火（lg-LSA）实验，并利用光谱技术快速识别相变。多维参数空间的有效探索是通过嵌套的主动学习（AL）循环来实现的，该循环建立在先进的机器学习模型之上，该模型结合了实验的基本物理以及端到端的不确定性量化。有了这一点，以及在多个尺度上的协调，SARA体现了人工智能对复杂科学任务的利用。我们通过自主绘制Bi$\u2$O$\u3$系统的合成相边界来证明它的性能，从而在建立一个合成相图时产生数量级的加速，该合成相图包括在室温下动力学稳定$\delta$-Bi$\u2$O$\u3$的条件，固体氧化物燃料电池等电化学技术的关键发展。
<details>	<summary>英文摘要</summary>	Autonomous experimentation enabled by artificial intelligence (AI) offers a new paradigm for accelerating scientific discovery. Non-equilibrium materials synthesis is emblematic of complex, resource-intensive experimentation whose acceleration would be a watershed for materials discovery and development. The mapping of non-equilibrium synthesis phase diagrams has recently been accelerated via high throughput experimentation but still limits materials research because the parameter space is too vast to be exhaustively explored. We demonstrate accelerated synthesis and exploration of metastable materials through hierarchical autonomous experimentation governed by the Scientific Autonomous Reasoning Agent (SARA). SARA integrates robotic materials synthesis and characterization along with a hierarchy of AI methods that efficiently reveal the structure of processing phase diagrams. SARA designs lateral gradient laser spike annealing (lg-LSA) experiments for parallel materials synthesis and employs optical spectroscopy to rapidly identify phase transitions. Efficient exploration of the multi-dimensional parameter space is achieved with nested active learning (AL) cycles built upon advanced machine learning models that incorporate the underlying physics of the experiments as well as end-to-end uncertainty quantification. With this, and the coordination of AL at multiple scales, SARA embodies AI harnessing of complex scientific tasks. We demonstrate its performance by autonomously mapping synthesis phase boundaries for the Bi$_2$O$_3$ system, leading to orders-of-magnitude acceleration in establishment of a synthesis phase diagram that includes conditions for kinetically stabilizing $\delta$-Bi$_2$O$_3$ at room temperature, a critical development for electrochemical technologies such as solid oxide fuel cells. </details>
<details>	<summary>邮件日期</summary>	2021年01月20日</details>

# 46、模拟七鳃鳗机器人在SpiNNaker和Loihi神经形态板上运行的脉冲中心模式发生器
- [ ] A Spiking Central Pattern Generator for the control of a simulated lamprey robot running on SpiNNaker and Loihi neuromorphic boards 
时间：2021年01月18日                         第一作者：Emmanouil Angelidis                       [链接](https://arxiv.org/abs/2101.07001).                     
## 摘要：中枢模式发生器（CPGs）模型长期以来被用来研究动物运动的神经机制，也被用作机器人研究的工具。在这项工作中，我们提出了一个脉冲CPG神经网络及其在神经形态硬件上的实现作为一种手段来控制一个模拟七鳃鳗模型。为了建立我们的CPG模型，我们采用了自然出现的动态系统，这些系统是通过在神经工程框架（NEF）中使用递归神经种群而产生的。我们定义了我们模型背后的数学公式，它由一个由高电平信号调制的耦合抽象振荡器系统组成，能够产生各种输出步态。我们证明，利用这种中央模式发生器模型的数学公式，可以将该模型转化为一个脉冲神经网络（SNN），该网络可以很容易地用SNN模拟器Nengo进行模拟。然后利用脉冲CPG模型生成不同场景下模拟七鳃鳗机器人模型的游动步态。我们证明，通过修改网络的输入（可以由感官信息提供），机器人可以在方向和速度上进行动态控制。该方法可推广应用于工程应用和科学研究中的其它类型的cpg。我们在两个神经形态平台上测试我们的系统，SpiNNaker和Loihi。最后，我们证明了这类脉冲算法在能量效率和计算速度方面显示了利用神经形态硬件理论优势的潜力。
<details>	<summary>英文摘要</summary>	Central Pattern Generators (CPGs) models have been long used to investigate both the neural mechanisms that underlie animal locomotion as well as a tool for robotic research. In this work we propose a spiking CPG neural network and its implementation on neuromorphic hardware as a means to control a simulated lamprey model. To construct our CPG model, we employ the naturally emerging dynamical systems that arise through the use of recurrent neural populations in the Neural Engineering Framework (NEF). We define the mathematical formulation behind our model, which consists of a system of coupled abstract oscillators modulated by high-level signals, capable of producing a variety of output gaits. We show that with this mathematical formulation of the Central Pattern Generator model, the model can be turned into a Spiking Neural Network (SNN) that can be easily simulated with Nengo, an SNN simulator. The spiking CPG model is then used to produce the swimming gaits of a simulated lamprey robot model in various scenarios. We show that by modifying the input to the network, which can be provided by sensory information, the robot can be controlled dynamically in direction and pace. The proposed methodology can be generalized to other types of CPGs suitable for both engineering applications and scientific research. We test our system on two neuromorphic platforms, SpiNNaker and Loihi. Finally, we show that this category of spiking algorithms shows a promising potential to exploit the theoretical advantages of neuromorphic hardware in terms of energy efficiency and computational speed. </details>
<details>	<summary>注释</summary>	25 pages, 15 figures </details>
<details>	<summary>邮件日期</summary>	2021年01月19日</details>

# 45、用于时空特征提取的卷积脉冲神经网络
- [ ] Convolutional Spiking Neural Networks for Spatio-Temporal Feature Extraction 
时间：2021年01月18日                         第一作者：Ali Samadzadeh                       [链接](https://arxiv.org/abs/2003.12346).                     
<details>	<summary>注释</summary>	10 pages, 7 figures, 2 tables </details>
<details>	<summary>邮件日期</summary>	2021年01月20日</details>

# 44、方程：神经形态实现的脉冲驱动平衡传播
- [ ] EqSpike: Spike-driven Equilibrium Propagation for Neuromorphic Implementations 
时间：2021年01月15日                         第一作者：Erwann Martin                       [链接](https://arxiv.org/abs/2010.07859).                     
<details>	<summary>邮件日期</summary>	2021年01月18日</details>

# 43、概率脉冲神经网络的多样本在线学习
- [ ] Multi-Sample Online Learning for Probabilistic Spiking Neural Networks 
时间：2021年01月05日                         第一作者：Hyeryung Jang                        [链接](https://arxiv.org/abs/2007.11894).                     
<details>	<summary>注释</summary>	Submitted </details>
<details>	<summary>邮件日期</summary>	2021年01月06日</details>

# 42、人工脉冲量子神经元
- [ ] An Artificial Spiking Quantum Neuron 
时间：2020年12月30日                         第一作者：Lasse Bj{\o}rn Kristensen                       [链接](https://arxiv.org/abs/1907.06269).                     
<details>	<summary>邮件日期</summary>	2021年01月01日</details>

# 41、深Q网络向事件驱动脉冲神经网络转化的策略与基准
- [ ] Strategy and Benchmark for Converting Deep Q-Networks to Event-Driven Spiking Neural Networks 
时间：2020年12月23日                         第一作者：Weihao Tan                       [链接](https://arxiv.org/abs/2009.14456).                     
<details>	<summary>注释</summary>	Accepted by AAAI2021 </details>
<details>	<summary>邮件日期</summary>	2020年12月24日</details>

# 40、生成模型的进化变分优化
- [ ] Evolutionary Variational Optimization of Generative Models 
时间：2020年12月22日                         第一作者：Jakob Drefs                       [链接](https://arxiv.org/abs/2012.12294).                     
## 摘要：我们结合两种流行的优化方法来推导生成模型的学习算法：变分优化和进化算法。利用截断后验概率作为变分分布族，实现了离散时滞生成模型的组合。截断后验概率的变分参数是一组潜在状态。通过将这些状态解释为个体的基因组，并利用变分下界来定义适应度，我们可以应用进化算法来实现变分循环。所使用的变分分布是非常灵活的，我们证明了进化算法可以有效地优化变分界。此外，变分回路通常适用（“黑盒”），无需分析推导。为了说明该方法的普遍适用性，我们将该方法应用于三种生成模型（使用噪声或贝叶斯网、二进制稀疏编码以及脉冲和板稀疏编码）。为了证明新的变分方法的有效性和效率，我们使用了图像去噪和修复的标准竞争基准。这些基准允许对各种方法进行定量比较，包括概率方法、深层确定性和生成性网络以及非局部图像处理方法。在“零镜头”学习（当只使用损坏的图像进行训练时）的范畴中，我们观察到进化变分算法在许多基准设置中显著改善了最新的状态。对于一个著名的修复基准，我们还观察到了各种算法的最新性能，尽管我们只对损坏的图像进行训练。总的来说，我们的研究强调了研究生成模型的优化方法以提高性能的重要性。
<details>	<summary>英文摘要</summary>	We combine two popular optimization approaches to derive learning algorithms for generative models: variational optimization and evolutionary algorithms. The combination is realized for generative models with discrete latents by using truncated posteriors as the family of variational distributions. The variational parameters of truncated posteriors are sets of latent states. By interpreting these states as genomes of individuals and by using the variational lower bound to define a fitness, we can apply evolutionary algorithms to realize the variational loop. The used variational distributions are very flexible and we show that evolutionary algorithms can effectively and efficiently optimize the variational bound. Furthermore, the variational loop is generally applicable ("black box") with no analytical derivations required. To show general applicability, we apply the approach to three generative models (we use noisy-OR Bayes Nets, Binary Sparse Coding, and Spike-and-Slab Sparse Coding). To demonstrate effectiveness and efficiency of the novel variational approach, we use the standard competitive benchmarks of image denoising and inpainting. The benchmarks allow quantitative comparisons to a wide range of methods including probabilistic approaches, deep deterministic and generative networks, and non-local image processing methods. In the category of "zero-shot" learning (when only the corrupted image is used for training), we observed the evolutionary variational algorithm to significantly improve the state-of-the-art in many benchmark settings. For one well-known inpainting benchmark, we also observed state-of-the-art performance across all categories of algorithms although we only train on the corrupted image. In general, our investigations highlight the importance of research on optimization methods for generative models to achieve performance improvements. </details>
<details>	<summary>邮件日期</summary>	2020年12月24日</details>

# 39、用直接训练的更大的脉冲神经网络进行更深入的研究
- [ ] Going Deeper With Directly-Trained Larger Spiking Neural Networks 
时间：2020年12月18日                         第一作者：Hanle Zheng                       [链接](https://arxiv.org/abs/2011.05280).                     
<details>	<summary>注释</summary>	12 pages, 6 figures, conference or other essential info </details>
<details>	<summary>邮件日期</summary>	2020年12月21日</details>

# 38、脉冲神经网络到神经形态硬件的热感知编译
- [ ] Thermal-Aware Compilation of Spiking Neural Networks to Neuromorphic Hardware 
时间：2020年12月17日                         第一作者：Twisha Titirsha                        [链接](https://arxiv.org/abs/2010.04773).                     
<details>	<summary>注释</summary>	Accepted for publication at LCPC 2020 </details>
<details>	<summary>邮件日期</summary>	2020年12月21日</details>

# 37、基于贝叶斯学习的二元权值脉冲神经网络训练
- [ ] BiSNN: Training Spiking Neural Networks with Binary Weights via Bayesian Learning 
时间：2020年12月15日                         第一作者：Hyeryung Jang                        [链接](https://arxiv.org/abs/2012.08300).                     
## 摘要：基于人工神经网络（ANN）的电池供电设备的推理可以通过限制突触权值为二进制，从而消除执行乘法的需要，从而提高能量效率。另一种新兴的方法依赖于使用脉冲神经网络（SNNs），这是一种受生物启发的动态事件驱动模型，通过使用二进制稀疏激活来提高能源效率。本文介绍了一种SNN模型，它结合了时间稀疏二进制激活和二进制权值的优点。推导了两种学习规则，第一种基于直通和代理梯度技术的组合，第二种基于贝叶斯范式。实验验证了全精度实现的性能损失，并证明了贝叶斯范式在精度和校准方面的优势。
<details>	<summary>英文摘要</summary>	Artificial Neural Network (ANN)-based inference on battery-powered devices can be made more energy-efficient by restricting the synaptic weights to be binary, hence eliminating the need to perform multiplications. An alternative, emerging, approach relies on the use of Spiking Neural Networks (SNNs), biologically inspired, dynamic, event-driven models that enhance energy efficiency via the use of binary, sparse, activations. In this paper, an SNN model is introduced that combines the benefits of temporally sparse binary activations and of binary weights. Two learning rules are derived, the first based on the combination of straight-through and surrogate gradient techniques, and the second based on a Bayesian paradigm. Experiments validate the performance loss with respect to full-precision implementations, and demonstrate the advantage of the Bayesian paradigm in terms of accuracy and calibration. </details>
<details>	<summary>注释</summary>	Submitted </details>
<details>	<summary>邮件日期</summary>	2020年12月16日</details>

# 36、脉冲神经元Hebbian和STDP学习权值的约束
- [ ] Constraints on Hebbian and STDP learned weights of a spiking neuron 
时间：2020年12月14日                         第一作者：Dominique Chu                        [链接](https://arxiv.org/abs/2012.07664).                     
## 摘要：我们从数学上分析了Hebbian和STDP学习规则对权值的限制，这些规则应用于权值归一化的脉冲神经元。在纯Hebbian学习的情况下，我们发现标准化的权值等于权值的提升概率，直到依赖于学习率的修正项，并且通常很小。对于STDP算法，可以导出类似的关系，其中标准化的权重值反映了权重的提升和降级概率之间的差异。这些关系实际上很有用，因为它们允许检查Hebbian和STDP算法的收敛性。另一个应用是新颖性检测。我们使用MNIST数据集演示了这一点。
<details>	<summary>英文摘要</summary>	We analyse mathematically the constraints on weights resulting from Hebbian and STDP learning rules applied to a spiking neuron with weight normalisation. In the case of pure Hebbian learning, we find that the normalised weights equal the promotion probabilities of weights up to correction terms that depend on the learning rate and are usually small. A similar relation can be derived for STDP algorithms, where the normalised weight values reflect a difference between the promotion and demotion probabilities of the weight. These relations are practically useful in that they allow checking for convergence of Hebbian and STDP algorithms. Another application is novelty detection. We demonstrate this using the MNIST dataset. </details>
<details>	<summary>邮件日期</summary>	2020年12月15日</details>

# 35、生物神经网络的低阶模型
- [ ] Low-Order Model of Biological Neural Networks 
时间：2020年12月12日                         第一作者：Huachuan Wang                        [链接](https://arxiv.org/abs/2012.06720).                     
## 摘要：生物神经网络的生物似真低阶模型（LOM）是由树突节点/树、脉冲/非脉冲神经元、无监督/有监督协方差/累积学习机制、反馈连接和最大泛化方案组成的递归层次网络。这些组件模型的动机和必要性在于使LOM易于学习和检索，而无需区分、优化或迭代，以及聚类、检测和识别多个/层次损坏、扭曲和闭塞的时间和空间模式。
<details>	<summary>英文摘要</summary>	A biologically plausible low-order model (LOM) of biological neural networks is a recurrent hierarchical network of dendritic nodes/trees, spiking/nonspiking neurons, unsupervised/ supervised covariance/accumulative learning mechanisms, feedback connections, and a scheme for maximal generalization. These component models are motivated and necessitated by making LOM learn and retrieve easily without differentiation, optimization, or iteration, and cluster, detect and recognize multiple/hierarchical corrupted, distorted, and occluded temporal and spatial patterns. </details>
<details>	<summary>邮件日期</summary>	2020年12月15日</details>

# 34、脉冲神经网络第一部分：空间模式检测
- [ ] Spiking Neural Networks -- Part I: Detecting Spatial Patterns 
时间：2020年12月09日                         第一作者：Hyeryung Jang                       [链接](https://arxiv.org/abs/2010.14208).                     
<details>	<summary>注释</summary>	Submitted </details>
<details>	<summary>邮件日期</summary>	2020年12月10日</details>

# 33、脉冲神经网络第二部分：时空模式检测
- [ ] Spiking Neural Networks -- Part II: Detecting Spatio-Temporal Patterns 
时间：2020年12月09日                         第一作者：Nicolas Skatchkovsky                       [链接](https://arxiv.org/abs/2010.14217).                     
<details>	<summary>注释</summary>	Submitted. The first two authors have equally contributed to this work </details>
<details>	<summary>邮件日期</summary>	2020年12月10日</details>

# 32、脉冲神经网络第三部分：神经形态通信
- [ ] Spiking Neural Networks -- Part III: Neuromorphic Communications 
时间：2020年12月09日                         第一作者：Nicolas Skatchkovsky                       [链接](https://arxiv.org/abs/2010.14220).                     
<details>	<summary>注释</summary>	Submitted </details>
<details>	<summary>邮件日期</summary>	2020年12月10日</details>

# 31、一种训练脉冲神经网络的多智能体进化机器人框架
- [ ] A multi-agent evolutionary robotics framework to train spiking neural networks 
时间：2020年12月07日                         第一作者：Souvik Das                       [链接](https://arxiv.org/abs/2012.03485).                     
## 摘要：提出了一种基于多智能体进化机器人（ER）的训练脉冲神经网络（SNN）的新框架。snn群体的权重以及它们在ER环境中控制的机器人的形态参数被视为表型。该框架的规则根据某些机器人在竞争环境中捕获食物的效率，选择它们及其snn进行繁殖，而选择其他snn进行淘汰。虽然机器人和它们的snn没有通过任何损失函数获得生存或繁衍的明确奖励，但当它们进化到捕猎食物并在这些规则下生存时，这些驱动力隐而不露。它们捕获食物的效率随着世代的变化而呈现出间断平衡的进化特征。给出了两种表型遗传算法：变异遗传算法和带变异交叉遗传算法。通过对每种算法进行100个实验，比较了这些算法的性能。我们发现，在SNN中，带突变的交叉比仅带统计显著性差异的突变能提高40%的学习速度。
<details>	<summary>英文摘要</summary>	A novel multi-agent evolutionary robotics (ER) based framework, inspired by competitive evolutionary environments in nature, is demonstrated for training Spiking Neural Networks (SNN). The weights of a population of SNNs along with morphological parameters of bots they control in the ER environment are treated as phenotypes. Rules of the framework select certain bots and their SNNs for reproduction and others for elimination based on their efficacy in capturing food in a competitive environment. While the bots and their SNNs are given no explicit reward to survive or reproduce via any loss function, these drives emerge implicitly as they evolve to hunt food and survive within these rules. Their efficiency in capturing food as a function of generations exhibit the evolutionary signature of punctuated equilibria. Two evolutionary inheritance algorithms on the phenotypes, Mutation and Crossover with Mutation, are demonstrated. Performances of these algorithms are compared using ensembles of 100 experiments for each algorithm. We find that Crossover with Mutation promotes 40% faster learning in the SNN than mere Mutation with a statistically significant margin. </details>
<details>	<summary>注释</summary>	9 pages, 11 figures </details>
<details>	<summary>邮件日期</summary>	2020年12月08日</details>

# 30、大脑的功能是否像一台使用相位三值计算的量子相位计算机？
- [ ] Does the brain function as a quantum phase computer using phase ternary computation? 
时间：2020年12月04日                         第一作者：Andrew Simon Johnson                        [链接](https://arxiv.org/abs/2012.06537).                     
## 摘要：在这里，我们提供的证据表明，神经通信的基本基础来自于压力脉冲/孤子，它能够以足够的时间精度进行计算，以克服任何处理错误。神经系统内的信号传递和计算是复杂而不同的现象。动作电位是塑性的，这使得动作电位峰值对于神经计算来说是一个不合适的固定点，但是动作电位阈值适合于这个目的。此外，由脉冲神经元计时的神经模型的运算速率低于克服加工误差所需的速率。以视网膜处理为例，我们证明了基于电缆理论的当代神经传导理论不适合解释视网膜和大脑其他部分的完整功能所需的短计算时间。此外，电缆理论不能帮助传播的行动电位，因为在激活阈值没有足够的电荷在激活地点连续离子通道静电开放。对大脑神经网络的解构表明它是一组量子相位计算机中的一员，其中图灵机是最简单的：大脑是另一个基于相位三值计算的计算机。然而，使用图灵机制的尝试无法解决视网膜的编码或智能的计算，因为基于图灵的计算机的技术是根本不同的。我们证明了大脑神经网络中的编码是基于量子的，其中量子有一个时间变量和一个相位基变量，这使得相位三值计算成为可能，正如之前在视网膜中所证明的那样。
<details>	<summary>英文摘要</summary>	Here we provide evidence that the fundamental basis of nervous communication is derived from a pressure pulse/soliton capable of computation with sufficient temporal precision to overcome any processing errors. Signalling and computing within the nervous system are complex and different phenomena. Action potentials are plastic and this makes the action potential peak an inappropriate fixed point for neural computation, but the action potential threshold is suitable for this purpose. Furthermore, neural models timed by spiking neurons operate below the rate necessary to overcome processing error. Using retinal processing as our example, we demonstrate that the contemporary theory of nerve conduction based on cable theory is inappropriate to account for the short computational time necessary for the full functioning of the retina and by implication the rest of the brain. Moreover, cable theory cannot be instrumental in the propagation of the action potential because at the activation-threshold there is insufficient charge at the activation site for successive ion channels to be electrostatically opened. Deconstruction of the brain neural network suggests that it is a member of a group of Quantum phase computers of which the Turing machine is the simplest: the brain is another based upon phase ternary computation. However, attempts to use Turing based mechanisms cannot resolve the coding of the retina or the computation of intelligence, as the technology of Turing based computers is fundamentally different. We demonstrate that that coding in the brain neural network is quantum based, where the quanta have a temporal variable and a phase-base variable enabling phase ternary computation as previously demonstrated in the retina. </details>
<details>	<summary>注释</summary>	16 pages, 7 figures. Key Words: Plasticity; Action potential; Timing; Error redaction; Synchronization; Quantum phase computation; Phase ternary computation; Retinal model ACM-class: I.2; J.3 </details>
<details>	<summary>邮件日期</summary>	2020年12月14日</details>

# 29、DIET-SNN：深脉冲神经网络中带泄漏和阈值优化的直接输入编码
- [ ] DIET-SNN: Direct Input Encoding With Leakage and Threshold Optimization in Deep Spiking Neural Networks 
时间：2020年12月02日                         第一作者：Nitin Rathi                       [链接](https://arxiv.org/abs/2008.03658).                     
<details>	<summary>邮件日期</summary>	2020年12月03日</details>

# 28、从头开始训练低潜伏期深脉冲神经网络的批标准化研究
- [ ] Revisiting Batch Normalization for Training Low-latency Deep Spiking Neural Networks from Scratch 
时间：2020年11月30日                         第一作者：Youngeun Kim                       [链接](https://arxiv.org/abs/2010.01729).                     
<details>	<summary>邮件日期</summary>	2020年12月01日</details>

# 27、DIET-SNN：深脉冲神经网络中带泄漏和阈值优化的直接输入编码
- [ ] DIET-SNN: Direct Input Encoding With Leakage and Threshold Optimization in Deep Spiking Neural Networks 
时间：2020年11月29日                         第一作者：Nitin Rathi                       [链接](https://arxiv.org/abs/2008.03658).                     
<details>	<summary>邮件日期</summary>	2020年12月01日</details>

# 26、编译脉冲神经网络以减轻神经形态的硬件约束
- [ ] Compiling Spiking Neural Networks to Mitigate Neuromorphic Hardware Constraints 
时间：2020年11月27日                         第一作者：Adarsha Balaji                        [链接](https://arxiv.org/abs/2011.13965).                     
## 摘要：脉冲神经网络（SNNs）是在{resource}和{power}约束平台上进行时空模式识别的有效计算模型。在神经形态硬件上执行snn可以进一步降低这些平台的能耗。随着模型尺寸和复杂性的增加，将基于SNN的应用程序映射到基于tile的神经形态硬件变得越来越具有挑战性。这归因于神经突触核心的局限性，即。一种横杆，每个突触后神经元只能容纳固定数量的突触前连接。对于具有许多神经元和每个神经元的突触前连接的基于SNN的复杂模型，（1）在训练后可能需要修剪连接以适应交叉资源，导致模型质量的损失，例如准确性，（2）神经元和突触需要分块并放置在硬件的神经系统核心上，这可能导致延迟和能量消耗增加。在这项工作中，我们提出（1）一种新的展开技术，将具有许多突触前连接的神经元功能分解为一系列同质的神经单元，以显著提高交叉杆的利用率并保留所有突触前连接，（2）SpiNeMap，提出了一种在神经形态硬件上映射snn的新方法，旨在最小化能量消耗和峰值潜伏期。
<details>	<summary>英文摘要</summary>	Spiking Neural Networks (SNNs) are efficient computation models to perform spatio-temporal pattern recognition on {resource}- and {power}-constrained platforms. SNNs executed on neuromorphic hardware can further reduce energy consumption of these platforms. With increasing model size and complexity, mapping SNN-based applications to tile-based neuromorphic hardware is becoming increasingly challenging. This is attributed to the limitations of neuro-synaptic cores, viz. a crossbar, to accommodate only a fixed number of pre-synaptic connections per post-synaptic neuron. For complex SNN-based models that have many neurons and pre-synaptic connections per neuron, (1) connections may need to be pruned after training to fit onto the crossbar resources, leading to a loss in model quality, e.g., accuracy, and (2) the neurons and synapses need to be partitioned and placed on the neuro-sypatic cores of the hardware, which could lead to increased latency and energy consumption. In this work, we propose (1) a novel unrolling technique that decomposes a neuron function with many pre-synaptic connections into a sequence of homogeneous neural units to significantly improve the crossbar utilization and retain all pre-synaptic connections, and (2) SpiNeMap, a novel methodology to map SNNs on neuromorphic hardware with an aim to minimize energy consumption and spike latency. </details>
<details>	<summary>邮件日期</summary>	2020年12月01日</details>

# 25、一种用于在线学习的时态神经网络结构
- [ ] A Temporal Neural Network Architecture for Online Learning 
时间：2020年11月27日                         第一作者：James E. Smith                       [链接](https://arxiv.org/abs/2011.13844).                     
## 摘要：一个长期存在的观点是，通过模拟大脑新皮质的运作，脉冲神经网络（SNN）可以实现类似的理想特性：灵活的学习、速度和效率。时态神经网络（TNNs）是一种snn，用来传递和处理编码为相对峰值时间的信息（与峰值速率相反）。提出了一种TNN体系结构，并在在线监督分类的大背景下证明了TNN的操作。首先，通过无监督学习，TNN根据相似性将输入模式划分为多个簇。然后TNN将一个簇标识符传递给一个简单的在线监督解码器，解码器完成分类任务。TNN学习过程只使用每个突触的局部信号来调整突触的权重，聚类行为在全局范围内出现。系统架构是在抽象层描述的，类似于传统数字设计中的门和寄存器传输层。除了整体架构的特性之外，一些TNN组件对于这项工作来说是新的。虽然没有直接解决，但总体研究目标是TNNs的直接硬件实现。因此，所有的架构元素都很简单，处理的精度很低。重要的是，低精度导致学习时间非常快。使用历史悠久的MNIST数据集的仿真结果表明，学习时间比其他在线方法至少快一个数量级，同时提供了类似的错误率。
<details>	<summary>英文摘要</summary>	A long-standing proposition is that by emulating the operation of the brain's neocortex, a spiking neural network (SNN) can achieve similar desirable features: flexible learning, speed, and efficiency. Temporal neural networks (TNNs) are SNNs that communicate and process information encoded as relative spike times (in contrast to spike rates). A TNN architecture is proposed, and, as a proof-of-concept, TNN operation is demonstrated within the larger context of online supervised classification. First, through unsupervised learning, a TNN partitions input patterns into clusters based on similarity. The TNN then passes a cluster identifier to a simple online supervised decoder which finishes the classification task. The TNN learning process adjusts synaptic weights by using only signals local to each synapse, and clustering behavior emerges globally. The system architecture is described at an abstraction level analogous to the gate and register transfer levels in conventional digital design. Besides features of the overall architecture, several TNN components are new to this work. Although not addressed directly, the overall research objective is a direct hardware implementation of TNNs. Consequently, all the architecture elements are simple, and processing is done at very low precision. Importantly, low precision leads to very fast learning times. Simulation results using the time-honored MNIST dataset demonstrate learning times at least an order of magnitude faster than other online approaches while providing similar error rates. </details>
<details>	<summary>注释</summary>	13 pages, 10 figures ACM-class: C.3; I.2.6; I.5.3 </details>
<details>	<summary>邮件日期</summary>	2020年11月30日</details>

# 24、结合可学习膜时间常数提高脉冲神经网络的学习能力
- [ ] Incorporating Learnable Membrane Time Constant to Enhance Learning of Spiking Neural Networks 
时间：2020年11月27日                         第一作者：Wei Fang                       [链接](https://arxiv.org/abs/2007.05785).                     
<details>	<summary>邮件日期</summary>	2020年11月30日</details>

# 23、PeleNet：Loihi的储层计算框架
- [ ] PeleNet: A Reservoir Computing Framework for Loihi 
时间：2020年11月24日                         第一作者：Carlo Michaelis                       [链接](https://arxiv.org/abs/2011.12338).                     
## 摘要：脉冲神经网络的高级框架是快速原型化和复杂算法高效开发的关键因素。在过去的几年里，这种框架已经出现在传统的计算机上，但是编程神经形态的硬件仍然是一个挑战。通常需要具备神经形态芯片硬件知识的低级编程。PeleNet框架旨在简化神经形态硬件Loihi的储层计算。它是在英特尔的NxSDK之上构建的，是用Python编写的。该框架管理权重矩阵、参数和探测。特别是，它提供了一个自动和有效的网络分布在几个核心和芯片。这样，用户就不用面对技术细节，可以集中精力进行实验。
<details>	<summary>英文摘要</summary>	High-level frameworks for spiking neural networks are a key factor for fast prototyping and efficient development of complex algorithms. Such frameworks have emerged in the last years for traditional computers, but programming neuromorphic hardware is still a challenge. Often low level programming with knowledge about the hardware of the neuromorphic chip is required. The PeleNet framework aims to simplify reservoir computing for the neuromorphic hardware Loihi. It is build on top of the NxSDK from Intel and is written in Python. The framework manages weight matrices, parameters and probes. In particular, it provides an automatic and efficient distribution of networks over several cores and chips. With this, the user is not confronted with technical details and can concentrate on experiments. </details>
<details>	<summary>邮件日期</summary>	2020年11月26日</details>

# 22、面向零镜头跨语言图像检索
- [ ] Towards Zero-shot Cross-lingual Image Retrieval 
时间：2020年11月24日                         第一作者：Pranav Aggarwal                       [链接](https://arxiv.org/abs/2012.05107).                     
## 摘要：最近人们对多模态语言和视觉问题的兴趣激增。在语言方面，由于大多数多模态数据集都是单语的，所以这些模型主要关注英语。我们试图通过在文本方面进行跨语言预训练的零镜头方法来弥补这一差距。我们提出了一个简单而实用的方法来建立一个跨语言图像检索模型，该模型在单语训练数据集上进行训练，但可以在推理过程中以零镜头的跨语言方式使用。我们还引入了一个新的目标函数，通过相互推送不同的文本来收紧文本嵌入簇。最后，我们介绍了一个新的1K多语种MSCOCO2014字幕测试数据集（XTD10），该数据集采用7种语言，我们使用众包平台收集。我们使用它作为跨语言评估零炮模型性能的测试集。XTD10数据集在以下位置公开：https://github.com/adobe-research/Cross-lingual-Test-Dataset-XTD10
<details>	<summary>英文摘要</summary>	There has been a recent spike in interest in multi-modal Language and Vision problems. On the language side, most of these models primarily focus on English since most multi-modal datasets are monolingual. We try to bridge this gap with a zero-shot approach for learning multi-modal representations using cross-lingual pre-training on the text side. We present a simple yet practical approach for building a cross-lingual image retrieval model which trains on a monolingual training dataset but can be used in a zero-shot cross-lingual fashion during inference. We also introduce a new objective function which tightens the text embedding clusters by pushing dissimilar texts from each other. Finally, we introduce a new 1K multi-lingual MSCOCO2014 caption test dataset (XTD10) in 7 languages that we collected using a crowdsourcing platform. We use this as the test set for evaluating zero-shot model performance across languages. XTD10 dataset is made publicly available here: https://github.com/adobe-research/Cross-lingual-Test-Dataset-XTD10 </details>
<details>	<summary>邮件日期</summary>	2020年12月10日</details>

# 21、一种更具生物学意义的人工神经网络局部学习规则
- [ ] A More Biologically Plausible Local Learning Rule for ANNs 
时间：2020年11月24日                         第一作者：Shashi Kant Gupta                       [链接](https://arxiv.org/abs/2011.12012).                     
## 摘要：反向传播算法因其生物学合理性而经常引起争论。然而，为了寻求更具生物学意义的学习，人们提出了各种神经结构的学习方法。他们中的大多数人都试图解决“重量传输问题”，并试图通过一些替代方法在体系结构中向后传播错误。在这项工作中，我们研究了一种稍有不同的方法，它只使用局部信息来捕获脉冲定时信息，而不会传播错误。所提出的学习规则来自于脉冲时间依赖的可塑性和神经元联系的概念。对具有两个隐藏层的MNIST和IRIS数据集的二元分类进行的初步评估表明，其性能与反向传播相当。与通过交叉熵损失反向传播学习的模型相比，使用该方法学习的模型对FGSM攻击具有更好的鲁棒性。学习的局部性为网络中大规模的分布式并行学习提供了可能。最后，提出的方法是一个更符合生物学的方法，可能有助于理解生物神经元如何学习不同的抽象。
<details>	<summary>英文摘要</summary>	The backpropagation algorithm is often debated for its biological plausibility. However, various learning methods for neural architecture have been proposed in search of more biologically plausible learning. Most of them have tried to solve the "weight transport problem" and try to propagate errors backward in the architecture via some alternative methods. In this work, we investigated a slightly different approach that uses only the local information which captures spike timing information with no propagation of errors. The proposed learning rule is derived from the concepts of spike timing dependant plasticity and neuronal association. A preliminary evaluation done on the binary classification of MNIST and IRIS datasets with two hidden layers shows comparable performance with backpropagation. The model learned using this method also shows a possibility of better adversarial robustness against the FGSM attack compared to the model learned through backpropagation of cross-entropy loss. The local nature of learning gives a possibility of large scale distributed and parallel learning in the network. And finally, the proposed method is a more biologically sound method that can probably help in understanding how biological neurons learn different abstractions. </details>
<details>	<summary>注释</summary>	8 pages (4 main + 1 reference + 3 supplementary) </details>
<details>	<summary>邮件日期</summary>	2020年11月25日</details>

# 20、从头开始训练低潜伏期深脉冲神经网络的批标准化研究
- [ ] Revisiting Batch Normalization for Training Low-latency Deep Spiking Neural Networks from Scratch 
时间：2020年11月24日                         第一作者：Youngeun Kim                       [链接](https://arxiv.org/abs/2010.01729).                     
<details>	<summary>邮件日期</summary>	2020年11月25日</details>

# 19、结合可学习膜时间常数提高脉冲神经网络的学习能力
- [ ] Incorporating Learnable Membrane Time Constant to Enhance Learning of Spiking Neural Networks 
时间：2020年11月24日                         第一作者：Wei Fang                       [链接](https://arxiv.org/abs/2007.05785).                     
<details>	<summary>邮件日期</summary>	2020年11月25日</details>

# 18、脉冲神经元的自然梯度学习
- [ ] Natural-gradient learning for spiking neurons 
时间：2020年11月23日                         第一作者：Elena Kreutzer                       [链接](https://arxiv.org/abs/2011.11710).                     
## 摘要：在许多突触可塑性的规范理论中，权重的更新隐含地依赖于所选择的权重参数化。例如，这个问题与神经元形态有关：在功能上对躯体放电的影响相当的突触，由于其在树突树上的位置不同，其脊柱大小可能有很大差异。基于欧氏梯度下降的经典理论很容易由于这种参数化依赖而导致不一致。这些问题是在黎曼几何的框架下解决的，在黎曼几何中，我们提出塑性应遵循自然梯度下降。在这一假设下，我们推导出了一个突触学习规则，该规则将功能效率与树突状民主、乘法标度和异突触可塑性等生物学现象的解释结合起来。因此，我们认为，在寻找功能性突触可塑性的过程中，进化可能产生了自己版本的自然梯度下降。
<details>	<summary>英文摘要</summary>	In many normative theories of synaptic plasticity, weight updates implicitly depend on the chosen parametrization of the weights. This problem relates, for example, to neuronal morphology: synapses which are functionally equivalent in terms of their impact on somatic firing can differ substantially in spine size due to their different positions along the dendritic tree. Classical theories based on Euclidean gradient descent can easily lead to inconsistencies due to such parametrization dependence. The issues are solved in the framework of Riemannian geometry, in which we propose that plasticity instead follows natural gradient descent. Under this hypothesis, we derive a synaptic learning rule for spiking neurons that couples functional efficiency with the explanation of several well-documented biological phenomena such as dendritic democracy, multiplicative scaling and heterosynaptic plasticity. We therefore suggest that in its search for functional synaptic plasticity, evolution might have come up with its own version of natural gradient descent. </details>
<details>	<summary>注释</summary>	Joint senior authorship: Walter M. Senn and Mihai A. Petrovici </details>
<details>	<summary>邮件日期</summary>	2020年11月25日</details>

# 17、多层记忆脉冲神经网络的片上错误触发学习
- [ ] On-Chip Error-triggered Learning of Multi-layer Memristive Spiking Neural Networks 
时间：2020年11月21日                         第一作者：Melika Payv                       [链接](https://arxiv.org/abs/2011.10852).                     
## 摘要：神经形态计算的最新突破表明，梯度下降学习的局部形式与脉冲神经网络（SNNs）和突触可塑性是相容的。虽然SNNs可以用神经形态的VLSI可伸缩地实现，但是仍然缺少一种可以在原地使用梯度下降进行学习的体系结构。在本文中，我们提出了一个局部的，梯度为基础的，错误触发学习算法与在线三元权值更新。所提出的算法可以在线训练多层snn与记忆神经形态的硬件表现出小损失的性能相比，国家的最新技术。我们还提出了一种基于忆阻纵横制阵列的硬件结构来执行所需的向量矩阵乘法。采用标准180nmcmos工艺，在亚阈值范围内设计了在线训练所需的外围电路，包括突触前、突触后和写电路。
<details>	<summary>英文摘要</summary>	Recent breakthroughs in neuromorphic computing show that local forms of gradient descent learning are compatible with Spiking Neural Networks (SNNs) and synaptic plasticity. Although SNNs can be scalably implemented using neuromorphic VLSI, an architecture that can learn using gradient-descent in situ is still missing. In this paper, we propose a local, gradient-based, error-triggered learning algorithm with online ternary weight updates. The proposed algorithm enables online training of multi-layer SNNs with memristive neuromorphic hardware showing a small loss in the performance compared with the state of the art. We also propose a hardware architecture based on memristive crossbar arrays to perform the required vector-matrix multiplications. The necessary peripheral circuitry including pre-synaptic, post-synaptic and write circuits required for online training, have been designed in the sub-threshold regime for power saving with a standard 180 nm CMOS process. </details>
<details>	<summary>注释</summary>	15 pages, 11 figures, Journal of Emerging Technology in Circuits and Systems (JETCAS) </details>
<details>	<summary>邮件日期</summary>	2020年11月24日</details>

# 16、快速而深入：具有第一脉冲时间的节能神经形态学习
- [ ] Fast and deep: energy-efficient neuromorphic learning with first-spike times 
时间：2020年11月19日                         第一作者：Julian G\"oltz                       [链接](https://arxiv.org/abs/1912.11443).                     
<details>	<summary>注释</summary>	20 pages, 8 figures </details>
<details>	<summary>邮件日期</summary>	2020年11月20日</details>

# 15、基于生物似然无监督延迟学习的脉冲神经网络时间特征提取
- [ ] Bio-plausible Unsupervised Delay Learning for Extracting Temporal Features in Spiking Neural Networks 
时间：2020年11月18日                         第一作者：Alireza Nadafian                       [链接](https://arxiv.org/abs/2011.09380).                     
## 摘要：神经元间传导延迟的可塑性在学习中起着基础性作用。然而，大脑中这种调节的确切机制仍然是一个开放的问题。了解突触延迟的精确调节可以帮助我们开发有效的大脑启发计算模型，提供与实验证据一致的见解。在这篇论文中，我们提出一个无监督的生物学上合理的学习规则来调整神经网络中的突触延迟。然后，我们提供了一些数学证明来证明我们的学习规则赋予神经元学习重复时空模式的能力。此外，将基于STDP的脉冲神经网络与我们提出的延迟学习规则相结合，应用于随机点运动图的实验结果表明了所提出的延迟学习规则在提取时间特征方面的有效性。
<details>	<summary>英文摘要</summary>	The plasticity of the conduction delay between neurons plays a fundamental role in learning. However, the exact underlying mechanisms in the brain for this modulation is still an open problem. Understanding the precise adjustment of synaptic delays could help us in developing effective brain-inspired computational models in providing aligned insights with the experimental evidence. In this paper, we propose an unsupervised biologically plausible learning rule for adjusting the synaptic delays in spiking neural networks. Then, we provided some mathematical proofs to show that our learning rule gives a neuron the ability to learn repeating spatio-temporal patterns. Furthermore, the experimental results of applying an STDP-based spiking neural network equipped with our proposed delay learning rule on Random Dot Kinematogram indicate the efficacy of the proposed delay learning rule in extracting temporal features. </details>
<details>	<summary>邮件日期</summary>	2020年11月19日</details>

# 14、脉冲神经网络的时间代理反向传播算法
- [ ] Temporal Surrogate Back-propagation for Spiking Neural Networks 
时间：2020年11月18日                         第一作者：Yukun Yang                       [链接](https://arxiv.org/abs/2011.09964).                     
## 摘要：脉冲神经网络（SNN）通常比人工神经网络（ANN）更节能，其工作方式与我们的大脑有很大的相似性。近年来，BP算法在神经网络训练中显示出了强大的能力。然而，由于脉冲行为是不可微的，BP不能直接应用于SNN。虽然已有的工作证明了在空间和时间方向上通过替代梯度或随机性来逼近BP梯度的几种方法，但是它们忽略了每一步之间重置机制引入的时间依赖性。本文以理论完善为目标，深入研究了缺失项的影响。通过增加重置机制的时间依赖性，新算法对玩具数据集的学习率调整更具鲁棒性，但对CIFAR-10等较大的学习任务没有太大的改进。从经验上讲，缺失项的好处不值得额外的计算开销。在许多情况下，可以忽略缺少的项。
<details>	<summary>英文摘要</summary>	Spiking neural networks (SNN) are usually more energy-efficient as compared to Artificial neural networks (ANN), and the way they work has a great similarity with our brain. Back-propagation (BP) has shown its strong power in training ANN in recent years. However, since spike behavior is non-differentiable, BP cannot be applied to SNN directly. Although prior works demonstrated several ways to approximate the BP-gradient in both spatial and temporal directions either through surrogate gradient or randomness, they omitted the temporal dependency introduced by the reset mechanism between each step. In this article, we target on theoretical completion and investigate the effect of the missing term thoroughly. By adding the temporal dependency of the reset mechanism, the new algorithm is more robust to learning-rate adjustments on a toy dataset but does not show much improvement on larger learning tasks like CIFAR-10. Empirically speaking, the benefits of the missing term are not worth the additional computational overhead. In many cases, the missing term can be ignored. </details>
<details>	<summary>注释</summary>	4 pases, 3 figures, 3 tables, 10 eqs </details>
<details>	<summary>邮件日期</summary>	2020年11月20日</details>

# 13、一种用于术中心电图高频振荡检测的脉冲神经网络（SNN）
- [ ] A Spiking Neural Network (SNN) for detecting High Frequency Oscillations (HFOs) in the intraoperative ECoG 
时间：2020年11月17日                         第一作者：Karla Burelo                        [链接](https://arxiv.org/abs/2011.08783).                     
## 摘要：癫痫手术需要彻底切除致痫脑组织，才能实现癫痫发作的自由。在术中的ECoG记录中，由致痫组织产生的高频振荡（HFOs）可以用来调整切除边缘。然而，实时自动检测HFOs仍然是一个开放的挑战。在这里，我们提出了一个脉冲神经网络（SNN）的自动HFO检测，是最适合神经形态的硬件实现。我们训练SNN来检测术中ECoG在线测量的HFO信号，使用一个独立标记的数据集。我们针对快速纹波频率范围（250-500hz）的HFO检测，并将网络结果与标记的HFO数据进行比较。我们赋予SNN一种新的伪影抑制机制来抑制突变，并在ECoG数据集上验证了其有效性。该SNN检测到的HFO率（术前记录中位数为6.6 HFO/min）与数据集中公布的HFO率（58 min，16次记录）相当。所有8例患者术后癫痫发作结果的“预测”准确率均为100%。这些结果为建立一个可在癫痫手术中用于指导致痫区切除的实时便携式电池供电HFO检测系统提供了进一步的进展。
<details>	<summary>英文摘要</summary>	To achieve seizure freedom, epilepsy surgery requires the complete resection of the epileptogenic brain tissue. In intraoperative ECoG recordings, high frequency oscillations (HFOs) generated by epileptogenic tissue can be used to tailor the resection margin. However, automatic detection of HFOs in real-time remains an open challenge. Here we present a spiking neural network (SNN) for automatic HFO detection that is optimally suited for neuromorphic hardware implementation. We trained the SNN to detect HFO signals measured from intraoperative ECoG on-line, using an independently labeled dataset. We targeted the detection of HFOs in the fast ripple frequency range (250-500 Hz) and compared the network results with the labeled HFO data. We endowed the SNN with a novel artifact rejection mechanism to suppress sharp transients and demonstrate its effectiveness on the ECoG dataset. The HFO rates (median 6.6 HFO/min in pre-resection recordings) detected by this SNN are comparable to those published in the dataset (58 min, 16 recordings). The postsurgical seizure outcome was "predicted" with 100% accuracy for all 8 patients. These results provide a further step towards the construction of a real-time portable battery-operated HFO detection system that can be used during epilepsy surgery to guide the resection of the epileptogenic zone. </details>
<details>	<summary>注释</summary>	11 pages, 3 figures, 2 tables. The results of this publication were obtained by simulating our hardware platform, built for online processing of biological signals. This hardware combines neural recording headstages with a multi-core neuromorphic processor arxiv.org/abs/2009.11245 </details>
<details>	<summary>邮件日期</summary>	2020年11月18日</details>

# 12、结合可学习膜时间常数提高脉冲神经网络的学习能力
- [ ] Incorporating Learnable Membrane Time Constant to Enhance Learning of Spiking Neural Networks 
时间：2020年11月16日                         第一作者：Wei Fang                       [链接](https://arxiv.org/abs/2007.05785).                     
<details>	<summary>邮件日期</summary>	2020年11月17日</details>

# 11、具有Alpha突触功能的脉冲神经网络中的时间编码：反向传播学习
- [ ] Temporal Coding in Spiking Neural Networks with Alpha Synaptic Function: Learning with Backpropagation 
时间：2020年11月16日                         第一作者：Iulia M. Comsa                       [链接](https://arxiv.org/abs/1907.13223).                     
<details>	<summary>注释</summary>	Open-source code related to this paper is available at https://github.com/google/ihmehimmeli v2: Added references and added some clarifications for the methods </details>
<details>	<summary>邮件日期</summary>	2020年11月18日</details>

# 10、LIAF-Net：轻量级高效时空信息处理的漏泄集成模拟消防网络
- [ ] LIAF-Net: Leaky Integrate and Analog Fire Network for Lightweight and Efficient Spatiotemporal Information Processing 
时间：2020年11月12日                         第一作者：Zhenzhi Wu                       [链接](https://arxiv.org/abs/2011.06176).                     
## 摘要：基于漏积分火灾（LIF）模型的脉冲神经网络（SNNs）已被应用于节能的时空处理任务中。由于生物似有理的神经元动力学和简单性，LIF-SNN受益于事件驱动处理，然而，通常面临性能下降的尴尬。这可能是因为在LIF-SNN中，神经元通过脉冲传递信息。为了解决这一问题，本文提出了一种漏积分模拟火灾（LIAF）神经元模型，使得模拟值可以在神经元之间传输，并在此基础上建立了一个称为LIAF网络的深层网络，以实现高效的时空处理。在时域上，LIAF遵循传统的LIF动态机制来保持其时间处理能力。在空间域中，LIAF能够通过卷积积分或全连通积分对空间信息进行集成。作为一个时空层，LIAF也可以与传统的人工神经网络（ANN）层联合使用。实验结果表明，在bAbI问答（QA）任务中，LIAF网络的性能与选通递归单元（GRU）和长短时记忆（LSTM）相当，在时空动态视觉传感器（DVS）数据集（包括MNIST-DVS、CIFAR10-DVS和DVS128手势）上，LIAF网络的性能达到了最先进的水平，但数量要少得多与传统的LSTM、GRU、卷积LSTM（ConvLSTM）或3D卷积（Conv3D）构建的网络相比，突触权值和计算开销都有较大的提高。与传统的LIF-SNN相比，LIAF网络在所有这些实验中也显示出显著的精度提高。总之，LIAF-Net提供了一个结合ANNs和SNNs优点的轻量级高效时空信息处理框架。
<details>	<summary>英文摘要</summary>	Spiking neural networks (SNNs) based on Leaky Integrate and Fire (LIF) model have been applied to energy-efficient temporal and spatiotemporal processing tasks. Thanks to the bio-plausible neuronal dynamics and simplicity, LIF-SNN benefits from event-driven processing, however, usually faces the embarrassment of reduced performance. This may because in LIF-SNN the neurons transmit information via spikes. To address this issue, in this work, we propose a Leaky Integrate and Analog Fire (LIAF) neuron model, so that analog values can be transmitted among neurons, and a deep network termed as LIAF-Net is built on it for efficient spatiotemporal processing. In the temporal domain, LIAF follows the traditional LIF dynamics to maintain its temporal processing capability. In the spatial domain, LIAF is able to integrate spatial information through convolutional integration or fully-connected integration. As a spatiotemporal layer, LIAF can also be used with traditional artificial neural network (ANN) layers jointly. Experiment results indicate that LIAF-Net achieves comparable performance to Gated Recurrent Unit (GRU) and Long short-term memory (LSTM) on bAbI Question Answering (QA) tasks, and achieves state-of-the-art performance on spatiotemporal Dynamic Vision Sensor (DVS) datasets, including MNIST-DVS, CIFAR10-DVS and DVS128 Gesture, with much less number of synaptic weights and computational overhead compared with traditional networks built by LSTM, GRU, Convolutional LSTM (ConvLSTM) or 3D convolution (Conv3D). Compared with traditional LIF-SNN, LIAF-Net also shows dramatic accuracy gain on all these experiments. In conclusion, LIAF-Net provides a framework combining the advantages of both ANNs and SNNs for lightweight and efficient spatiotemporal information processing. </details>
<details>	<summary>注释</summary>	14 pages, 9 figures, submitted to IEEE Transactions on Neural Networks and Learning Systems ACM-class: I.2.6 </details>
<details>	<summary>邮件日期</summary>	2020年11月13日</details>

# 9、利用生物似然奖赏传播调整卷积脉冲神经网络
- [x] Tuning Convolutional Spiking Neural Network with Biologically-plausible Reward Propagation 
时间：2020年11月12日                         第一作者：Tielin Zhang                        [链接](https://arxiv.org/abs/2010.04434).                     
<details>	<summary>邮件日期</summary>	2020年11月13日</details>

# 8、基于VCSEL神经元的全光神经形态二值卷积算法
- [ ] All-optical neuromorphic binary convolution with a spiking VCSEL neuron for image gradient magnitudes 
时间：2020年11月09日                         第一作者：Yahui Zhang                       [链接](https://arxiv.org/abs/2011.04438).                     
## 摘要：首次提出了一种基于光子脉冲垂直腔面发射激光器（VCSEL）神经元的全光二值卷积方法，并进行了实验验证。从数字图像中提取并使用矩形脉冲进行时间编码的光输入被注入VCSEL神经元中，VCSEL神经元提供快速（<100ps长）脉冲发射数的卷积结果。实验和数值结果表明，采用单脉冲VCSEL神经元实现了二值卷积，全光二值卷积可用于计算图像梯度大小，检测边缘特征，分离源图像中的垂直分量和水平分量。我们还证明了这种全光脉冲二值卷积系统对噪声具有很强的鲁棒性，并且可以处理高分辨率的图像。此外，该系统还具有速度快、能量效率高、硬件实现简单等优点，突出了脉冲光子VCSEL神经元在高速神经图像处理系统和未来光子脉冲卷积神经网络中的应用潜力。
<details>	<summary>英文摘要</summary>	All-optical binary convolution with a photonic spiking vertical-cavity surface-emitting laser (VCSEL) neuron is proposed and demonstrated experimentally for the first time. Optical inputs, extracted from digital images and temporally encoded using rectangular pulses, are injected in the VCSEL neuron which delivers the convolution result in the number of fast (<100 ps long) spikes fired. Experimental and numerical results show that binary convolution is achieved successfully with a single spiking VCSEL neuron and that all-optical binary convolution can be used to calculate image gradient magnitudes to detect edge features and separate vertical and horizontal components in source images. We also show that this all-optical spiking binary convolution system is robust to noise and can operate with high-resolution images. Additionally, the proposed system offers important advantages such as ultrafast speed, high energy efficiency and simple hardware implementation, highlighting the potentials of spiking photonic VCSEL neurons for high-speed neuromorphic image processing systems and future photonic spiking convolutional neural networks. </details>
<details>	<summary>注释</summary>	jxxsy@126.com; antonio.hurtado@strath.ac.uk </details>
<details>	<summary>邮件日期</summary>	2020年11月10日</details>

# 7、用gpu快速模拟高度连接的棘波皮层模型
- [ ] Fast simulations of highly-connected spiking cortical models using GPUs 
时间：2020年11月09日                         第一作者：Bruno Golosio                       [链接](https://arxiv.org/abs/2007.14236).                     
<details>	<summary>邮件日期</summary>	2020年11月10日</details>

# 6、你只刺一次：提高能源效率神经形态推理到神经网络水平的准确性
- [ ] You Only Spike Once: Improving Energy-Efficient Neuromorphic Inference to ANN-Level Accuracy 
时间：2020年11月08日                         第一作者：Srivatsa P                        [链接](https://arxiv.org/abs/2006.09982).                     
<details>	<summary>注释</summary>	10 pages, 4 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. This work is an extended version of the paper accepted to the 2nd Workshop on Accelerated Machine Learning (AccML 2020) </details>
<details>	<summary>邮件日期</summary>	2020年11月10日</details>

# 5、深脉冲神经网络反向传播的校正线性突触后电位函数
- [x] Rectified Linear Postsynaptic Potential Function for Backpropagation in Deep Spiking Neural Networks 
时间：2020年11月04日                         第一作者：Malu Zhang                       [链接](https://arxiv.org/abs/2003.11837).                     
<details>	<summary>注释</summary>	This work has been submitted to the IEEE for possible publication. Copyrightmay be transferred without notice, after which this version may no longer beaccessible </details>
<details>	<summary>邮件日期</summary>	2020年11月05日</details>

# 4、脉冲耦合振荡器网络中的受控微扰诱导开关
- [x] Controlled Perturbation-Induced Switching in Pulse-Coupled Oscillator Networks 
时间：2020年11月02日                         第一作者：Fabio Schittler Neves                        [链接](https://arxiv.org/abs/2011.00888).                     
## 摘要：脉冲耦合系统，如脉冲神经网络，表现出非平凡不变集的形式吸引但不稳定的鞍周期轨道的单位同步成组。这些轨道之间的异宿连接原则上可以支持这些网络中的切换过程，并支持新的神经计算。对于耦合振子的小网络，我们在此研究在何种条件下以及系统对称性如何强制或禁止某些可能由扰动引起的开关跃迁。对于由五个振子组成的网络，我们导出了两个团簇对称性的显式跃迁规则，这些规则偏离了已知的连续耦合振子的跃迁规则。第三种对称产生异宿网络，它由所有具有这种对称性的不稳定吸引子以及它们之间的连接组成。我们的结果表明，脉冲耦合系统能够可靠地产生符合特定转换规则的复杂时空模式。我们简要地讨论了脉冲神经系统计算的可能含义。
<details>	<summary>英文摘要</summary>	Pulse-coupled systems such as spiking neural networks exhibit nontrivial invariant sets in the form of attracting yet unstable saddle periodic orbits where units are synchronized into groups. Heteroclinic connections between such orbits may in principle support switching processes in those networks and enable novel kinds of neural computations. For small networks of coupled oscillators we here investigate under which conditions and how system symmetry enforces or forbids certain switching transitions that may be induced by perturbations. For networks of five oscillators we derive explicit transition rules that for two cluster symmetries deviate from those known from oscillators coupled continuously in time. A third symmetry yields heteroclinic networks that consist of sets of all unstable attractors with that symmetry and the connections between them. Our results indicate that pulse-coupled systems can reliably generate well-defined sets of complex spatiotemporal patterns that conform to specific transition rules. We briefly discuss possible implications for computation with spiking neural systems. </details>
<details>	<summary>邮件日期</summary>	2020年11月03日</details>

# 3、RANC：可重构的神经形态计算体系结构
- [ ] RANC: Reconfigurable Architecture for Neuromorphic Computing 
时间：2020年11月01日                         第一作者：Joshua Mack                       [链接](https://arxiv.org/abs/2011.00624).                     
## 摘要：神经形态结构已经被引入作为能量有效的脉冲神经网络执行的平台。这些体系结构所提供的大规模并行性也引起了非机器学习应用领域的兴趣。为了提升硬件设计者和应用开发者的进入壁垒，我们提出了RANC：一种可重构的神经形态计算体系结构，一个开源的高度灵活的生态系统，通过C++仿真和硬件通过FPGA仿真，能够快速地在软件中对神经形态结构进行实验。我们展示了RANC生态系统的实用性，通过展示其重现IBM的TrueNorth行为的能力，并通过与IBM的Compass模拟环境和已发表文献的直接比较进行验证。RANC允许基于应用程序洞察优化架构，以及原型化可以完全支持新类应用程序的未来神经形态架构。通过基于Alveo U250 FPGA的定量分析，研究了体系结构变化对提高应用程序映射效率的影响，证明了RANC的高度参数化和可配置性。本文介绍了合成孔径雷达分类和矢量矩阵乘法应用的路由后资源使用和吞吐量分析，并展示了一个可扩展到模拟259K个不同神经元和733m个不同突触的神经形态结构。
<details>	<summary>英文摘要</summary>	Neuromorphic architectures have been introduced as platforms for energy efficient spiking neural network execution. The massive parallelism offered by these architectures has also triggered interest from non-machine learning application domains. In order to lift the barriers to entry for hardware designers and application developers we present RANC: a Reconfigurable Architecture for Neuromorphic Computing, an open-source highly flexible ecosystem that enables rapid experimentation with neuromorphic architectures in both software via C++ simulation and hardware via FPGA emulation. We present the utility of the RANC ecosystem by showing its ability to recreate behavior of the IBM's TrueNorth and validate with direct comparison to IBM's Compass simulation environment and published literature. RANC allows optimizing architectures based on application insights as well as prototyping future neuromorphic architectures that can support new classes of applications entirely. We demonstrate the highly parameterized and configurable nature of RANC by studying the impact of architectural changes on improving application mapping efficiency with quantitative analysis based on Alveo U250 FPGA. We present post routing resource usage and throughput analysis across implementations of Synthetic Aperture Radar classification and Vector Matrix Multiplication applications, and demonstrate a neuromorphic architecture that scales to emulating 259K distinct neurons and 73.3M distinct synapses. </details>
<details>	<summary>注释</summary>	18 pages, 12 figures, accepted for publication in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. For associated source files see https://github.com/UA-RCL/RANC </details>
<details>	<summary>邮件日期</summary>	2020年11月03日</details>

# 2、基于Loihi处理器的mav光流着陆神经形态控制
- [x] Neuromorphic control for optic-flow-based landings of MAVs using the Loihi processor 
时间：2020年11月01日                         第一作者：Julien Dupeyroux                       [链接](https://arxiv.org/abs/2011.00534).                     
## 摘要：像Loihi这样的神经形态处理器为微型飞行器（mav）这样的受限系统提供了一个有希望的替代传统计算模块，使其具有强大、高效和自主的技能，如起飞和着陆、避障和追踪。然而，在机器人平台上使用这种处理器的一个主要挑战是模拟和真实世界之间的现实差距。在这项研究中，我们首次提出了一个完全嵌入式应用的Loihi神经芯片原型在飞行机器人。为了实现自主着陆，提出了一种基于腹部光流场发散的脉冲神经网络（SNN）来计算推力指令。进化是使用PySNN库在基于Python的模拟器中执行的。该网络结构仅由分布在3层中的35个神经元组成。仿真和Loihi之间的定量分析表明，推力设定值的均方根误差低至0.005 g，同时，隐藏层的脉冲序列匹配率为99.8%，输出层的脉冲序列匹配率为99.7%。所提出的方法成功地填补了现实差距，为未来机器人中的神经形态应用提供了重要的见解。补充材料可在https://mavlab.tudelft.nl/loihi/。
<details>	<summary>英文摘要</summary>	Neuromorphic processors like Loihi offer a promising alternative to conventional computing modules for endowing constrained systems like micro air vehicles (MAVs) with robust, efficient and autonomous skills such as take-off and landing, obstacle avoidance, and pursuit. However, a major challenge for using such processors on robotic platforms is the reality gap between simulation and the real world. In this study, we present for the very first time a fully embedded application of the Loihi neuromorphic chip prototype in a flying robot. A spiking neural network (SNN) was evolved to compute the thrust command based on the divergence of the ventral optic flow field to perform autonomous landing. Evolution was performed in a Python-based simulator using the PySNN library. The resulting network architecture consists of only 35 neurons distributed among 3 layers. Quantitative analysis between simulation and Loihi reveals a root-mean-square error of the thrust setpoint as low as 0.005 g, along with a 99.8% matching of the spike sequences in the hidden layer, and 99.7% in the output layer. The proposed approach successfully bridges the reality gap, offering important insights for future neuromorphic applications in robotics. Supplementary material is available at https://mavlab.tudelft.nl/loihi/. </details>
<details>	<summary>邮件日期</summary>	2020年11月03日</details>

# 1、用直接训练的更大的脉冲神经网络进行更深入的研究
- [x] Going Deeper With Directly-Trained Larger Spiking Neural Networks 
时间：2020年10月29日                         第一作者：Hanle Zheng                       [链接](https://arxiv.org/abs/2011.05280).                     
## 摘要：脉冲神经网络（Spiking neural networks，SNNs）在时空信息和事件驱动信号处理的生物似然编码方面有着广阔的应用前景，非常适合于神经形态硬件的节能实现。然而，SNNs独特的工作模式使其比传统网络更难训练。目前，探索高性能深层snn的培养主要有两条途径。第一种方法是将预先训练好的神经网络模型转换为SNN模型，SNN模型通常需要较长的编码窗口才能收敛，并且在训练过程中不能利用时空特征来求解时间任务。另一种是直接在时空域训练snn。但是由于触发函数的二元脉冲活动和梯度消失或爆炸的问题，目前的方法局限于浅层结构，因此难以利用大规模数据集（如ImageNet）。为此，我们提出了一种基于时空反向传播的阈值相关批处理归一化（tdBN）方法，称为STBP-tdBN，它能够直接训练非常深的SNN并在神经形态硬件上有效地实现其推理。通过提出的方法和详细的快捷连接，我们将直接训练的snn从浅层（<10层）扩展到非常深的结构（50层）。在此基础上，从理论上分析了基于块动态等距理论的方法的有效性。最后，我们报告了更高的准确率结果，包括93.15%的CIFAR-10，67.8%的DVS-CIFAR10和67.05%的ImageNet与很少的时间步长。据我们所知，这是第一次在ImageNet上探索直接训练的高性能深度snn。
<details>	<summary>英文摘要</summary>	Spiking neural networks (SNNs) are promising in a bio-plausible coding for spatio-temporal information and event-driven signal processing, which is very suited for energy-efficient implementation in neuromorphic hardware. However, the unique working mode of SNNs makes them more difficult to train than traditional networks. Currently, there are two main routes to explore the training of deep SNNs with high performance. The first is to convert a pre-trained ANN model to its SNN version, which usually requires a long coding window for convergence and cannot exploit the spatio-temporal features during training for solving temporal tasks. The other is to directly train SNNs in the spatio-temporal domain. But due to the binary spike activity of the firing function and the problem of gradient vanishing or explosion, current methods are restricted to shallow architectures and thereby difficult in harnessing large-scale datasets (e.g. ImageNet). To this end, we propose a threshold-dependent batch normalization (tdBN) method based on the emerging spatio-temporal backpropagation, termed "STBP-tdBN", enabling direct training of a very deep SNN and the efficient implementation of its inference on neuromorphic hardware. With the proposed method and elaborated shortcut connection, we significantly extend directly-trained SNNs from a shallow structure ( < 10 layer) to a very deep structure (50 layers). Furthermore, we theoretically analyze the effectiveness of our method based on "Block Dynamical Isometry" theory. Finally, we report superior accuracy results including 93.15 % on CIFAR-10, 67.8 % on DVS-CIFAR10, and 67.05% on ImageNet with very few timesteps. To our best knowledge, it's the first time to explore the directly-trained deep SNNs with high performance on ImageNet. </details>
<details>	<summary>注释</summary>	12 pages, 6 figures, conference or other essential info </details>
<details>	<summary>邮件日期</summary>	2020年11月11日</details>

